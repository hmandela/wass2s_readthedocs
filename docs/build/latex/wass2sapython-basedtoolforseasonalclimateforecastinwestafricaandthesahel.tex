%% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax
\ifdefined\pdfimageresolution
    \pdfimageresolution= \numexpr \dimexpr1in\relax/\sphinxpxdimen\relax
\fi
%% let collapsible pdf bookmarks panel have high depth per default
\PassOptionsToPackage{bookmarksdepth=5}{hyperref}

\PassOptionsToPackage{booktabs}{sphinx}
\PassOptionsToPackage{colorrows}{sphinx}

\PassOptionsToPackage{warn}{textcomp}
\usepackage[utf8]{inputenc}
\ifdefined\DeclareUnicodeCharacter
% support both utf8 and utf8x syntaxes
  \ifdefined\DeclareUnicodeCharacterAsOptional
    \def\sphinxDUC#1{\DeclareUnicodeCharacter{"#1}}
  \else
    \let\sphinxDUC\DeclareUnicodeCharacter
  \fi
  \sphinxDUC{00A0}{\nobreakspace}
  \sphinxDUC{2500}{\sphinxunichar{2500}}
  \sphinxDUC{2502}{\sphinxunichar{2502}}
  \sphinxDUC{2514}{\sphinxunichar{2514}}
  \sphinxDUC{251C}{\sphinxunichar{251C}}
  \sphinxDUC{2572}{\textbackslash}
\fi
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amstext}
\usepackage{babel}



\usepackage{tgtermes}
\usepackage{tgheros}
\renewcommand{\ttdefault}{txtt}



\usepackage[Bjarne]{fncychap}
\usepackage{sphinx}

\fvset{fontsize=auto}
\usepackage{geometry}


% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}

\addto\captionsenglish{\renewcommand{\contentsname}{Contents:}}

\usepackage{sphinxmessages}
\setcounter{tocdepth}{1}


    \usepackage{enumitem}
    \setlistdepth{8}
    

\title{wass2s: A python\sphinxhyphen{}based tool for seasonal climate forecast in West Africa and the Sahel.\@{}}
\date{Jun 25, 2025}
\release{0.1.1}
\author{Mandela C.\@{} M.\@{} HOUNGNIBO}
\newcommand{\sphinxlogo}{\vbox{}}
\renewcommand{\releasename}{Release}
\makeindex
\begin{document}

\ifdefined\shorthandoff
  \ifnum\catcode`\=\string=\active\shorthandoff{=}\fi
  \ifnum\catcode`\"=\active\shorthandoff{"}\fi
\fi

\pagestyle{empty}
\sphinxmaketitle
\pagestyle{plain}
\sphinxtableofcontents
\pagestyle{normal}
\phantomsection\label{\detokenize{index::doc}}


\sphinxAtStartPar
A python\sphinxhyphen{}based tool for seasonal climate forecast in West Africa and the Sahel.

\sphinxAtStartPar
The wass2s tool is designed to facilitate implementation of the new generation of seasonal forecasts in West Africa and the Sahel using various statistical and machine learning methods. New generation of seasonal forecasts aligns with the World Meteorological Organization’s (WMO) guidelines for objective, operational, and scientifically rigorous seasonal forecasting methods. wass2s helps forecaster to download GCM, reanalysis, and satellite/observation data, build statistical or machine learning models, verify the models using cross\sphinxhyphen{}validation, and forecast.
A user\sphinxhyphen{}friendly \sphinxhref{https://github.com/hmandela/WASS2S\_notebooks}{jupyter\sphinxhyphen{}lab notebook}  streamlines the forecasting process .

\sphinxAtStartPar
\sphinxstylestrong{Features}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Automated Forecasting

\item {} 
\sphinxAtStartPar
Reproducibility

\item {} 
\sphinxAtStartPar
Modularity

\item {} 
\sphinxAtStartPar
Exploration of Machine Learning Models.

\end{itemize}

\sphinxstepscope


\chapter{Installation}
\label{\detokenize{Installation:installation}}\label{\detokenize{Installation::doc}}\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Create an environment and activate it

\end{enumerate}
\begin{itemize}
\item {} 
\sphinxAtStartPar
For Windows: download yaml \sphinxhref{https://github.com/hmandela/WASS2S/blob/main/WAS\_S2S\_windows.yml}{here} and run

\end{itemize}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
conda\PYG{+w}{ }env\PYG{+w}{ }create\PYG{+w}{ }\PYGZhy{}f\PYG{+w}{ }WAS\PYGZus{}S2S\PYGZus{}windows.yml
conda\PYG{+w}{ }activate\PYG{+w}{ }WASS2S
\end{sphinxVerbatim}
\begin{itemize}
\item {} 
\sphinxAtStartPar
For Linux: download yaml \sphinxhref{https://github.com/hmandela/WASS2S/blob/main/WAS\_S2S\_linux.yml}{here} and run

\end{itemize}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
conda\PYG{+w}{ }env\PYG{+w}{ }create\PYG{+w}{ }\PYGZhy{}f\PYG{+w}{ }WAS\PYGZus{}S2S\PYGZus{}linux.yml
conda\PYG{+w}{ }activate\PYG{+w}{ }WASS2S
\end{sphinxVerbatim}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{1}
\item {} 
\sphinxAtStartPar
Install the wass2s package

\end{enumerate}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
pip\PYG{+w}{ }install\PYG{+w}{ }wass2s
\end{sphinxVerbatim}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{2}
\item {} 
\sphinxAtStartPar
Upgrade the wass2s package

\end{enumerate}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
pip\PYG{+w}{ }install\PYG{+w}{ }\PYGZhy{}\PYGZhy{}upgrade\PYG{+w}{ }wass2s
\end{sphinxVerbatim}

\sphinxstepscope


\chapter{Usage}
\label{\detokenize{Usage:usage}}\label{\detokenize{Usage::doc}}
\sphinxAtStartPar
Comprehensive usage guidelines, including data download, processing, models description, configuration and execution, cross\sphinxhyphen{}validation, and verification, are available in the \sphinxhref{https://hmandela.github.io/WAS\_S2S\_Training/}{Training Documentation}.
But for a quick start, use the \sphinxhref{https://github.com/hmandela/WASS2S\_notebooks}{example notebooks}.

\sphinxAtStartPar
Download example notebooks:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
git\PYG{+w}{ }clone\PYG{+w}{ }https://github.com/hmandela/WASS2S\PYGZus{}notebooks.git
\end{sphinxVerbatim}

\sphinxAtStartPar
or download the zip file:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
wget\PYG{+w}{ }https://github.com/hmandela/WASS2S\PYGZus{}notebooks/archive/refs/heads/main.zip\PYG{+w}{ }\PYGZhy{}O\PYG{+w}{ }WASS2S\PYGZus{}notebooks.zip
\end{sphinxVerbatim}

\sphinxstepscope


\section{Download module}
\label{\detokenize{Download:download-module}}\label{\detokenize{Download::doc}}
\sphinxAtStartPar
Three types of data can be downloaded with wass2s:
\begin{itemize}
\item {} 
\sphinxAtStartPar
GCM data on seasonal time scales

\item {} 
\sphinxAtStartPar
Reanalysis data

\item {} 
\sphinxAtStartPar
Observational data (satellite data, products combining satellite and observational data)

\end{itemize}

\sphinxAtStartPar
For some data, for instance \sphinxhref{https://cds.climate.copernicus.eu/}{C3S}, it requires creating an account, accepting the terms of use, and configuring an API key (\sphinxhref{https://hmandela.github.io/WAS\_S2S\_Training/s2s\_data.html}{CDS API key}).
Please refer also to the \sphinxhref{https://cds.climate.copernicus.eu/api-how-to}{CDS documentation} for more instructions on how to set up the API key.
For more information on C3S seasonal data, browse the \sphinxhref{https://confluence.ecmwf.int/display/CKB/Description+of+the+C3S+seasonal+multi-system}{MetaData}.


\subsection{Download GCM data}
\label{\detokenize{Download:download-gcm-data}}
\sphinxAtStartPar
The \sphinxcode{\sphinxupquote{WAS\_Download\_Models}} method allows downloading seasonal forecast model data from various centers for specified variables, initialization months, lead times, and years.

\sphinxAtStartPar
\sphinxstylestrong{Parameters:}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{dir\_to\_save}} (str): Directory to save the downloaded files.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{center\_variable}} (list): List of center\sphinxhyphen{}variable identifiers, e.g., {[}“ECMWF\_51.PRCP”, “UKMO\_604.TEMP”{]}.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{month\_of\_initialization}} (int): Initialization month as an integer (1\sphinxhyphen{}12).

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{lead\_time}} (list): List of lead times in months.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{year\_start\_hindcast}} (int): Start year for hindcast data.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{year\_end\_hindcast}} (int): End year for hindcast data.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{area}} (list): Bounding box as {[}North, West, South, East{]} for clipping.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{year\_forecast}} (int, optional): Forecast year if downloading forecast data. Defaults to None.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{ensemble\_mean}} (str, optional): Can be “median”, “mean”, or None. Defaults to None.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{force\_download}} (bool): If True, forces download even if file exists.

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Available centers and variables:}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Centers:} BOM\_2, ECMWF\_51, UKMO\_604, UKMO\_603, METEOFRANCE\_8, METEOFRANCE\_9, DWD\_21, DWD\_22, CMCC\_35, NCEP\_2, JMA\_3, ECCC\_4, ECCC\_5, CFSV2\_1, CMC1\_1, CMC2\_1, GFDL\_1, NASA\_1, NCAR\_CCSM4\_1, NMME\_1

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Variables:} PRCP, TEMP, TMAX, TMIN, UGRD10, VGRD10, SST, SLP, DSWR, DLWR, HUSS\_1000, HUSS\_925, HUSS\_850, UGRD\_1000, UGRD\_925, UGRD\_850, VGRD\_1000, VGRD\_925, VGRD\_850

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Note:} Some models are part of the NMME (North American Multi\sphinxhyphen{}Model Ensemble) project. For more information, see the \sphinxhref{https://www.cpc.ncep.noaa.gov/products/NMME/}{NMME documentation}.
If \sphinxcode{\sphinxupquote{year\_forecast}} is not specified, hindcast data is downloaded; otherwise, forecast data for the specified year is retrieved.

\sphinxAtStartPar
\sphinxstylestrong{Example:}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from}\PYG{+w}{ }\PYG{n+nn}{wass2s}\PYG{+w}{ }\PYG{k+kn}{import} \PYG{o}{*}

\PYG{n}{downloader} \PYG{o}{=} \PYG{n}{WAS\PYGZus{}Download}\PYG{p}{(}\PYG{p}{)}

\PYG{n}{downloader}\PYG{o}{.}\PYG{n}{WAS\PYGZus{}Download\PYGZus{}Models}\PYG{p}{(}
    \PYG{n}{dir\PYGZus{}to\PYGZus{}save}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{/path/to/save}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{n}{center\PYGZus{}variable}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{ECMWF\PYGZus{}51.PRCP}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{,}
    \PYG{n}{month\PYGZus{}of\PYGZus{}initialization}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{03}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{n}{lead\PYGZus{}time}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{01}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{02}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{03}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{,}
    \PYG{n}{year\PYGZus{}start\PYGZus{}hindcast}\PYG{o}{=}\PYG{l+m+mi}{1993}\PYG{p}{,}
    \PYG{n}{year\PYGZus{}end\PYGZus{}hindcast}\PYG{o}{=}\PYG{l+m+mi}{2016}\PYG{p}{,}
    \PYG{n}{area}\PYG{o}{=}\PYG{p}{[}\PYG{l+m+mi}{60}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{180}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{60}\PYG{p}{,} \PYG{l+m+mi}{180}\PYG{p}{]}\PYG{p}{,}
    \PYG{n}{force\PYGZus{}download}\PYG{o}{=}\PYG{k+kc}{False}
\PYG{p}{)}
\end{sphinxVerbatim}


\subsection{Download daily GCM data}
\label{\detokenize{Download:download-daily-gcm-data}}
\sphinxAtStartPar
The \sphinxcode{\sphinxupquote{WAS\_Download\_Models\_Daily}} method allows downloading daily or sub\sphinxhyphen{}daily seasonal forecast model data from various centers for specified variables, initialization dates, lead times, and years.

\sphinxAtStartPar
\sphinxstylestrong{Parameters:}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{dir\_to\_save}} (str): Directory to save the downloaded files.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{center\_variable}} (list): List of center\sphinxhyphen{}variable identifiers, e.g., {[}“ECMWF\_51.PRCP”, “UKMO\_604.TEMP”{]}.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{month\_of\_initialization}} (int): Initialization month as an integer (1\sphinxhyphen{}12).

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{day\_of\_initialization}} (int): Initialization day as an integer (1\sphinxhyphen{}31).

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{leadtime\_hour}} (list): List of lead times in hours, e.g., {[}“24”, “48”, …, “5160”{]}.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{year\_start\_hindcast}} (int): Start year for hindcast data.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{year\_end\_hindcast}} (int): End year for hindcast data.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{area}} (list): Bounding box as {[}North, West, South, East{]} for clipping.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{year\_forecast}} (int, optional): Forecast year if downloading forecast data. Defaults to None.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{ensemble\_mean}} (str, optional): Can be “mean”, “median”, or None. Defaults to None.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{force\_download}} (bool): If True, forces download even if file exists.

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Available centers and variables:}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Centers:} ECMWF\_51, UKMO\_604, UKMO\_603, METEOFRANCE\_8, DWD\_21, DWD\_22, CMCC\_35, NCEP\_2, JMA\_3, ECCC\_4, ECCC\_5

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Variables:} PRCP, TEMP, TMAX, TMIN, UGRD10, VGRD10, SST, SLP, DSWR, DLWR, HUSS\_1000, HUSS\_925, HUSS\_850, UGRD\_1000, UGRD\_925, UGRD\_850, VGRD\_1000, VGRD\_925, VGRD\_850

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Example:}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from}\PYG{+w}{ }\PYG{n+nn}{wass2s}\PYG{+w}{ }\PYG{k+kn}{import} \PYG{o}{*}

\PYG{n}{downloader} \PYG{o}{=} \PYG{n}{WAS\PYGZus{}Download}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{downloader}\PYG{o}{.}\PYG{n}{WAS\PYGZus{}Download\PYGZus{}Models\PYGZus{}Daily}\PYG{p}{(}
    \PYG{n}{dir\PYGZus{}to\PYGZus{}save}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{/path/to/save}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{n}{center\PYGZus{}variable}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{ECMWF\PYGZus{}51.PRCP}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{,}
    \PYG{n}{month\PYGZus{}of\PYGZus{}initialization}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{01}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{n}{day\PYGZus{}of\PYGZus{}initialization}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{01}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{n}{leadtime\PYGZus{}hour}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{24}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{48}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{72}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{,}
    \PYG{n}{year\PYGZus{}start\PYGZus{}hindcast}\PYG{o}{=}\PYG{l+m+mi}{1993}\PYG{p}{,}
    \PYG{n}{year\PYGZus{}end\PYGZus{}hindcast}\PYG{o}{=}\PYG{l+m+mi}{2016}\PYG{p}{,}
    \PYG{n}{area}\PYG{o}{=}\PYG{p}{[}\PYG{l+m+mi}{60}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{180}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{60}\PYG{p}{,} \PYG{l+m+mi}{180}\PYG{p}{]}\PYG{p}{,}
    \PYG{n}{force\PYGZus{}download}\PYG{o}{=}\PYG{k+kc}{False}
\PYG{p}{)}
\end{sphinxVerbatim}


\subsection{Download reanalysis data}
\label{\detokenize{Download:download-reanalysis-data}}
\sphinxAtStartPar
The \sphinxcode{\sphinxupquote{WAS\_Download\_Reanalysis}} method downloads reanalysis data for specified center\sphinxhyphen{}variable combinations, years, and months, handling cross\sphinxhyphen{}year seasons.

\sphinxAtStartPar
\sphinxstylestrong{Parameters:}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{dir\_to\_save}} (str): Directory to save the downloaded files.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{center\_variable}} (list): List of center\sphinxhyphen{}variable identifiers, e.g., {[}“ERA5.PRCP”, “MERRA2.TEMP”{]}.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{year\_start}} (int): Start year for the data to download.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{year\_end}} (int): End year for the data to download.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{area}} (list): Bounding box as {[}North, West, South, East{]} for clipping.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{seas}} (list): List of month strings representing the season, e.g., {[}“11”, “12”, “01”{]} for NDJ.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{force\_download}} (bool): If True, forces download even if file exists.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{run\_avg}} (int): Number of months for running average (default=3).

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Available centers and variables:}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Centers:} ERA5, MERRA2, NOAA (for SST)

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Variables:} PRCP, TEMP, TMAX, TMIN, UGRD10, VGRD10, SST, SLP, DSWR, DLWR, HUSS\_1000, HUSS\_925, HUSS\_850, UGRD\_1000, UGRD\_925, UGRD\_850, VGRD\_1000, VGRD\_925, VGRD\_850

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Example:}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from}\PYG{+w}{ }\PYG{n+nn}{wass2s}\PYG{+w}{ }\PYG{k+kn}{import} \PYG{o}{*}

\PYG{n}{downloader} \PYG{o}{=} \PYG{n}{WAS\PYGZus{}Download}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{downloader}\PYG{o}{.}\PYG{n}{WAS\PYGZus{}Download\PYGZus{}Reanalysis}\PYG{p}{(}
    \PYG{n}{dir\PYGZus{}to\PYGZus{}save}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{/path/to/save}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{n}{center\PYGZus{}variable}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{ERA5.PRCP}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{,}
    \PYG{n}{year\PYGZus{}start}\PYG{o}{=}\PYG{l+m+mi}{1993}\PYG{p}{,}
    \PYG{n}{year\PYGZus{}end}\PYG{o}{=}\PYG{l+m+mi}{2016}\PYG{p}{,}
    \PYG{n}{area}\PYG{o}{=}\PYG{p}{[}\PYG{l+m+mi}{60}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{180}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{60}\PYG{p}{,} \PYG{l+m+mi}{180}\PYG{p}{]}\PYG{p}{,}
    \PYG{n}{seas}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{11}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{12}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{01}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{,}
    \PYG{n}{force\PYGZus{}download}\PYG{o}{=}\PYG{k+kc}{False}
\PYG{p}{)}
\end{sphinxVerbatim}


\subsection{Download observational data}
\label{\detokenize{Download:download-observational-data}}
\sphinxAtStartPar
Observational data includes agro\sphinxhyphen{}meteorological indicators and satellite\sphinxhyphen{}based precipitation data like CHIRPS.


\subsubsection{Agro\sphinxhyphen{}meteorological indicators}
\label{\detokenize{Download:agro-meteorological-indicators}}
\sphinxAtStartPar
The \sphinxcode{\sphinxupquote{WAS\_Download\_AgroIndicators}} method downloads agro\sphinxhyphen{}meteorological indicators for specified variables, years, and months, handling cross\sphinxhyphen{}year seasons.

\sphinxAtStartPar
\sphinxstylestrong{Parameters:}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{dir\_to\_save}} (str): Directory to save the downloaded files.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{variables}} (list): List of shorthand variables, e.g., {[}“AGRO.PRCP”, “AGRO.TMAX”{]}.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{year\_start}} (int): Start year for the data to download.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{year\_end}} (int): End year for the data to download.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{area}} (list): Bounding box as {[}North, West, South, East{]} for clipping.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{seas}} (list): List of month strings representing the season, e.g., {[}“11”, “12”, “01”{]} for NDJ.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{force\_download}} (bool): If True, forces download even if file exists.

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Available variables:}
\begin{itemize}
\item {} 
\sphinxAtStartPar
AGRO.PRCP: precipitation\_flux

\item {} 
\sphinxAtStartPar
AGRO.TMAX: 2m\_temperature (24\_hour\_maximum)

\item {} 
\sphinxAtStartPar
AGRO.TEMP: 2m\_temperature (24\_hour\_mean)

\item {} 
\sphinxAtStartPar
AGRO.TMIN: 2m\_temperature (24\_hour\_minimum)

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Example:}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from}\PYG{+w}{ }\PYG{n+nn}{wass2s}\PYG{+w}{ }\PYG{k+kn}{import} \PYG{o}{*}

\PYG{n}{downloader} \PYG{o}{=} \PYG{n}{WAS\PYGZus{}Download}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{downloader}\PYG{o}{.}\PYG{n}{WAS\PYGZus{}Download\PYGZus{}AgroIndicators}\PYG{p}{(}
    \PYG{n}{dir\PYGZus{}to\PYGZus{}save}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{/path/to/save}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{n}{variables}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{AGRO.PRCP}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{,}
    \PYG{n}{year\PYGZus{}start}\PYG{o}{=}\PYG{l+m+mi}{1993}\PYG{p}{,}
    \PYG{n}{year\PYGZus{}end}\PYG{o}{=}\PYG{l+m+mi}{2016}\PYG{p}{,}
    \PYG{n}{area}\PYG{o}{=}\PYG{p}{[}\PYG{l+m+mi}{60}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{180}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{60}\PYG{p}{,} \PYG{l+m+mi}{180}\PYG{p}{]}\PYG{p}{,}
    \PYG{n}{seas}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{11}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{12}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{01}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{,}
    \PYG{n}{force\PYGZus{}download}\PYG{o}{=}\PYG{k+kc}{False}
\PYG{p}{)}
\end{sphinxVerbatim}


\subsubsection{Download daily agro\sphinxhyphen{}meteorological indicators}
\label{\detokenize{Download:download-daily-agro-meteorological-indicators}}
\sphinxAtStartPar
The \sphinxcode{\sphinxupquote{WAS\_Download\_AgroIndicators\_daily}} method downloads daily agro\sphinxhyphen{}meteorological indicators for specified variables and years.

\sphinxAtStartPar
\sphinxstylestrong{Parameters:}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{dir\_to\_save}} (str): Directory to save the downloaded files.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{variables}} (list): List of shorthand variables, e.g., {[}“AGRO.PRCP”, “AGRO.TMAX”{]}.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{year\_start}} (int): Start year for the data to download.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{year\_end}} (int): End year for the data to download.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{area}} (list): Bounding box as {[}North, West, South, East{]} for clipping.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{force\_download}} (bool): If True, forces download even if file exists.

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Available variables:}
\begin{itemize}
\item {} 
\sphinxAtStartPar
AGRO.PRCP: precipitation\_flux

\item {} 
\sphinxAtStartPar
AGRO.TMAX: 2m\_temperature (24\_hour\_maximum)

\item {} 
\sphinxAtStartPar
AGRO.TEMP: 2m\_temperature (24\_hour\_mean)

\item {} 
\sphinxAtStartPar
AGRO.TMIN: 2m\_temperature (24\_hour\_minimum)

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Example:}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from}\PYG{+w}{ }\PYG{n+nn}{wass2s}\PYG{+w}{ }\PYG{k+kn}{import} \PYG{o}{*}

\PYG{n}{downloader} \PYG{o}{=} \PYG{n}{WAS\PYGZus{}Download}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{downloader}\PYG{o}{.}\PYG{n}{WAS\PYGZus{}Download\PYGZus{}AgroIndicators\PYGZus{}daily}\PYG{p}{(}
    \PYG{n}{dir\PYGZus{}to\PYGZus{}save}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{/path/to/save}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{n}{variables}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{AGRO.PRCP}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{,}
    \PYG{n}{year\PYGZus{}start}\PYG{o}{=}\PYG{l+m+mi}{1993}\PYG{p}{,}
    \PYG{n}{year\PYGZus{}end}\PYG{o}{=}\PYG{l+m+mi}{2016}\PYG{p}{,}
    \PYG{n}{area}\PYG{o}{=}\PYG{p}{[}\PYG{l+m+mi}{60}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{180}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{60}\PYG{p}{,} \PYG{l+m+mi}{180}\PYG{p}{]}\PYG{p}{,}
    \PYG{n}{force\PYGZus{}download}\PYG{o}{=}\PYG{k+kc}{False}
\PYG{p}{)}
\end{sphinxVerbatim}


\subsubsection{CHIRPS precipitation data}
\label{\detokenize{Download:chirps-precipitation-data}}
\sphinxAtStartPar
The \sphinxcode{\sphinxupquote{WAS\_Download\_CHIRPSv3}} method downloads CHIRPS v3.0 monthly precipitation data for a specified cross\sphinxhyphen{}year season.

\sphinxAtStartPar
\sphinxstylestrong{Parameters:}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{dir\_to\_save}} (str): Directory to save the downloaded files.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{variables}} (list): List of variables, typically {[}“PRCP”{]}.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{year\_start}} (int): Start year for the data to download.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{year\_end}} (int): End year for the data to download.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{area}} (list, optional): Bounding box as {[}North, West, South, East{]} for clipping.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{season\_months}} (list): List of month strings representing the season, e.g., {[}“03”, “04”, “05”{]} for MAM.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{force\_download}} (bool): If True, forces download even if file exists.

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Note:} CHIRPS data is available for land areas between 50°S and 50°N.

\sphinxAtStartPar
\sphinxstylestrong{Example:}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from}\PYG{+w}{ }\PYG{n+nn}{wass2s}\PYG{+w}{ }\PYG{k+kn}{import} \PYG{o}{*}

\PYG{n}{downloader} \PYG{o}{=} \PYG{n}{WAS\PYGZus{}Download}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{downloader}\PYG{o}{.}\PYG{n}{WAS\PYGZus{}Download\PYGZus{}CHIRPSv3}\PYG{p}{(}
    \PYG{n}{dir\PYGZus{}to\PYGZus{}save}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{/path/to/save}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{n}{variables}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{PRCP}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{,}
    \PYG{n}{year\PYGZus{}start}\PYG{o}{=}\PYG{l+m+mi}{1993}\PYG{p}{,}
    \PYG{n}{year\PYGZus{}end}\PYG{o}{=}\PYG{l+m+mi}{2016}\PYG{p}{,}
    \PYG{n}{area}\PYG{o}{=}\PYG{p}{[}\PYG{l+m+mi}{15}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{20}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{5}\PYG{p}{,} \PYG{l+m+mi}{20}\PYG{p}{]}\PYG{p}{,}  \PYG{c+c1}{\PYGZsh{} Example for Africa}
    \PYG{n}{season\PYGZus{}months}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{03}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{04}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{05}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{,}
    \PYG{n}{force\PYGZus{}download}\PYG{o}{=}\PYG{k+kc}{False}
\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxstepscope


\section{Processing Modules}
\label{\detokenize{Processing:processing-modules}}\label{\detokenize{Processing::doc}}
\sphinxAtStartPar
The Processing modules provide tools for computing various climate indices or predictands from daily data, such as onset and cessation of the rainy season, dry and wet spells, number of rainy days, extreme precipitation indices, and heat wave indices. Additionally, it offers methods for merging or adjusting gridded data with station observations to correct biases.

\sphinxAtStartPar
These modules are divided into two main parts:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Computing Predictands}: Classes for calculating different climate indices from daily data.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Merging and Adjusting Data}: Classes for combining gridded data with station observations to improve accuracy.

\end{enumerate}

\sphinxAtStartPar
\sphinxstylestrong{Prerequisites}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Dask}: Required for parallel processing in gridded data computations.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Data Formats}: Gridded data should be in xarray DataArray format with coordinates (T, Y, X). Station data should be in CDT format for daily data or CPT format for seasonal aggregation before merging.

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Climate Data Tools (CDT)}: Format for daily data.


\begin{savenotes}\sphinxattablestart
\sphinxthistablewithglobalstyle
\centering
\begin{tabulary}{\linewidth}[t]{TTT}
\sphinxtoprule
\sphinxstyletheadfamily 
\sphinxAtStartPar
ID
&\sphinxstyletheadfamily 
\sphinxAtStartPar
ALLADA
&\sphinxstyletheadfamily 
\sphinxAtStartPar
APLAHOUE
\\
\sphinxmidrule
\sphinxtableatstartofbodyhook
\sphinxAtStartPar
LON
&
\sphinxAtStartPar
2.133333
&
\sphinxAtStartPar
1.666667
\\
\sphinxhline
\sphinxAtStartPar
LAT
&
\sphinxAtStartPar
6.65
&
\sphinxAtStartPar
6.916667
\\
\sphinxhline
\sphinxAtStartPar
DAILY/ELEV
&
\sphinxAtStartPar
92.0
&
\sphinxAtStartPar
153.0
\\
\sphinxhline
\sphinxAtStartPar
19810101
&
\sphinxAtStartPar
0.0
&
\sphinxAtStartPar
0.0
\\
\sphinxhline
\sphinxAtStartPar
19810102
&
\sphinxAtStartPar
0.0
&
\sphinxAtStartPar
0.0
\\
\sphinxhline
\sphinxAtStartPar
19810103
&
\sphinxAtStartPar
0.0
&
\sphinxAtStartPar
0.0
\\
\sphinxhline
\sphinxAtStartPar
19810104
&
\sphinxAtStartPar
0.0
&
\sphinxAtStartPar
0.0
\\
\sphinxhline
\sphinxAtStartPar
19810105
&
\sphinxAtStartPar
0.0
&
\sphinxAtStartPar
0.0
\\
\sphinxhline
\sphinxAtStartPar
19810106
&
\sphinxAtStartPar
0.0
&
\sphinxAtStartPar
0.0
\\
\sphinxhline
\sphinxAtStartPar
19810107
&
\sphinxAtStartPar
0.0
&
\sphinxAtStartPar
0.0
\\
\sphinxhline
\sphinxAtStartPar
19810108
&
\sphinxAtStartPar
0.0
&
\sphinxAtStartPar
0.0
\\
\sphinxhline
\sphinxAtStartPar
19810109
&
\sphinxAtStartPar
0.0
&
\sphinxAtStartPar
0.0
\\
\sphinxhline
\sphinxAtStartPar
19810110
&
\sphinxAtStartPar
0.0
&
\sphinxAtStartPar
0.0
\\
\sphinxhline
\sphinxAtStartPar
…
&&\\
\sphinxbottomrule
\end{tabulary}
\sphinxtableafterendhook\par
\sphinxattableend\end{savenotes}

\sphinxAtStartPar
\sphinxstylestrong{Climate Prediction Tools (CPT)}: Format for seasonal aggregation (used in climate prediction tools) before merging.


\begin{savenotes}\sphinxattablestart
\sphinxthistablewithglobalstyle
\centering
\begin{tabulary}{\linewidth}[t]{TTTT}
\sphinxtoprule
\sphinxstyletheadfamily 
\sphinxAtStartPar
STATION
&\sphinxstyletheadfamily 
\sphinxAtStartPar
ABEO
&\sphinxstyletheadfamily 
\sphinxAtStartPar
ABUJ
&\sphinxstyletheadfamily 
\sphinxAtStartPar
ADEK
\\
\sphinxmidrule
\sphinxtableatstartofbodyhook
\sphinxAtStartPar
LAT
&
\sphinxAtStartPar
7.2
&
\sphinxAtStartPar
7.6
&
\sphinxAtStartPar
9.0
\\
\sphinxhline
\sphinxAtStartPar
LON
&
\sphinxAtStartPar
3.3
&
\sphinxAtStartPar
5.2
&
\sphinxAtStartPar
7.2
\\
\sphinxhline
\sphinxAtStartPar
1991
&
\sphinxAtStartPar
514.9
&
\sphinxAtStartPar
715.1
&
\sphinxAtStartPar
934.3
\\
\sphinxhline
\sphinxAtStartPar
1992
&
\sphinxAtStartPar
503.6
&
\sphinxAtStartPar
736.4
&
\sphinxAtStartPar
714.6
\\
\sphinxhline
\sphinxAtStartPar
1993
&
\sphinxAtStartPar
414.6
&
\sphinxAtStartPar
891.0
&
\sphinxAtStartPar
709.6
\\
\sphinxhline
\sphinxAtStartPar
1994
&
\sphinxAtStartPar
345.6
&
\sphinxAtStartPar
1034.7
&
\sphinxAtStartPar
491.7
\\
\sphinxhline
\sphinxAtStartPar
1995
&
\sphinxAtStartPar
492.2
&
\sphinxAtStartPar
837.6
&
\sphinxAtStartPar
938.8
\\
\sphinxhline
\sphinxAtStartPar
…
&&&\\
\sphinxbottomrule
\end{tabulary}
\sphinxtableafterendhook\par
\sphinxattableend\end{savenotes}


\subsection{Computing Predictands}
\label{\detokenize{Processing:computing-predictands}}
\sphinxAtStartPar
This section includes classes for computing various climate indices:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{WAS\_compute\_onset}}: Computes the onset of the rainy season.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{WAS\_compute\_cessation}}: Computes the cessation of the rainy season.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{WAS\_compute\_onset\_dry\_spell}}: Computes the longest dry spell after the onset.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{WAS\_compute\_cessation\_dry\_spell}}: Computes the longest dry spell in flourishing period.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{WAS\_count\_wet\_spells}}: Computes the number of wet spells between onset and cessation.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{WAS\_count\_dry\_spells}}: Computes the number of dry spells between onset and cessation.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{WAS\_count\_rainy\_days}}: Computes the number of rainy days between onset and cessation.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{WAS\_r95\_99p}}: Computes extreme precipitation indices R95p and R99p.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{WAS\_compute\_HWSDI}}: Computes the Heat Wave Severity Duration Index.

\end{itemize}

\sphinxAtStartPar
Each class has methods for computing the index from gridded data (\sphinxcode{\sphinxupquote{compute}}) and, where applicable, from station data in CDT format (\sphinxcode{\sphinxupquote{compute\_insitu}}).

\sphinxAtStartPar
\sphinxstylestrong{Onset Computation}

\sphinxAtStartPar
The \sphinxcode{\sphinxupquote{WAS\_compute\_onset}} class computes the onset of the rainy season based on user\sphinxhyphen{}defined or default criteria for different zones.

\sphinxAtStartPar
\sphinxstylestrong{Initialization}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{\_\_init\_\_(self, user\_criteria=None)}}: Initializes the class with user\sphinxhyphen{}defined criteria. If not provided, default criteria are used.

\item {} 
\sphinxAtStartPar
Dictionaries \sphinxcode{\sphinxupquote{onset\_criteria}},  \sphinxcode{\sphinxupquote{cessation\_criteria}}, \sphinxcode{\sphinxupquote{onset\_dryspell\_criteria}}, \sphinxcode{\sphinxupquote{cessation\_dryspell\_criteria}} show how to define the criteria for onset, cessation, onset dry spell and cessation dry spell computations.

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Methods}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{compute(self, daily\_data, nb\_cores)}}: Computes onset dates for gridded daily rainfall data.
* \sphinxcode{\sphinxupquote{daily\_data}}: xarray DataArray with daily rainfall data (coords: T, Y, X).
* \sphinxcode{\sphinxupquote{nb\_cores}}: Number of CPU cores for parallel processing.
* Returns: xarray DataArray with onset dates.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{compute\_insitu(self, daily\_df)}}: Computes onset dates for station data in CDT format.
* \sphinxcode{\sphinxupquote{daily\_df}}: pandas DataFrame in CDT format.
* Returns: pandas DataFrame in CPT format with onset dates.

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Criteria Dictionary}

\sphinxAtStartPar
The criteria dictionary defines parameters for onset computation:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{p}{\PYGZob{}}
    \PYG{l+m+mi}{0}\PYG{p}{:} \PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{zone\PYGZus{}name}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Sahel100\PYGZus{}0mm}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{start\PYGZus{}search}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{06\PYGZhy{}01}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{cumulative}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+m+mi}{10}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{number\PYGZus{}dry\PYGZus{}days}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+m+mi}{25}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{thrd\PYGZus{}rain\PYGZus{}day}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+m+mf}{0.85}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{end\PYGZus{}search}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{08\PYGZhy{}30}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{\PYGZcb{}}\PYG{p}{,}
    \PYG{l+m+mi}{1}\PYG{p}{:} \PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{zone\PYGZus{}name}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Sahel200\PYGZus{}100mm}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{start\PYGZus{}search}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{05\PYGZhy{}15}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{cumulative}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+m+mi}{15}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{number\PYGZus{}dry\PYGZus{}days}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+m+mi}{25}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{thrd\PYGZus{}rain\PYGZus{}day}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+m+mf}{0.85}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{end\PYGZus{}search}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{08\PYGZhy{}15}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{\PYGZcb{}}\PYG{p}{,}
    \PYG{o}{.}\PYG{o}{.}\PYG{o}{.}
\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{zone\_name}}: Name of the zone.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{start\_search}}: Start date for searching the onset (e.g., “06\sphinxhyphen{}01”).

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{cumulative}}: Cumulative rainfall threshold (mm).

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{number\_dry\_days}}: Maximum number of dry days allowed after onset.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{thrd\_rain\_day}}: Rainfall threshold to consider a day as rainy (mm).

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{end\_search}}: End date for searching the onset.

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Example}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from}\PYG{+w}{ }\PYG{n+nn}{wass2s}\PYG{+w}{ }\PYG{k+kn}{import} \PYG{o}{*}
\PYG{c+c1}{\PYGZsh{} Download daily rainfall data}
\PYG{n}{downloader} \PYG{o}{=} \PYG{n}{WAS\PYGZus{}Download}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{downloader}\PYG{o}{.}\PYG{n}{WAS\PYGZus{}Download\PYGZus{}AgroIndicators\PYGZus{}daily}\PYG{p}{(}
    \PYG{n}{dir\PYGZus{}to\PYGZus{}save}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{/path/to/save}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{n}{variables}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{AGRO.PRCP}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{,}
    \PYG{n}{year\PYGZus{}start}\PYG{o}{=}\PYG{l+m+mi}{1993}\PYG{p}{,}
    \PYG{n}{year\PYGZus{}end}\PYG{o}{=}\PYG{l+m+mi}{2016}\PYG{p}{,}
    \PYG{n}{area}\PYG{o}{=}\PYG{p}{[}\PYG{l+m+mi}{60}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{180}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{60}\PYG{p}{,} \PYG{l+m+mi}{180}\PYG{p}{]}\PYG{p}{,}
    \PYG{n}{force\PYGZus{}download}\PYG{o}{=}\PYG{k+kc}{False}
\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Load daily rainfall data}
\PYG{n}{rainfall} \PYG{o}{=} \PYG{n}{prepare\PYGZus{}predictand}\PYG{p}{(}\PYG{n}{dir\PYGZus{}to\PYGZus{}save}\PYG{p}{,} \PYG{n}{variables}\PYG{p}{,} \PYG{n}{year\PYGZus{}start}\PYG{p}{,} \PYG{n}{year\PYGZus{}end}\PYG{p}{,} \PYG{n}{daily}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{ds}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} NB: prepare\PYGZus{}predictand is a utility function that loads the data and prepares it for the computation of the predictand.}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} ds is set to False because the data will be loaded as dataarray.}

\PYG{c+c1}{\PYGZsh{} Print predefined  onset criteria}
\PYG{n}{onset\PYGZus{}criteria}
\PYG{c+c1}{\PYGZsh{} Define user criteria}
\PYG{n}{user\PYGZus{}criteria} \PYG{o}{=} \PYG{n}{onset\PYGZus{}criteria}
\PYG{c+c1}{\PYGZsh{} adjust user criteria}
\PYG{n}{user\PYGZus{}criteria}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{start\PYGZus{}search}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{06\PYGZhy{}15}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{n}{user\PYGZus{}criteria}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{end\PYGZus{}search}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{09\PYGZhy{}01}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{c+c1}{\PYGZsh{} Compute onset}
\PYG{n}{was\PYGZus{}onset} \PYG{o}{=} \PYG{n}{WAS\PYGZus{}compute\PYGZus{}onset}\PYG{p}{(}\PYG{n}{user\PYGZus{}criteria}\PYG{p}{)}
\PYG{n}{onset} \PYG{o}{=} \PYG{n}{was\PYGZus{}onset}\PYG{o}{.}\PYG{n}{compute}\PYG{p}{(}\PYG{n}{daily\PYGZus{}data}\PYG{o}{=}\PYG{n}{rainfall}\PYG{p}{,} \PYG{n}{nb\PYGZus{}cores}\PYG{o}{=}\PYG{l+m+mi}{4}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{} Plot the mean onset date to check the results}
\PYG{n}{plot\PYGZus{}date}\PYG{p}{(}\PYG{n}{onset}\PYG{o}{.}\PYG{n}{mean}\PYG{p}{(}\PYG{n}{dim}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{T}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
\sphinxstylestrong{Cessation Computation}

\sphinxAtStartPar
The \sphinxcode{\sphinxupquote{WAS\_compute\_cessation}} class computes the cessation of the rainy season based on soil moisture balance criteria.
\begin{itemize}
\item {} 
\sphinxAtStartPar
Similar initialization and methods as \sphinxcode{\sphinxupquote{WAS\_compute\_onset}} with criteria including:
* \sphinxcode{\sphinxupquote{date\_dry\_soil}}: Date when soil is assumed dry (e.g., “01\sphinxhyphen{}01”).
* \sphinxcode{\sphinxupquote{ETP}}: Evapotranspiration rate (mm/day).
* \sphinxcode{\sphinxupquote{Cap\_ret\_maxi}}: Maximum soil water retention capacity (mm).

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Dry Spell Computation}

\sphinxAtStartPar
The \sphinxcode{\sphinxupquote{WAS\_compute\_onset\_dry\_spell}} class computes the longest dry spell after the onset.
\begin{itemize}
\item {} 
\sphinxAtStartPar
Includes an additional \sphinxcode{\sphinxupquote{nbjour}} parameter in the criteria for the number of days to check after onset.

\end{itemize}

\sphinxAtStartPar
The \sphinxcode{\sphinxupquote{WAS\_compute\_cessation\_dry\_spell}} class computes the longest dry spell in flourishing period.
\begin{itemize}
\item {} 
\sphinxAtStartPar
Includes an additional \sphinxcode{\sphinxupquote{nbjour}} parameter in the criteria for the number of days to check after cessation.

\end{itemize}

\sphinxAtStartPar
The \sphinxcode{\sphinxupquote{WAS\_count\_dry\_spells}} class computes the number of dry spells between onset and cessation. Requires onset and cessation dates as inputs.

\sphinxAtStartPar
\sphinxstylestrong{Wet Spell Computation}

\sphinxAtStartPar
The \sphinxcode{\sphinxupquote{WAS\_count\_wet\_spells}} class computes the number of wet spells between onset and cessation. Requires onset and cessation dates as inputs.

\sphinxAtStartPar
\sphinxstylestrong{Rainy Days Computation}

\sphinxAtStartPar
The \sphinxcode{\sphinxupquote{WAS\_count\_rainy\_days}} class computes the number of rainy days between onset and cessation. Requires onset and cessation dates as inputs.

\sphinxAtStartPar
\sphinxstylestrong{Extreme Precipitation Indices}

\sphinxAtStartPar
The \sphinxcode{\sphinxupquote{WAS\_r95\_99p}} class computes R95p and R99p indices. Initialization with a base period (e.g., \sphinxcode{\sphinxupquote{slice("1991\sphinxhyphen{}01\sphinxhyphen{}01", "2020\sphinxhyphen{}12\sphinxhyphen{}31")}}) and optional season (list of months).
\begin{itemize}
\item {} 
\sphinxAtStartPar
Methods:
* \sphinxcode{\sphinxupquote{compute\_r95p}} and \sphinxcode{\sphinxupquote{compute\_r99p}} for gridded data.
* \sphinxcode{\sphinxupquote{compute\_insitu\_r95p}} and \sphinxcode{\sphinxupquote{compute\_insitu\_r99p}} for station data.

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Heat Wave Indices}

\sphinxAtStartPar
The \sphinxcode{\sphinxupquote{WAS\_compute\_HWSDI}} class computes the Heat Wave Severity Duration Index. Computes TXin90 (90th percentile of daily max temperature) and counts heatwave days with at least 6 consecutive hot days.


\subsection{Merging and Adjusting Data}
\label{\detokenize{Processing:merging-and-adjusting-data}}
\sphinxAtStartPar
The \sphinxcode{\sphinxupquote{WAS\_Merging}} class provides methods for merging gridded data with station observations to adjust for biases.

\sphinxAtStartPar
\sphinxstylestrong{Initialization}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{\_\_init\_\_(self, df, da, date\_month\_day="08\sphinxhyphen{}01")}}: Initializes with station data DataFrame (CPT format), gridded data DataArray, and a date string.

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Methods}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{simple\_bias\_adjustment(self, missing\_value=\sphinxhyphen{}999.0, do\_cross\_validation=False)}}: Adjusts gridded data using kriging of residuals.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{regression\_kriging(self, missing\_value=\sphinxhyphen{}999.0, do\_cross\_validation=False)}}: Uses linear regression followed by kriging of residuals.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{neural\_network\_kriging(self, missing\_value=\sphinxhyphen{}999.0, do\_cross\_validation=False)}}: Uses a neural network followed by kriging of residuals.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{multiplicative\_bias(self, missing\_value=\sphinxhyphen{}999.0, do\_cross\_validation=False)}}: Applies a multiplicative bias correction.

\end{itemize}

\sphinxAtStartPar
Each method returns the adjusted gridded data as an xarray DataArray and optionally cross\sphinxhyphen{}validation results as a DataFrame.
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{plot\_merging\_comparaison(self, df\_Obs, da\_estimated, da\_corrected, missing\_value=\sphinxhyphen{}999.0)}}: Visualizes the comparison between observations, original estimates, and corrected data.

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Example: Merging Onset with Station Observations}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Load station onset data in CPT format}
\PYG{n}{cpt\PYGZus{}input\PYGZus{}file\PYGZus{}path} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{./path/to/cpt\PYGZus{}file.csv}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{n}{df} \PYG{o}{=} \PYG{n}{pd}\PYG{o}{.}\PYG{n}{read\PYGZus{}csv}\PYG{p}{(}\PYG{n}{cpt\PYGZus{}input\PYGZus{}file\PYGZus{}path}\PYG{p}{,} \PYG{n}{na\PYGZus{}values}\PYG{o}{=}\PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{999.0}\PYG{p}{,} \PYG{n}{encoding}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{latin1}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Filter for relevant years and stations}
\PYG{n}{year\PYGZus{}start}\PYG{p}{,} \PYG{n}{year\PYGZus{}end} \PYG{o}{=} \PYG{l+m+mi}{1981}\PYG{p}{,} \PYG{l+m+mi}{2020}  \PYG{c+c1}{\PYGZsh{} Example years}
\PYG{n}{onset\PYGZus{}df} \PYG{o}{=} \PYG{n}{df}\PYG{p}{[}\PYG{p}{(}\PYG{n}{df}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{STATION}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{==} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{LAT}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)} \PYG{o}{|} \PYG{p}{(}\PYG{n}{df}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{STATION}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{==} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{LON}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)} \PYG{o}{|}
              \PYG{p}{(}\PYG{n}{pd}\PYG{o}{.}\PYG{n}{to\PYGZus{}numeric}\PYG{p}{(}\PYG{n}{df}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{STATION}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{,} \PYG{n}{errors}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{coerce}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{between}\PYG{p}{(}\PYG{n}{year\PYGZus{}start}\PYG{p}{,} \PYG{n}{year\PYGZus{}end}\PYG{p}{)}\PYG{p}{)}\PYG{p}{]}

\PYG{c+c1}{\PYGZsh{} Verify station network}
\PYG{n}{verify\PYGZus{}station\PYGZus{}network}\PYG{p}{(}\PYG{n}{onset\PYGZus{}df}\PYG{p}{,} \PYG{n}{area}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} NB: verify\PYGZus{}station\PYGZus{}network is a utility function that verifies the station network. area is the extent of the gridded onset domain.}

\PYG{c+c1}{\PYGZsh{} Instantiate WAS\PYGZus{}Merging}
\PYG{n}{data\PYGZus{}merger} \PYG{o}{=} \PYG{n}{WAS\PYGZus{}Merging}\PYG{p}{(}\PYG{n}{onset\PYGZus{}df}\PYG{p}{,} \PYG{n}{onset}\PYG{p}{,} \PYG{n}{date\PYGZus{}month\PYGZus{}day}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{02\PYGZhy{}01}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} NB: date\PYGZus{}month\PYGZus{}day is set to \PYGZsq{}02\PYGZhy{}01\PYGZsq{} because the onset start\PYGZus{}search criteria is set to the month of February.}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} Important to verify the T dimension in the gridded onset computed. the month and day must match the date\PYGZus{}month\PYGZus{}day.}

\PYG{c+c1}{\PYGZsh{} Perform simple bias adjustment}
\PYG{n}{onset\PYGZus{}adjusted}\PYG{p}{,} \PYG{n}{\PYGZus{}} \PYG{o}{=} \PYG{n}{data\PYGZus{}merger}\PYG{o}{.}\PYG{n}{simple\PYGZus{}bias\PYGZus{}adjustment}\PYG{p}{(}\PYG{n}{do\PYGZus{}cross\PYGZus{}validation}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Plot comparison}
\PYG{n}{data\PYGZus{}merger}\PYG{o}{.}\PYG{n}{plot\PYGZus{}merging\PYGZus{}comparaison}\PYG{p}{(}\PYG{n}{onset\PYGZus{}df}\PYG{p}{,} \PYG{n}{onset}\PYG{p}{,} \PYG{n}{onset\PYGZus{}adjusted}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} NB: plot\PYGZus{}merging\PYGZus{}comparaison is a utility function that plots the comparison between the station onset, the gridded onset and the adjusted onset.}
\end{sphinxVerbatim}

\sphinxstepscope


\section{Quantifying uncertainty via cross\sphinxhyphen{}validation}
\label{\detokenize{cv:quantifying-uncertainty-via-cross-validation}}\label{\detokenize{cv::doc}}
\sphinxAtStartPar
Cross\sphinxhyphen{}validation schemes are used to assess model performance and to quantify uncertainty. \sphinxtitleref{wass2s} uses a cross\sphinxhyphen{}validation scheme that splits the data into training, omit, and test periods. The scheme is a variation of the \sphinxtitleref{K\sphinxhyphen{}Fold} cross\sphinxhyphen{}validation scheme, but it is tailored for time series data throughout \sphinxtitleref{CustomTimeSeriesSplit} and \sphinxtitleref{WAS\_Cross\_Validator} class. The scheme is illustrated in the figure below (Figure 1).

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.7]{{cvv}.png}
\caption{Cross\sphinxhyphen{}validation scheme used in wass2s}\label{\detokenize{cv:id1}}\end{figure}

\sphinxAtStartPar
The figure shows how we split our data (1981\textendash{}2010) to validate the model. Each row is a “fold” or a test run.
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Pink (Training)}: Years we use to train the model. For example, in the first row, we train on 1986\textendash{}2010.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Yellow (Omit)}: A buffer years we skip to avoid cheating. Climate data has patterns over time, so we don’t want to train on a years right after/before the one we’re predicting, which would make the model look better than it really is. In this case we’ve omitted four years (in the first row, we skip 1982\sphinxhyphen{}1985).

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{White (Predict)}: The year we predict. In the first row, we predict 1981.

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{CustomTimeSeriesSplit}

\sphinxAtStartPar
A custom splitter for time series data that accounts for temporal dependencies.

\sphinxAtStartPar
\sphinxstylestrong{Initialization}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxtitleref{n\_splits}: Number of splits for cross\sphinxhyphen{}validation.

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Methods}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxtitleref{split}: Generates indices for training and test sets, omitting a specified number of samples after the test index.

\item {} 
\sphinxAtStartPar
\sphinxtitleref{get\_n\_splits}: Returns the number of splits.

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{WAS\_Cross\_Validator}

\sphinxAtStartPar
A wrapper class that uses the custom splitter to perform cross\sphinxhyphen{}validation with various models.

\sphinxAtStartPar
\sphinxstylestrong{Initialization}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxtitleref{n\_splits}: Number of splits for cross\sphinxhyphen{}validation.

\item {} 
\sphinxAtStartPar
\sphinxtitleref{nb\_omit}: Number of samples to omit from training after the test index.

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Methods}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxtitleref{get\_model\_params}: Retrieves parameters for the model’s \sphinxtitleref{compute\_model} method.

\item {} 
\sphinxAtStartPar
\sphinxtitleref{cross\_validate}: Performs cross\sphinxhyphen{}validation and computes deterministic hindcast and tercile probabilities.

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Example Usage}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from}\PYG{+w}{ }\PYG{n+nn}{wass2s}\PYG{n+nn}{.}\PYG{n+nn}{was\PYGZus{}cross\PYGZus{}validate}\PYG{+w}{ }\PYG{k+kn}{import} \PYG{n}{WAS\PYGZus{}Cross\PYGZus{}Validator}

\PYG{c+c1}{\PYGZsh{} Initialize the cross\PYGZhy{}validator}
\PYG{n}{cv} \PYG{o}{=} \PYG{n}{WAS\PYGZus{}Cross\PYGZus{}Validator}\PYG{p}{(}\PYG{n}{n\PYGZus{}splits}\PYG{o}{=}\PYG{l+m+mi}{30}\PYG{p}{,} \PYG{n}{nb\PYGZus{}omit}\PYG{o}{=}\PYG{l+m+mi}{4}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
A better example will be provided in the next sections.


\subsection{Estimating Prediction Uncertainty}
\label{\detokenize{cv:estimating-prediction-uncertainty}}
\sphinxAtStartPar
The cross\sphinxhyphen{}validation makes out\sphinxhyphen{}of\sphinxhyphen{}sample predictions for each fold’s prediction period, and errors are calculated by comparing predictions to actual values. These errors are collected across all folds.
Running the statistical models—e.g. multiple linear regression—yields the most likely value of the predictand (best\sphinxhyphen{}guess) for the coming season.
Because seasonal outlooks are inherently probabilistic, we must go beyond this single best\sphinxhyphen{}guess and quantify the likelihood of other possible outcomes.
wass2s does so by analysing the cross\sphinxhyphen{}validation errors described earlier. The method explicitly takes the statistical distribution of the predictand into account.
If, for instance, the predictand is approximately Gaussian, we assume the predicted values follow a normal distribution whose mean is the single best\sphinxhyphen{}guess and whose variance equals the cross\sphinxhyphen{}validated error variance.
Comparing that forecast probability\sphinxhyphen{}density function with the climatological density (see the example in Figure 2) lets us integrate the areas that fall below\sphinxhyphen{}normal (values below the 1st tercile), near\sphinxhyphen{}normal (values between the 1st and 3rd terciles), and above\sphinxhyphen{}normal (values above the 3rd tercile).
These integrals are the tercile probabilities ultimately delivered to users.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.7]{{generation_proba}.png}
\caption{Figure 2: Generation of probabilistic forecasts}\label{\detokenize{cv:id2}}\end{figure}

\begin{sphinxadmonition}{important}{Important:}
\sphinxAtStartPar
Classification\sphinxhyphen{}based statistical models—such as logistic regression,
extended logistic regression, and support vector classification—do \sphinxstylestrong{not}
generate continuous probabilistic forecasts over a full distribution of outcomes as indicated above.
Instead, they classify the predictand into discrete categories based on
climatological terciles (below\sphinxhyphen{}normal, near\sphinxhyphen{}normal, above\sphinxhyphen{}normal) and
estimate the probability associated with each class.
\end{sphinxadmonition}

\sphinxstepscope


\section{Models Modules}
\label{\detokenize{Models:models-modules}}\label{\detokenize{Models::doc}}
\sphinxAtStartPar
The Models modules provide a comprehensive suite of statistical and machine learning models for climate prediction, including linear models, EOF\sphinxhyphen{}based models, canonical correlation analysis (CCA), analog methods, and multi\sphinxhyphen{}model ensemble (MME) techniques.
These models are designed to handle both deterministic and probabilistic forecasts, with support for hyperparameter tuning.
Models are evaluated using cross\sphinxhyphen{}validation schemes.

\sphinxAtStartPar
The models modules are organized into several classes, each implementing a specific type of model:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Machine Learning Models}: This includes linear models such as multiple linear regression, logistic regression and regularized models like ridge, lasso, elastic\sphinxhyphen{}net. Additionally, more advanced models are available, including support vector regression, random forests, XGBoost, and neural networks.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{EOF and PCR Models}: For dimensionality reduction and regression using principal components.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{CCA Models}: For identifying relationships between two multivariate datasets.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Analog Methods}: For finding historical analogs to current conditions.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Multi\sphinxhyphen{}Model Ensemble (MME) Techniques}: For combining predictions from multiple models.

\end{enumerate}


\subsection{Machine Learning Models}
\label{\detokenize{Models:machine-learning-models}}
\sphinxAtStartPar
The available models are:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxtitleref{WAS\_LinearRegression\_Model}:

\end{itemize}

\sphinxAtStartPar
Standard Multiple Linear Regression.
* \sphinxtitleref{WAS\_Ridge\_Model}: Ridge regression with L2 regularization.
* \sphinxtitleref{WAS\_Lasso\_Model}: Lasso regression with L1 regularization.
* \sphinxtitleref{WAS\_LassoLars\_Model}: Lasso regression using the LARS algorithm.
* \sphinxtitleref{WAS\_ElasticNet\_Model}: Elastic net regression combining L1 and L2 regularization.
* \sphinxtitleref{WAS\_LogisticRegression\_Model}: Logistic regression for classification.
* \sphinxtitleref{WAS\_SVR}: Support vector regression.
* \sphinxtitleref{WAS\_PolynomialRegression}: Polynomial regression.
* \sphinxtitleref{WAS\_PoissonRegression}: Poisson regression.
* \sphinxtitleref{WAS\_RandomForest\_XGBoost\_ML\_Stacking}: Random forest and XGBoost regression with stacking.
* \sphinxtitleref{WAS\_MLP}: Multi\sphinxhyphen{}Layer Perceptron regression.
* \sphinxtitleref{WAS\_RandomForest\_XGBoost\_Stacking\_MLP}: Random forest, XGBoost, and MLP regression with stacking.
* \sphinxtitleref{WAS\_Stacking\_Ridge}: Random forest, XGBoost, MLP, and Ridge regression with stacking.

\sphinxAtStartPar
Except for \sphinxtitleref{WAS\_LogisticRegression\_Model}, each model class includes methods for:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxtitleref{compute\_model}: Training the model and making predictions.

\item {} 
\sphinxAtStartPar
\sphinxtitleref{compute\_prob}: Computing tercile probabilities for the predictions.

\item {} 
\sphinxAtStartPar
\sphinxtitleref{forecast}: Making forecasts for new data.

\end{itemize}


\subsection{EOF and PCR Models}
\label{\detokenize{Models:eof-and-pcr-models}}
\sphinxAtStartPar
The \sphinxtitleref{was\_eof.py} and \sphinxtitleref{was\_pcr.py} modules provide classes for EOF analysis and Principal Component Regression (PCR), with support for multiple EOF zones:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxtitleref{WAS\_EOF}: Performs EOF analysis with options for cosine latitude weighting, standardization, and L2 normalization.

\item {} 
\sphinxAtStartPar
\sphinxtitleref{WAS\_PCR}: Combines EOF analysis with a regression model for prediction, supporting multiple EOF zones.

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{WAS\_EOF}

\sphinxAtStartPar
\sphinxstylestrong{Initialization}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxtitleref{n\_modes}: Number of EOF modes to retain.

\item {} 
\sphinxAtStartPar
\sphinxtitleref{use\_coslat}: Apply cosine latitude weighting (default: True).

\item {} 
\sphinxAtStartPar
\sphinxtitleref{standardize}: Standardize the input data (default: False).

\item {} 
\sphinxAtStartPar
\sphinxtitleref{opti\_explained\_variance}: Target cumulative explained variance to determine modes.

\item {} 
\sphinxAtStartPar
\sphinxtitleref{L2norm}: Normalize components and scores to have L2 norm (default: True).

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Methods}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxtitleref{fit}: Fits the EOF model to the data, supporting multiple zones by applying EOF analysis to the entire dataset.

\item {} 
\sphinxAtStartPar
\sphinxtitleref{transform}: Projects new data onto the EOF modes.

\item {} 
\sphinxAtStartPar
\sphinxtitleref{inverse\_transform}: Reconstructs data from principal components (PCs).

\item {} 
\sphinxAtStartPar
\sphinxtitleref{plot\_EOF}: Plots the EOF spatial patterns with explained variance.

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{WAS\_PCR}

\sphinxAtStartPar
\sphinxstylestrong{Initialization}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxtitleref{regression\_model}: The regression model (e.g., \sphinxtitleref{WAS\_Ridge\_Model}) to use with PCs.

\item {} 
\sphinxAtStartPar
\sphinxtitleref{n\_modes}: Number of EOF modes to retain.

\item {} 
\sphinxAtStartPar
\sphinxtitleref{use\_coslat}: Apply cosine latitude weighting (default: True).

\item {} 
\sphinxAtStartPar
\sphinxtitleref{standardize}: Standardize the input data (default: False).

\item {} 
\sphinxAtStartPar
\sphinxtitleref{opti\_explained\_variance}: Target cumulative explained variance.

\item {} 
\sphinxAtStartPar
\sphinxtitleref{L2norm}: Normalize EOF components and scores (default: True).

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Methods}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxtitleref{compute\_model}: Fits the EOF model, transforms data to PCs, and applies the regression model.

\item {} 
\sphinxAtStartPar
\sphinxtitleref{compute\_prob}: Computes tercile probabilities using the regression model.

\item {} 
\sphinxAtStartPar
\sphinxtitleref{forecast}: Makes forecasts using EOF\sphinxhyphen{}transformed data.

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Example Usage: Seasonal Forecasting Based on Observational Data}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from}\PYG{+w}{ }\PYG{n+nn}{wass2s}\PYG{+w}{ }\PYG{k+kn}{import} \PYG{o}{*}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} Define the directory to save the data}
\PYG{n}{dir\PYGZus{}to\PYGZus{}save\PYGZus{}reanalysis} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{/path/to/save\PYGZus{}reanalysis}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{n}{dir\PYGZus{}to\PYGZus{}save\PYGZus{}agroindicators} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{/path/to/save\PYGZus{}agroindicators}\PYG{l+s+s2}{\PYGZdq{}}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{} Define the climatology  year range and the season}
\PYG{n}{clim\PYGZus{}year\PYGZus{}start} \PYG{o}{=} \PYG{l+m+mi}{1991}
\PYG{n}{clim\PYGZus{}year\PYGZus{}end} \PYG{o}{=} \PYG{l+m+mi}{2020}
\PYG{n}{seas\PYGZus{}reanalysis} \PYG{o}{=} \PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{01}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{02}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{03}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}
\PYG{n}{seas\PYGZus{}agroindicators} \PYG{o}{=} \PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{05}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{06}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{07}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{} Define the variables to download}
\PYG{n}{variables} \PYG{o}{=} \PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{AGRO.PRCP}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{} Define the center and the predictor variables}
\PYG{n}{center\PYGZus{}variable} \PYG{o}{=} \PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{ERA5.SST}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{:}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{} Define the extent for reanalysis}
\PYG{n}{extent} \PYG{o}{=} \PYG{p}{[}\PYG{l+m+mi}{45}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{180}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{45}\PYG{p}{,} \PYG{l+m+mi}{180}\PYG{p}{]} \PYG{c+c1}{\PYGZsh{} [North, West, South, East]}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{} Define the extent for Observation}
\PYG{n}{extent\PYGZus{}obs} \PYG{o}{=} \PYG{p}{[}\PYG{l+m+mi}{30}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{25}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{30}\PYG{p}{]} \PYG{c+c1}{\PYGZsh{} [North, West, South, East]}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{} Download the predictors and the predictand}
\PYG{n}{downloader} \PYG{o}{=} \PYG{n}{WAS\PYGZus{}Download}\PYG{p}{(}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{} Download the predictors}
\PYG{n}{downloader}\PYG{o}{.}\PYG{n}{WAS\PYGZus{}Download\PYGZus{}Reanalysis}\PYG{p}{(}
    \PYG{n}{dir\PYGZus{}to\PYGZus{}save}\PYG{o}{=}\PYG{n}{dir\PYGZus{}to\PYGZus{}save\PYGZus{}reanalysis}\PYG{p}{,}
    \PYG{n}{center\PYGZus{}variable}\PYG{o}{=}\PYG{n}{center\PYGZus{}variable}\PYG{p}{,}
    \PYG{n}{year\PYGZus{}start}\PYG{o}{=}\PYG{l+m+mi}{1991}\PYG{p}{,}
    \PYG{n}{year\PYGZus{}end}\PYG{o}{=}\PYG{l+m+mi}{2025}\PYG{p}{,}
    \PYG{n}{area}\PYG{o}{=}\PYG{n}{extent}\PYG{p}{,}
    \PYG{n}{seas}\PYG{o}{=}\PYG{n}{seas\PYGZus{}reanalysis}\PYG{p}{,}
    \PYG{n}{force\PYGZus{}download}\PYG{o}{=}\PYG{k+kc}{False}
\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{} Download the predictand}
\PYG{n}{downloader}\PYG{o}{.}\PYG{n}{WAS\PYGZus{}Download\PYGZus{}AgroIndicators}\PYG{p}{(}
    \PYG{n}{dir\PYGZus{}to\PYGZus{}save}\PYG{o}{=}\PYG{n}{dir\PYGZus{}to\PYGZus{}save\PYGZus{}agroindicators}\PYG{p}{,}
    \PYG{n}{variables}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{AGRO.PRCP}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{,}
    \PYG{n}{year\PYGZus{}start}\PYG{o}{=}\PYG{l+m+mi}{1991}\PYG{p}{,}
    \PYG{n}{year\PYGZus{}end}\PYG{o}{=}\PYG{l+m+mi}{2024}\PYG{p}{,}
    \PYG{n}{area}\PYG{o}{=}\PYG{n}{extent\PYGZus{}obs}\PYG{p}{,}
    \PYG{n}{seas}\PYG{o}{=}\PYG{n}{seas\PYGZus{}agroindicators}\PYG{p}{,}
    \PYG{n}{force\PYGZus{}download}\PYG{o}{=}\PYG{k+kc}{False}
\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
\sphinxstylestrong{Case 1: Used SST index as a predictor}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Prepare predictand and predictors}
\PYG{n}{predictand} \PYG{o}{=} \PYG{n}{prepare\PYGZus{}predictand}\PYG{p}{(}\PYG{n}{dir\PYGZus{}to\PYGZus{}save\PYGZus{}agroindicators}\PYG{p}{,} \PYG{n}{variables}\PYG{p}{,} \PYG{n}{year\PYGZus{}start}\PYG{p}{,} \PYG{n}{year\PYGZus{}end}\PYG{p}{,} \PYG{n}{seas\PYGZus{}agroindicators}\PYG{p}{,} \PYG{n}{ds}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{daily}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Prepare predictors}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} Print available SST indices}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n+nb}{list}\PYG{p}{(}\PYG{n}{sst\PYGZus{}indices\PYGZus{}name}\PYG{o}{.}\PYG{n}{keys}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{} Choose yours}
\PYG{n}{sst\PYGZus{}index\PYGZus{}name} \PYG{o}{=} \PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{NINO34}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{TNA}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{TSA}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{DMI}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{} Plot the SST index zone}
\PYG{n}{plot\PYGZus{}map}\PYG{p}{(}\PYG{p}{[}\PYG{n}{extent}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{,}\PYG{n}{extent}\PYG{p}{[}\PYG{l+m+mi}{3}\PYG{p}{]}\PYG{p}{,}\PYG{n}{extent}\PYG{p}{[}\PYG{l+m+mi}{2}\PYG{p}{]}\PYG{p}{,}\PYG{n}{extent}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{]}\PYG{p}{,} \PYG{n}{sst\PYGZus{}indices} \PYG{o}{=} \PYG{n}{sst\PYGZus{}index\PYGZus{}name}\PYG{p}{,} \PYG{n}{title}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Index Zone}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}\PYG{n}{fig\PYGZus{}size}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{7}\PYG{p}{,}\PYG{l+m+mi}{4}\PYG{p}{)}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{} Compute the SST indices}
\PYG{n}{predictors} \PYG{o}{=} \PYG{n}{compute\PYGZus{}sst\PYGZus{}indices}\PYG{p}{(}\PYG{n}{dir\PYGZus{}to\PYGZus{}save\PYGZus{}reanalysis}\PYG{p}{,} \PYG{n}{sst\PYGZus{}index\PYGZus{}name}\PYG{p}{,} \PYG{n}{center\PYGZus{}variable}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,} \PYG{n}{year\PYGZus{}start}\PYG{p}{,} \PYG{n}{year\PYGZus{}end}\PYG{p}{,} \PYG{n}{seas\PYGZus{}reanalysis}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{} Compute variance inflation factor to see multicolinearity between predictors}

\PYG{n}{vif\PYGZus{}data} \PYG{o}{=} \PYG{n}{pd}\PYG{o}{.}\PYG{n}{DataFrame}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{vif\PYGZus{}data}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{feature}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]} \PYG{o}{=} \PYG{n}{predictors}\PYG{o}{.}\PYG{n}{to\PYGZus{}dataframe}\PYG{p}{(}\PYG{p}{)}\PYG{o}{.}\PYG{n}{columns}
\PYG{n}{vif\PYGZus{}data}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{VIF}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]} \PYG{o}{=} \PYG{p}{[}\PYG{n}{VIF}\PYG{p}{(}\PYG{n}{predictors}\PYG{o}{.}\PYG{n}{to\PYGZus{}dataframe}\PYG{p}{(}\PYG{p}{)}\PYG{p}{,} \PYG{n}{i}\PYG{p}{)} \PYG{k}{for} \PYG{n}{i} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{n}{predictors}\PYG{o}{.}\PYG{n}{to\PYGZus{}dataframe}\PYG{p}{(}\PYG{p}{)}\PYG{o}{.}\PYG{n}{shape}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{)}\PYG{p}{]}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} Print VIF values}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{vif\PYGZus{}data}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{} Set a threshold for VIF}
\PYG{n}{vif\PYGZus{}threshold} \PYG{o}{=} \PYG{l+m+mi}{5}
\PYG{c+c1}{\PYGZsh{} Remove features with VIF greater than the threshold}
\PYG{n}{low\PYGZus{}vif\PYGZus{}predictors} \PYG{o}{=} \PYG{n}{vif\PYGZus{}data}\PYG{p}{[}\PYG{n}{vif\PYGZus{}data}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{VIF}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]} \PYG{o}{\PYGZlt{}} \PYG{n}{vif\PYGZus{}threshold}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{feature}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{o}{.}\PYG{n}{tolist}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{filtered\PYGZus{}predictors} \PYG{o}{=} \PYG{n}{predictors}\PYG{p}{[}\PYG{n}{low\PYGZus{}vif\PYGZus{}predictors}\PYG{p}{]}\PYG{o}{.}\PYG{n}{to\PYGZus{}array}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{filtered\PYGZus{}predictors} \PYG{o}{=} \PYG{n}{filtered\PYGZus{}predictors}\PYG{o}{.}\PYG{n}{rename}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{variable}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{features}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{\PYGZcb{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{transpose}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{T}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{features}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Initialize the model class}
\PYG{n}{model} \PYG{o}{=} \PYG{n}{WAS\PYGZus{}LinearRegression\PYGZus{}Model}\PYG{p}{(}\PYG{n}{nb\PYGZus{}cores}\PYG{o}{=}\PYG{l+m+mi}{2}\PYG{p}{,} \PYG{n}{dist\PYGZus{}method}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{lognormal}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{} Assuming predictand follows a lognormal distribution. otherwise, normal, student\PYGZhy{}t or gamma are available. used dist\PYGZus{}method=\PYGZdq{}normal\PYGZdq{} or dist\PYGZus{}method=\PYGZdq{}t\PYGZdq{} or dist\PYGZus{}method=\PYGZdq{}gamma\PYGZdq{}.}

\PYG{c+c1}{\PYGZsh{} Perform cross\PYGZhy{}validation}
\PYG{n}{was\PYGZus{}cv} \PYG{o}{=} \PYG{n}{WAS\PYGZus{}Cross\PYGZus{}Validator}\PYG{p}{(}\PYG{n}{n\PYGZus{}splits}\PYG{o}{=}\PYG{n+nb}{len}\PYG{p}{(}\PYG{n}{predictand}\PYG{o}{.}\PYG{n}{get\PYGZus{}index}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{T}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}\PYG{p}{,} \PYG{n}{nb\PYGZus{}omit}\PYG{o}{=}\PYG{l+m+mi}{2}\PYG{p}{)}
\PYG{n}{hindcast\PYGZus{}det}\PYG{p}{,} \PYG{n}{hindcast\PYGZus{}prob} \PYG{o}{=} \PYG{n}{was\PYGZus{}cv}\PYG{o}{.}\PYG{n}{cross\PYGZus{}validate}\PYG{p}{(}\PYG{n}{model}\PYG{p}{,} \PYG{n}{predictand}\PYG{p}{,} \PYG{n}{filtered\PYGZus{}predictorsisel}\PYG{p}{(}\PYG{n}{T}\PYG{o}{=}\PYG{n+nb}{slice}\PYG{p}{(}\PYG{k+kc}{None}\PYG{p}{,}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{)}\PYG{p}{,} \PYG{n}{clim\PYGZus{}year\PYGZus{}start}\PYG{p}{,} \PYG{n}{clim\PYGZus{}year\PYGZus{}end}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{} clim\PYGZus{}year\PYGZus{}start and clim\PYGZus{}year\PYGZus{}end are the years used to compute the climatology.}

\PYG{c+c1}{\PYGZsh{} Initialize the model class}
\PYG{n}{model} \PYG{o}{=} \PYG{n}{WAS\PYGZus{}Ridge\PYGZus{}Model}\PYG{p}{(}\PYG{n}{n\PYGZus{}clusters}\PYG{o}{=}\PYG{l+m+mi}{6}\PYG{p}{,} \PYG{n}{alpha\PYGZus{}range}\PYG{o}{=}\PYG{n}{np}\PYG{o}{.}\PYG{n}{logspace}\PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{4}\PYG{p}{,} \PYG{l+m+mf}{0.1}\PYG{p}{,} \PYG{l+m+mi}{20}\PYG{p}{)}\PYG{p}{,} \PYG{n}{nb\PYGZus{}cores} \PYG{o}{=} \PYG{l+m+mi}{2}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Compute alpha parameters}
\PYG{n}{alpha}\PYG{p}{,} \PYG{n}{clusters} \PYG{o}{=} \PYG{n}{model}\PYG{o}{.}\PYG{n}{compute\PYGZus{}hyperparameters}\PYG{p}{(}\PYG{n}{predictand}\PYG{p}{,} \PYG{n}{filtered\PYGZus{}predictors}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Perform cross\PYGZhy{}validation}
\PYG{n}{was\PYGZus{}cv} \PYG{o}{=} \PYG{n}{WAS\PYGZus{}Cross\PYGZus{}Validator}\PYG{p}{(}\PYG{n}{n\PYGZus{}splits}\PYG{o}{=}\PYG{n+nb}{len}\PYG{p}{(}\PYG{n}{predictand}\PYG{o}{.}\PYG{n}{get\PYGZus{}index}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{T}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}\PYG{p}{,} \PYG{n}{nb\PYGZus{}omit}\PYG{o}{=}\PYG{l+m+mi}{2}\PYG{p}{)}
\PYG{n}{hindcast\PYGZus{}det\PYGZus{}Ridge}\PYG{p}{,} \PYG{n}{hindcast\PYGZus{}prob\PYGZus{}Ridge} \PYG{o}{=} \PYG{n}{was\PYGZus{}cv}\PYG{o}{.}\PYG{n}{cross\PYGZus{}validate}\PYG{p}{(}\PYG{n}{model}\PYG{p}{,} \PYG{n}{predictand}\PYG{p}{,} \PYG{n}{filtered\PYGZus{}predictors}\PYG{o}{.}\PYG{n}{isel}\PYG{p}{(}\PYG{n}{T}\PYG{o}{=}\PYG{n+nb}{slice}\PYG{p}{(}\PYG{k+kc}{None}\PYG{p}{,}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{)}\PYG{p}{,} \PYG{n}{clim\PYGZus{}year\PYGZus{}start}\PYG{p}{,} \PYG{n}{clim\PYGZus{}year\PYGZus{}end}\PYG{p}{,} \PYG{n}{alpha}\PYG{o}{=}\PYG{n}{alpha}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Make a forecast}
\PYG{n}{forecast\PYGZus{}det\PYGZus{}Ridge}\PYG{p}{,} \PYG{n}{forecast\PYGZus{}prob\PYGZus{}Ridge} \PYG{o}{=} \PYG{n}{model}\PYG{o}{.}\PYG{n}{forecast}\PYG{p}{(}\PYG{n}{predictand}\PYG{p}{,} \PYG{n}{clim\PYGZus{}year\PYGZus{}start}\PYG{p}{,} \PYG{n}{clim\PYGZus{}year\PYGZus{}end}\PYG{p}{,} \PYG{n}{filtered\PYGZus{}predictors}\PYG{o}{.}\PYG{n}{isel}\PYG{p}{(}\PYG{n}{T}\PYG{o}{=}\PYG{n+nb}{slice}\PYG{p}{(}\PYG{k+kc}{None}\PYG{p}{,}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{)}\PYG{p}{,} \PYG{n}{hindcast\PYGZus{}det\PYGZus{}Ridge}\PYG{p}{,} \PYG{n}{filtered\PYGZus{}predictors}\PYG{o}{.}\PYG{n}{isel}\PYG{p}{(}\PYG{n}{T}\PYG{o}{=}\PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{)}\PYG{p}{,} \PYG{n}{alpha}\PYG{o}{=}\PYG{n}{alpha}\PYG{p}{,} \PYG{n}{l1\PYGZus{}ratio}\PYG{o}{=}\PYG{n}{l1\PYGZus{}ratio}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
\sphinxstylestrong{Case 2: Used PCRs as a predictor}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Set your own zones ( zones not available in built\PYGZhy{}in)}
\PYG{c+c1}{\PYGZsh{} define zone as dict : \PYGZob{}\PYGZsq{}zone\PYGZus{}name\PYGZus{}key\PYGZsq{}: (\PYGZsq{}Explicit\PYGZus{}Zone\PYGZus{}name\PYGZsq{}, lon\PYGZus{}min, lon\PYGZus{}max, lat\PYGZus{}min, lat\PYGZus{}max)\PYGZcb{}}
\PYG{n}{zones\PYGZus{}for\PYGZus{}PCR} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{A}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{A}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{150}\PYG{p}{,} \PYG{l+m+mi}{150}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{45}\PYG{p}{,} \PYG{l+m+mi}{45}\PYG{p}{)}\PYG{p}{\PYGZcb{}}

\PYG{c+c1}{\PYGZsh{} Set number of modes}
\PYG{n}{n\PYGZus{}modes} \PYG{o}{=} \PYG{l+m+mi}{6}

\PYG{c+c1}{\PYGZsh{} ElasticNet hyperparameters range}
\PYG{n}{alpha\PYGZus{}range} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{logspace}\PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{4}\PYG{p}{,} \PYG{l+m+mf}{0.1}\PYG{p}{,} \PYG{l+m+mi}{20}\PYG{p}{)}
\PYG{n}{l1\PYGZus{}ratio\PYGZus{}range} \PYG{o}{=} \PYG{p}{[}\PYG{l+m+mf}{0.5}\PYG{p}{,} \PYG{l+m+mf}{0.9999}\PYG{p}{]}

\PYG{c+c1}{\PYGZsh{} Initialize the model class}
\PYG{n}{model} \PYG{o}{=} \PYG{n}{WAS\PYGZus{}PCR\PYGZus{}Model}\PYG{p}{(}\PYG{n}{n\PYGZus{}clusters}\PYG{o}{=}\PYG{l+m+mi}{6}\PYG{p}{,} \PYG{n}{alpha\PYGZus{}range}\PYG{o}{=}\PYG{n}{np}\PYG{o}{.}\PYG{n}{logspace}\PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{4}\PYG{p}{,} \PYG{l+m+mf}{0.1}\PYG{p}{,} \PYG{l+m+mi}{20}\PYG{p}{)}\PYG{p}{,} \PYG{n}{nb\PYGZus{}cores} \PYG{o}{=} \PYG{l+m+mi}{2}\PYG{p}{)}
\PYG{n}{plot\PYGZus{}map}\PYG{p}{(}\PYG{p}{[}\PYG{n}{extent}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{,}\PYG{n}{extent}\PYG{p}{[}\PYG{l+m+mi}{3}\PYG{p}{]}\PYG{p}{,}\PYG{n}{extent}\PYG{p}{[}\PYG{l+m+mi}{2}\PYG{p}{]}\PYG{p}{,}\PYG{n}{extent}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{]}\PYG{p}{,} \PYG{n}{sst\PYGZus{}indices} \PYG{o}{=} \PYG{n}{zones\PYGZus{}for\PYGZus{}PCR}\PYG{p}{,} \PYG{n}{title}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Predictors Area}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}\PYG{n}{fig\PYGZus{}size}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{8}\PYG{p}{,}\PYG{l+m+mi}{6}\PYG{p}{)}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Retrieve predictor data for the defined zone}
\PYG{n}{predictor} \PYG{o}{=} \PYG{n}{retrieve\PYGZus{}single\PYGZus{}zone\PYGZus{}for\PYGZus{}PCR}\PYG{p}{(}\PYG{n}{dir\PYGZus{}to\PYGZus{}save\PYGZus{}Reanalysis}\PYG{p}{,} \PYG{n}{zones\PYGZus{}for\PYGZus{}PCR}\PYG{p}{,} \PYG{n}{variables\PYGZus{}reanalysis}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,} \PYG{n}{year\PYGZus{}start}\PYG{p}{,} \PYG{n}{year\PYGZus{}end}\PYG{p}{,} \PYG{n}{season}\PYG{p}{,} \PYG{n}{clim\PYGZus{}year\PYGZus{}start}\PYG{p}{,} \PYG{n}{clim\PYGZus{}year\PYGZus{}end}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Load WAS\PYGZus{}EOF Class}
\PYG{n}{eof\PYGZus{}model} \PYG{o}{=} \PYG{n}{WAS\PYGZus{}EOF}\PYG{p}{(}\PYG{n}{n\PYGZus{}modes}\PYG{o}{=}\PYG{n}{n\PYGZus{}modes}\PYG{p}{,} \PYG{n}{use\PYGZus{}coslat}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{standardize}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Load predictor, compute EOFs and retrieve component, scores and explained variances}
\PYG{n}{s\PYGZus{}eofs}\PYG{p}{,} \PYG{n}{s\PYGZus{}pcs}\PYG{p}{,} \PYG{n}{s\PYGZus{}expvar}\PYG{p}{,} \PYG{n}{\PYGZus{}} \PYG{o}{=} \PYG{n}{eof\PYGZus{}model}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{n}{predictor}\PYG{p}{,} \PYG{n}{dim}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{T}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}  \PYG{n}{clim\PYGZus{}year\PYGZus{}start}\PYG{o}{=}\PYG{n}{clim\PYGZus{}year\PYGZus{}start}\PYG{p}{,} \PYG{n}{clim\PYGZus{}year\PYGZus{}end}\PYG{o}{=}\PYG{n}{clim\PYGZus{}year\PYGZus{}end}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Plot EOFs and explained variances}
\PYG{n}{eof\PYGZus{}model}\PYG{o}{.}\PYG{n}{plot\PYGZus{}EOF}\PYG{p}{(}\PYG{n}{s\PYGZus{}eofs}\PYG{p}{,} \PYG{n}{s\PYGZus{}expvar}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Perform Cross\PYGZhy{}validation with elastic\PYGZhy{}net}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{} Load class for model}
\PYG{n}{regression\PYGZus{}model} \PYG{o}{=} \PYG{n}{WAS\PYGZus{}ElasticNet\PYGZus{}Model}\PYG{p}{(}\PYG{n}{alpha\PYGZus{}range} \PYG{o}{=} \PYG{n}{alpha\PYGZus{}range}\PYG{p}{,} \PYG{n}{l1\PYGZus{}ratio\PYGZus{}range} \PYG{o}{=} \PYG{n}{l1\PYGZus{}ratio\PYGZus{}range}\PYG{p}{,} \PYG{n}{nb\PYGZus{}cores} \PYG{o}{=} \PYG{l+m+mi}{2}\PYG{p}{,} \PYG{n}{dist\PYGZus{}method}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{lognormal}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{pcr\PYGZus{}model} \PYG{o}{=} \PYG{n}{WAS\PYGZus{}PCR}\PYG{p}{(}\PYG{n}{regression\PYGZus{}model}\PYG{o}{=}\PYG{n}{regression\PYGZus{}model}\PYG{p}{,} \PYG{n}{n\PYGZus{}modes}\PYG{o}{=}\PYG{n}{n\PYGZus{}modes}\PYG{p}{,} \PYG{n}{standardize}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{} Compute alpha parameters}
\PYG{n}{alpha}\PYG{p}{,} \PYG{n}{l1\PYGZus{}ratio}\PYG{p}{,} \PYG{n}{clusters} \PYG{o}{=} \PYG{n}{regression\PYGZus{}model}\PYG{o}{.}\PYG{n}{compute\PYGZus{}hyperparameters}\PYG{p}{(}\PYG{n}{predictand}\PYG{p}{,} \PYG{n}{s\PYGZus{}pcs}\PYG{o}{.}\PYG{n}{isel}\PYG{p}{(}\PYG{n}{T}\PYG{o}{=}\PYG{n+nb}{slice}\PYG{p}{(}\PYG{k+kc}{None}\PYG{p}{,}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{)}\PYG{o}{.}\PYG{n}{rename}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{mode}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{features}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{\PYGZcb{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{transpose}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{T}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{features}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} Perform cross\PYGZhy{}validation}
\PYG{n}{was\PYGZus{}cv} \PYG{o}{=} \PYG{n}{WAS\PYGZus{}Cross\PYGZus{}Validator}\PYG{p}{(}\PYG{n}{n\PYGZus{}splits}\PYG{o}{=}\PYG{n+nb}{len}\PYG{p}{(}\PYG{n}{predictand}\PYG{o}{.}\PYG{n}{get\PYGZus{}index}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{T}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}\PYG{p}{,} \PYG{n}{nb\PYGZus{}omit}\PYG{o}{=}\PYG{l+m+mi}{2}\PYG{p}{)}
\PYG{n}{hindcast\PYGZus{}det}\PYG{p}{,} \PYG{n}{hindcast\PYGZus{}prob} \PYG{o}{=} \PYG{n}{was\PYGZus{}cv}\PYG{o}{.}\PYG{n}{cross\PYGZus{}validate}\PYG{p}{(}\PYG{n}{pcr\PYGZus{}model}\PYG{p}{,} \PYG{n}{predictand}\PYG{p}{,} \PYG{n}{s\PYGZus{}pcs}\PYG{o}{.}\PYG{n}{isel}\PYG{p}{(}\PYG{n}{T}\PYG{o}{=}\PYG{n+nb}{slice}\PYG{p}{(}\PYG{k+kc}{None}\PYG{p}{,}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{)}\PYG{o}{.}\PYG{n}{rename}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{mode}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{features}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{\PYGZcb{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{transpose}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{T}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{features}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,} \PYG{n}{clim\PYGZus{}year\PYGZus{}start}\PYG{p}{,} \PYG{n}{clim\PYGZus{}year\PYGZus{}end}\PYG{p}{,} \PYG{n}{alpha}\PYG{o}{=}\PYG{n}{alpha}\PYG{p}{,} \PYG{n}{l1\PYGZus{}ratio}\PYG{o}{=}\PYG{n}{l1\PYGZus{}ratio}\PYG{p}{)}
\end{sphinxVerbatim}


\subsection{CCA Models}
\label{\detokenize{Models:cca-models}}
\sphinxAtStartPar
The \sphinxtitleref{was\_cca.py} module provides classes for Canonical Correlation Analysis (CCA):
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxtitleref{WAS\_CCA}: Performs CCA to identify relationships between two multivariate datasets.

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Initialization}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxtitleref{n\_modes}: Number of CCA modes to retain.

\item {} 
\sphinxAtStartPar
\sphinxtitleref{n\_pca\_modes}: Number of PCA modes to use for dimensionality reduction.

\item {} 
\sphinxAtStartPar
\sphinxtitleref{dist\_method}: distribution method for probability computations.

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Methods}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxtitleref{compute\_model}: Fits the CCA model and makes predictions.

\item {} 
\sphinxAtStartPar
\sphinxtitleref{compute\_prob}: Computes tercile probabilities for the predictions.

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Example Usage: Recalibrating Seasonal Forecast Outputs from Global Climate Models (GCMs)}


\subsection{Analog Forecasting Methods}
\label{\detokenize{Models:analog-forecasting-methods}}
\sphinxAtStartPar
The \sphinxtitleref{was\_analog.py} module provides the \sphinxtitleref{WAS\_Analog} class for analog\sphinxhyphen{}based forecasting using various techniques to identify historical analogs to current conditions for prediction, particularly for seasonal rainfall forecasts using sea surface temperature (SST) data.

\sphinxAtStartPar
\sphinxstylestrong{Initialization Parameters}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{dir\_to\_save}} (str): Directory path to save downloaded and processed data files.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{year\_start}} (int): Starting year for historical data.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{year\_forecast}} (int): Target forecast year.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{reanalysis\_name}} (str): Reanalysis dataset name (e.g., “ERA5.SST” or “NOAA.SST”).

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{model\_name}} (str): Forecast model name (e.g., “ECMWF\_51.SST”).

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{method\_analog}} (str, default=”som”): Analog method to use (“som”, “cor\_based”, “pca\_based”).

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{best\_prcp\_models}} (list, optional): List of best precipitation models. Default is None.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{month\_of\_initialization}} (int, optional): Forecast initialization month. Default is None (uses current month).

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{lead\_time}} (list, optional): Lead times in months. Default is None (uses {[}1, 2, 3, 4, 5{]}).

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{ensemble\_mean}} (str, default=”mean”): Ensemble mean method (“mean” or “median”).

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{clim\_year\_start}} (int, optional): Start year for climatology period.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{clim\_year\_end}} (int, optional): End year for climatology period.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{define\_extent}} (tuple, optional): Bounding box as (lon\_min, lon\_max, lat\_min, lat\_max) for regional analysis.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{index\_compute}} (list, optional): Climate indices to compute (e.g., {[}“NINO34”, “DMI”{]}).

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{some\_grid\_size}} (tuple, default=(None, None)): SOM grid dimensions (rows, cols); None uses automatic sizing.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{some\_learning\_rate}} (float, default=0.5): Learning rate for SOM training.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{some\_neighborhood\_function}} (str, default=”gaussian”): Neighborhood function for SOM (“gaussian”, etc.).

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{some\_sigma}} (float, default=1.0): Initial neighborhood radius for SOM.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{dist\_method}} (str, default=”gamma”): Probability method (“gamma”, “t”, “normal”, “lognormal”, “nonparam”).

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Key Methods}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{download\_sst\_reanalysis()}}: Downloads and processes SST reanalysis data from the specified center for the given years and area.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{download\_models()}}: Downloads seasonal forecast model data for the specified model, initialization month, and lead times.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{standardize\_timeseries()}}: Standardizes time series data over a specified climatology period.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{calc\_index()}}: Computes specified climate indices (e.g., NINO34, DMI) from SST data.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{compute\_model()}}: Identifies historical analogs using the specified method and computes deterministic forecasts.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{compute\_prob()}}: Calculates tercile probabilities (Below Normal, Near Normal, Above Normal) using the specified distribution method.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{forecast()}}: Generates deterministic and probabilistic forecasts for the target year, returning processed SST data, similar years, deterministic forecast, and probabilistic forecast.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{composite\_plot()}}: Creates composite plots of forecast results, optionally including the predictor (SST) visualization.

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Example Usage}

\sphinxAtStartPar
Basic analog forecast setup:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from}\PYG{+w}{ }\PYG{n+nn}{wass2s}\PYG{n+nn}{.}\PYG{n+nn}{was\PYGZus{}analog}\PYG{+w}{ }\PYG{k+kn}{import} \PYG{n}{WAS\PYGZus{}Analog}

\PYG{c+c1}{\PYGZsh{} Initialize analog model}
\PYG{n}{analog\PYGZus{}model} \PYG{o}{=} \PYG{n}{WAS\PYGZus{}Analog}\PYG{p}{(}
    \PYG{n}{dir\PYGZus{}to\PYGZus{}save}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{./s2s\PYGZus{}data/analog}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{n}{year\PYGZus{}start}\PYG{o}{=}\PYG{l+m+mi}{1990}\PYG{p}{,}
    \PYG{n}{year\PYGZus{}forecast}\PYG{o}{=}\PYG{l+m+mi}{2025}\PYG{p}{,}
    \PYG{n}{reanalysis\PYGZus{}name}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{NOAA.SST}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{n}{model\PYGZus{}name}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{ECMWF\PYGZus{}51.SST}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{n}{method\PYGZus{}analog}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{som}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{n}{month\PYGZus{}of\PYGZus{}initialization}\PYG{o}{=}\PYG{l+m+mi}{3}\PYG{p}{,}
    \PYG{n}{clim\PYGZus{}year\PYGZus{}start}\PYG{o}{=}\PYG{l+m+mi}{1991}\PYG{p}{,}
    \PYG{n}{clim\PYGZus{}year\PYGZus{}end}\PYG{o}{=}\PYG{l+m+mi}{2020}\PYG{p}{,}
    \PYG{n}{define\PYGZus{}extent}\PYG{o}{=}\PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{180}\PYG{p}{,} \PYG{l+m+mi}{180}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{45}\PYG{p}{,} \PYG{l+m+mi}{45}\PYG{p}{)}\PYG{p}{,}
    \PYG{n}{index\PYGZus{}compute}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{NINO34}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{DMI}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{,}
    \PYG{n}{dist\PYGZus{}method}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{gamma}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Download and process data}
\PYG{n}{sst\PYGZus{}hist}\PYG{p}{,} \PYG{n}{sst\PYGZus{}for} \PYG{o}{=} \PYG{n}{analog\PYGZus{}model}\PYG{o}{.}\PYG{n}{download\PYGZus{}and\PYGZus{}process}\PYG{p}{(}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Generate forecast}
\PYG{n}{ddd}\PYG{p}{,} \PYG{n}{similar\PYGZus{}years}\PYG{p}{,} \PYG{n}{forecast\PYGZus{}det}\PYG{p}{,} \PYG{n}{forecast\PYGZus{}prob} \PYG{o}{=} \PYG{n}{analog\PYGZus{}model}\PYG{o}{.}\PYG{n}{forecast}\PYG{p}{(}
    \PYG{n}{predictant}\PYG{o}{=}\PYG{n}{rainfall\PYGZus{}data}\PYG{p}{,}
    \PYG{n}{clim\PYGZus{}year\PYGZus{}start}\PYG{o}{=}\PYG{l+m+mi}{1991}\PYG{p}{,}
    \PYG{n}{clim\PYGZus{}year\PYGZus{}end}\PYG{o}{=}\PYG{l+m+mi}{2020}\PYG{p}{,}
    \PYG{n}{hindcast\PYGZus{}det}\PYG{o}{=}\PYG{n}{hindcast\PYGZus{}data}\PYG{p}{,}
    \PYG{n}{forecast\PYGZus{}year}\PYG{o}{=}\PYG{l+m+mi}{2025}
\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Create composite plot}
\PYG{n}{similar\PYGZus{}years} \PYG{o}{=} \PYG{n}{analog\PYGZus{}model}\PYG{o}{.}\PYG{n}{composite\PYGZus{}plot}\PYG{p}{(}
    \PYG{n}{predictant}\PYG{o}{=}\PYG{n}{rainfall\PYGZus{}data}\PYG{p}{,}
    \PYG{n}{clim\PYGZus{}year\PYGZus{}start}\PYG{o}{=}\PYG{l+m+mi}{1991}\PYG{p}{,}
    \PYG{n}{clim\PYGZus{}year\PYGZus{}end}\PYG{o}{=}\PYG{l+m+mi}{2020}\PYG{p}{,}
    \PYG{n}{hindcast\PYGZus{}det}\PYG{o}{=}\PYG{n}{hindcast\PYGZus{}data}\PYG{p}{,}
    \PYG{n}{plot\PYGZus{}predictor}\PYG{o}{=}\PYG{k+kc}{True}
\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
\sphinxstylestrong{Cross\sphinxhyphen{}Validation Example}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from}\PYG{+w}{ }\PYG{n+nn}{wass2s}\PYG{n+nn}{.}\PYG{n+nn}{was\PYGZus{}analog}\PYG{+w}{ }\PYG{k+kn}{import} \PYG{n}{WAS\PYGZus{}Cross\PYGZus{}Validator}

\PYG{c+c1}{\PYGZsh{} Perform cross\PYGZhy{}validation}
\PYG{n}{was\PYGZus{}analog\PYGZus{}cv} \PYG{o}{=} \PYG{n}{WAS\PYGZus{}Cross\PYGZus{}Validator}\PYG{p}{(}\PYG{n}{n\PYGZus{}splits}\PYG{o}{=}\PYG{n+nb}{len}\PYG{p}{(}\PYG{n}{rainfall}\PYG{o}{.}\PYG{n}{get\PYGZus{}index}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{T}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}\PYG{p}{,} \PYG{n}{nb\PYGZus{}omit}\PYG{o}{=}\PYG{l+m+mi}{2}\PYG{p}{)}
\PYG{n}{hindcast\PYGZus{}analog\PYGZus{}det}\PYG{p}{,} \PYG{n}{hindcast\PYGZus{}analog\PYGZus{}prob} \PYG{o}{=} \PYG{n}{was\PYGZus{}analog\PYGZus{}cv}\PYG{o}{.}\PYG{n}{cross\PYGZus{}validate}\PYG{p}{(}
    \PYG{n}{analog\PYGZus{}model}\PYG{p}{,}
    \PYG{n}{rainfall}\PYG{p}{,}
    \PYG{n}{clim\PYGZus{}year\PYGZus{}start}\PYG{o}{=}\PYG{l+m+mi}{1991}\PYG{p}{,}
    \PYG{n}{clim\PYGZus{}year\PYGZus{}end}\PYG{o}{=}\PYG{l+m+mi}{2020}
\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Generate forecast using cross\PYGZhy{}validated hindcast}
\PYG{n}{ddd}\PYG{p}{,} \PYG{n}{similar\PYGZus{}years}\PYG{p}{,} \PYG{n}{forecast\PYGZus{}det}\PYG{p}{,} \PYG{n}{forecast\PYGZus{}prob} \PYG{o}{=} \PYG{n}{analog\PYGZus{}model}\PYG{o}{.}\PYG{n}{forecast}\PYG{p}{(}
    \PYG{n}{predictant}\PYG{o}{=}\PYG{n}{rainfall}\PYG{p}{,}
    \PYG{n}{clim\PYGZus{}year\PYGZus{}start}\PYG{o}{=}\PYG{l+m+mi}{1991}\PYG{p}{,}
    \PYG{n}{clim\PYGZus{}year\PYGZus{}end}\PYG{o}{=}\PYG{l+m+mi}{2020}\PYG{p}{,}
    \PYG{n}{hindcast\PYGZus{}det}\PYG{o}{=}\PYG{n}{hindcast\PYGZus{}analog\PYGZus{}det}\PYG{p}{,}
    \PYG{n}{forecast\PYGZus{}year}\PYG{o}{=}\PYG{l+m+mi}{2025}
\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
Ensure \sphinxtitleref{WAS\_Cross\_Validator} is correctly imported from the \sphinxtitleref{wass2s.was\_analog} module and that the \sphinxtitleref{rainfall} variable is an xarray DataArray with appropriate dimensions (T, Y, X).
\end{sphinxadmonition}

\sphinxstepscope


\section{Verification Module}
\label{\detokenize{Verification:verification-module}}\label{\detokenize{Verification::doc}}
\sphinxAtStartPar
The Verification module provides tools for evaluating the performance of climate forecasts using a variety of deterministic, probabilistic, and ensemble\sphinxhyphen{}based metrics. It is implemented in the \sphinxtitleref{was\_verification.py} module and leverages the \sphinxtitleref{WAS\_Verification} class to compute metrics such as Kling\sphinxhyphen{}Gupta Efficiency (KGE), Pearson Correlation, Ranked Probability Skill Score (RPSS), and Continuous Ranked Probability Score (CRPS). The module also includes visualization utilities for plotting scores, reliability diagrams, and ROC curves.

\sphinxAtStartPar
This module is designed to work with gridded climate data, typically stored in \sphinxtitleref{xarray} DataArrays, and supports parallel computation using \sphinxtitleref{dask} for efficiency with large datasets.

\sphinxAtStartPar
The \sphinxtitleref{WAS\_Verification} class is the core of the Verification module, providing methods to compute and visualize various performance metrics for climate forecasts.

\sphinxAtStartPar
\sphinxstylestrong{Initialization}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from}\PYG{+w}{ }\PYG{n+nn}{wass2s}\PYG{n+nn}{.}\PYG{n+nn}{was\PYGZus{}verification}\PYG{+w}{ }\PYG{k+kn}{import} \PYG{n}{WAS\PYGZus{}Verification}

\PYG{c+c1}{\PYGZsh{} Initialize with a distribution method for probabilistic forecasts}
\PYG{n}{verifier} \PYG{o}{=} \PYG{n}{WAS\PYGZus{}Verification}\PYG{p}{(}\PYG{n}{dist\PYGZus{}method}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{gamma}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
\sphinxstylestrong{Parameters}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxtitleref{dist\_method}: Specifies the distribution method for computing tercile probabilities. Options include:
\sphinxhyphen{} \sphinxtitleref{“t”}: Student’s t\sphinxhyphen{}based method.
\sphinxhyphen{} \sphinxtitleref{“gamma”}: Gamma distribution\sphinxhyphen{}based method (default).
\sphinxhyphen{} \sphinxtitleref{“normal”}: Normal distribution\sphinxhyphen{}based method.
\sphinxhyphen{} \sphinxtitleref{“lognormal”}: Lognormal distribution\sphinxhyphen{}based method.
\sphinxhyphen{} \sphinxtitleref{“weibull\_min”}: Weibull minimum distribution\sphinxhyphen{}based method.
\sphinxhyphen{} \sphinxtitleref{“nonparam”}: Non\sphinxhyphen{}parametric method using historical errors.

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Available Metrics}

\sphinxAtStartPar
The class defines a dictionary of scoring metrics with metadata, including:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Deterministic Metrics}:
\sphinxhyphen{} \sphinxtitleref{KGE}: Kling\sphinxhyphen{}Gupta Efficiency (\sphinxhyphen{}1 to 1).
\sphinxhyphen{} \sphinxtitleref{Pearson}: Pearson Correlation Coefficient (\sphinxhyphen{}1 to 1).
\sphinxhyphen{} \sphinxtitleref{IOA}: Index of Agreement (0 to 1).
\sphinxhyphen{} \sphinxtitleref{MAE}: Mean Absolute Error (0 to 100).
\sphinxhyphen{} \sphinxtitleref{RMSE}: Root Mean Square Error (0 to 100).
\sphinxhyphen{} \sphinxtitleref{NSE}: Nash\sphinxhyphen{}Sutcliffe Efficiency (None to 1).
\sphinxhyphen{} \sphinxtitleref{TAYLOR\_DIAGRAM}: Taylor Diagram (visualization).

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Probabilistic Metrics}:
\sphinxhyphen{} \sphinxtitleref{GROC}: Generalized Receiver Operating Characteristic (0 to 1).
\sphinxhyphen{} \sphinxtitleref{RPSS}: Ranked Probability Skill Score (\sphinxhyphen{}1 to 1).
\sphinxhyphen{} \sphinxtitleref{IGS}: Ignorance Score (0 to None).
\sphinxhyphen{} \sphinxtitleref{RES}: Resolution Score (0 to None).
\sphinxhyphen{} \sphinxtitleref{REL}: Reliability Score (None to None).
\sphinxhyphen{} \sphinxtitleref{RELIABILITY\_DIAGRAM}: Reliability Diagram (visualization).
\sphinxhyphen{} \sphinxtitleref{ROC\_CURVE}: Receiver Operating Characteristic Curve (visualization).

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Ensemble Metrics}:
\sphinxhyphen{} \sphinxtitleref{CRPS}: Continuous Ranked Probability Score (0 to 100).

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Metadata Access}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{metadata} \PYG{o}{=} \PYG{n}{verifier}\PYG{o}{.}\PYG{n}{get\PYGZus{}scores\PYGZus{}metadata}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
This returns a dictionary containing the name, range, type, colormap, and computation function for each metric.


\subsection{Deterministic Metrics}
\label{\detokenize{Verification:deterministic-metrics}}
\sphinxAtStartPar
Deterministic metrics evaluate the performance of point forecasts against observations. They are computed using the \sphinxtitleref{compute\_deterministic\_score} method, which applies a scoring function over \sphinxtitleref{xarray} DataArrays.

\sphinxAtStartPar
\sphinxstylestrong{Example Usage}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Compute Pearson Correlation}
\PYG{n}{pearson\PYGZus{}score} \PYG{o}{=} \PYG{n}{verifier}\PYG{o}{.}\PYG{n}{compute\PYGZus{}deterministic\PYGZus{}score}\PYG{p}{(}
    \PYG{n}{verifier}\PYG{o}{.}\PYG{n}{pearson\PYGZus{}corr}\PYG{p}{,} \PYG{n}{obs\PYGZus{}data}\PYG{p}{,} \PYG{n}{model\PYGZus{}data}
\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Plot the score}
\PYG{n}{verifier}\PYG{o}{.}\PYG{n}{plot\PYGZus{}model\PYGZus{}score}\PYG{p}{(}\PYG{n}{pearson\PYGZus{}score}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Pearson}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{dir\PYGZus{}save\PYGZus{}score}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{./scores}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{figure\PYGZus{}name}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Pearson\PYGZus{}Score}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
\sphinxstylestrong{Key Methods}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxtitleref{kling\_gupta\_efficiency}: Computes KGE, balancing correlation, bias, and variability.

\item {} 
\sphinxAtStartPar
\sphinxtitleref{pearson\_corr}: Computes Pearson Correlation Coefficient.

\item {} 
\sphinxAtStartPar
\sphinxtitleref{index\_of\_agreement}: Computes IOA, measuring agreement between predictions and observations.

\item {} 
\sphinxAtStartPar
\sphinxtitleref{mean\_absolute\_error}: Computes MAE, the average absolute difference.

\item {} 
\sphinxAtStartPar
\sphinxtitleref{root\_mean\_square\_error}: Computes RMSE, the square root of mean squared differences.

\item {} 
\sphinxAtStartPar
\sphinxtitleref{nash\_sutcliffe\_efficiency}: Computes NSE, comparing prediction errors to the mean of observations.

\item {} 
\sphinxAtStartPar
\sphinxtitleref{taylor\_diagram}: Placeholder for Taylor Diagram visualization (to be implemented).

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Plotting}

\sphinxAtStartPar
The \sphinxtitleref{plot\_model\_score} method visualizes deterministic scores on a map using \sphinxtitleref{cartopy}.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{verifier}\PYG{o}{.}\PYG{n}{plot\PYGZus{}model\PYGZus{}score}\PYG{p}{(}\PYG{n}{score\PYGZus{}result}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{KGE}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{dir\PYGZus{}save\PYGZus{}score}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{./scores}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{figure\PYGZus{}name}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{KGE\PYGZus{}Model}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
The \sphinxtitleref{plot\_models\_score} method plots multiple model scores in a grid.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{model\PYGZus{}metrics} \PYG{o}{=} \PYG{p}{\PYGZob{}}
    \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{model1}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{score\PYGZus{}result1}\PYG{p}{,}
    \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{model2}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{score\PYGZus{}result2}
\PYG{p}{\PYGZcb{}}
\PYG{n}{verifier}\PYG{o}{.}\PYG{n}{plot\PYGZus{}models\PYGZus{}score}\PYG{p}{(}\PYG{n}{model\PYGZus{}metrics}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Pearson}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{dir\PYGZus{}save\PYGZus{}score}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{./scores}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}


\subsection{Probabilistic Metrics}
\label{\detokenize{Verification:probabilistic-metrics}}
\sphinxAtStartPar
Probabilistic metrics evaluate the performance of forecasts that provide probabilities for tercile categories (below\sphinxhyphen{}normal, near\sphinxhyphen{}normal, above\sphinxhyphen{}normal). These are computed using the \sphinxtitleref{compute\_probabilistic\_score} method.

\sphinxAtStartPar
\sphinxstylestrong{Example Usage}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Compute tercile probabilities}
\PYG{n}{proba\PYGZus{}forecast} \PYG{o}{=} \PYG{n}{verifier}\PYG{o}{.}\PYG{n}{gcm\PYGZus{}compute\PYGZus{}prob}\PYG{p}{(}\PYG{n}{obs\PYGZus{}data}\PYG{p}{,} \PYG{n}{clim\PYGZus{}year\PYGZus{}start}\PYG{o}{=}\PYG{l+m+mi}{1981}\PYG{p}{,} \PYG{n}{clim\PYGZus{}year\PYGZus{}end}\PYG{o}{=}\PYG{l+m+mi}{2010}\PYG{p}{,} \PYG{n}{hindcast\PYGZus{}det}\PYG{o}{=}\PYG{n}{model\PYGZus{}data}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Compute RPSS}
\PYG{n}{rpss\PYGZus{}score} \PYG{o}{=} \PYG{n}{verifier}\PYG{o}{.}\PYG{n}{compute\PYGZus{}probabilistic\PYGZus{}score}\PYG{p}{(}
    \PYG{n}{verifier}\PYG{o}{.}\PYG{n}{calculate\PYGZus{}rpss}\PYG{p}{,} \PYG{n}{obs\PYGZus{}data}\PYG{p}{,} \PYG{n}{proba\PYGZus{}forecast}\PYG{p}{,} \PYG{n}{clim\PYGZus{}year\PYGZus{}start}\PYG{o}{=}\PYG{l+m+mi}{1981}\PYG{p}{,} \PYG{n}{clim\PYGZus{}year\PYGZus{}end}\PYG{o}{=}\PYG{l+m+mi}{2010}
\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
\sphinxstylestrong{Key Methods}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxtitleref{classify}: Classifies data into terciles based on climatology.

\item {} 
\sphinxAtStartPar
\sphinxtitleref{compute\_class}: Computes tercile class labels for observations.

\item {} 
\sphinxAtStartPar
\sphinxtitleref{calculate\_groc}: Computes GROC, averaging AUC across tercile categories.

\item {} 
\sphinxAtStartPar
\sphinxtitleref{calculate\_rpss}: Computes RPSS, comparing forecast probabilities to climatology.

\item {} 
\sphinxAtStartPar
\sphinxtitleref{ignorance\_score}: Computes Ignorance Score per Weijs (2010).

\item {} 
\sphinxAtStartPar
\sphinxtitleref{resolution\_score\_grid}: Computes Resolution Score, measuring how forecasts differ from climatology.

\item {} 
\sphinxAtStartPar
\sphinxtitleref{reliability\_score\_grid}: Computes Reliability Score, assessing forecast calibration.

\item {} 
\sphinxAtStartPar
\sphinxtitleref{reliability\_diagram}: Plots Reliability Diagrams for each tercile category.

\item {} 
\sphinxAtStartPar
\sphinxtitleref{plot\_roc\_curves}: Plots ROC Curves with confidence intervals for each tercile.

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Visualization}

\sphinxAtStartPar
Reliability Diagrams and ROC Curves are generated for probabilistic forecasts.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Plot Reliability Diagram}
\PYG{n}{verifier}\PYG{o}{.}\PYG{n}{reliability\PYGZus{}diagram}\PYG{p}{(}
    \PYG{n}{modelname}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Model1}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{dir\PYGZus{}to\PYGZus{}save\PYGZus{}score}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{./scores}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{y\PYGZus{}true}\PYG{o}{=}\PYG{n}{obs\PYGZus{}data}\PYG{p}{,} \PYG{n}{y\PYGZus{}probs}\PYG{o}{=}\PYG{n}{proba\PYGZus{}forecast}\PYG{p}{,}
    \PYG{n}{clim\PYGZus{}year\PYGZus{}start}\PYG{o}{=}\PYG{l+m+mi}{1981}\PYG{p}{,} \PYG{n}{clim\PYGZus{}year\PYGZus{}end}\PYG{o}{=}\PYG{l+m+mi}{2010}
\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Plot ROC Curves with 95\PYGZpc{} confidence intervals}
\PYG{n}{verifier}\PYG{o}{.}\PYG{n}{plot\PYGZus{}roc\PYGZus{}curves}\PYG{p}{(}
    \PYG{n}{modelname}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Model1}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{dir\PYGZus{}to\PYGZus{}save\PYGZus{}score}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{./scores}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{y\PYGZus{}true}\PYG{o}{=}\PYG{n}{obs\PYGZus{}data}\PYG{p}{,} \PYG{n}{y\PYGZus{}probs}\PYG{o}{=}\PYG{n}{proba\PYGZus{}forecast}\PYG{p}{,}
    \PYG{n}{clim\PYGZus{}year\PYGZus{}start}\PYG{o}{=}\PYG{l+m+mi}{1981}\PYG{p}{,} \PYG{n}{clim\PYGZus{}year\PYGZus{}end}\PYG{o}{=}\PYG{l+m+mi}{2010}\PYG{p}{,} \PYG{n}{n\PYGZus{}bootstraps}\PYG{o}{=}\PYG{l+m+mi}{1000}\PYG{p}{,} \PYG{n}{ci}\PYG{o}{=}\PYG{l+m+mf}{0.95}
\PYG{p}{)}
\end{sphinxVerbatim}


\subsection{Ensemble Metrics}
\label{\detokenize{Verification:ensemble-metrics}}
\sphinxAtStartPar
Ensemble metrics evaluate forecasts with multiple members, such as those from GCMs. The primary metric is CRPS, computed using \sphinxtitleref{xskillscore}.

\sphinxAtStartPar
\sphinxstylestrong{Example Usage}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Compute CRPS for ensemble forecast}
\PYG{n}{crps\PYGZus{}score} \PYG{o}{=} \PYG{n}{verifier}\PYG{o}{.}\PYG{n}{compute\PYGZus{}crps}\PYG{p}{(}\PYG{n}{obs\PYGZus{}data}\PYG{p}{,} \PYG{n}{model\PYGZus{}data}\PYG{p}{,} \PYG{n}{member\PYGZus{}dim}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{number}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{dim}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{T}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
\sphinxstylestrong{Key Methods}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxtitleref{compute\_crps}: Computes CRPS for ensemble forecasts, measuring the difference between predicted and observed distributions.

\end{itemize}


\subsection{Tercile Probability Computation}
\label{\detokenize{Verification:tercile-probability-computation}}
\sphinxAtStartPar
The module provides multiple methods to compute tercile probabilities for probabilistic forecasts, based on different distributional assumptions.

\sphinxAtStartPar
\sphinxstylestrong{Key Methods}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxtitleref{calculate\_tercile\_probabilities}: Uses Student’s t\sphinxhyphen{}distribution.

\item {} 
\sphinxAtStartPar
\sphinxtitleref{calculate\_tercile\_probabilities\_gamma}: Uses Gamma distribution.

\item {} 
\sphinxAtStartPar
\sphinxtitleref{calculate\_tercile\_probabilities\_normal}: Uses Normal distribution.

\item {} 
\sphinxAtStartPar
\sphinxtitleref{calculate\_tercile\_probabilities\_lognormal}: Uses Lognormal distribution.

\item {} 
\sphinxAtStartPar
\sphinxtitleref{calculate\_tercile\_probabilities\_weibull\_min}: Uses Weibull minimum distribution.

\item {} 
\sphinxAtStartPar
\sphinxtitleref{calculate\_tercile\_probabilities\_nonparametric}: Uses historical errors for a non\sphinxhyphen{}parametric approach.

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Example Usage}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Compute probabilities using Gamma distribution}
\PYG{n}{hindcast\PYGZus{}prob} \PYG{o}{=} \PYG{n}{verifier}\PYG{o}{.}\PYG{n}{gcm\PYGZus{}compute\PYGZus{}prob}\PYG{p}{(}
    \PYG{n}{Predictant}\PYG{o}{=}\PYG{n}{obs\PYGZus{}data}\PYG{p}{,} \PYG{n}{clim\PYGZus{}year\PYGZus{}start}\PYG{o}{=}\PYG{l+m+mi}{1981}\PYG{p}{,} \PYG{n}{clim\PYGZus{}year\PYGZus{}end}\PYG{o}{=}\PYG{l+m+mi}{2010}\PYG{p}{,} \PYG{n}{hindcast\PYGZus{}det}\PYG{o}{=}\PYG{n}{model\PYGZus{}data}
\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
The \sphinxtitleref{gcm\_compute\_prob} method selects the appropriate distribution based on the \sphinxtitleref{dist\_method} parameter.


\subsection{GCM Validation}
\label{\detokenize{Verification:gcm-validation}}
\sphinxAtStartPar
The module includes methods to validate General Circulation Model (GCM) forecasts against observations, supporting both deterministic and probabilistic metrics.

\sphinxAtStartPar
\sphinxstylestrong{Key Methods}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxtitleref{gcm\_validation\_compute}: Validates GCM forecasts for multiple models, computing specified metrics.

\item {} 
\sphinxAtStartPar
\sphinxtitleref{weighted\_gcm\_forecasts}: Combines forecasts from multiple models using weights based on a performance metric (e.g., GROC).

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Example Usage}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Validate GCM forecasts}
\PYG{n}{models\PYGZus{}files\PYGZus{}path} \PYG{o}{=} \PYG{p}{\PYGZob{}}
    \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{model1}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{path/to/model1.nc}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{model2}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{path/to/model2.nc}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{p}{\PYGZcb{}}
\PYG{n}{x\PYGZus{}metric} \PYG{o}{=} \PYG{n}{verifier}\PYG{o}{.}\PYG{n}{gcm\PYGZus{}validation\PYGZus{}compute}\PYG{p}{(}
    \PYG{n}{models\PYGZus{}files\PYGZus{}path}\PYG{o}{=}\PYG{n}{models\PYGZus{}files\PYGZus{}path}\PYG{p}{,} \PYG{n}{Obs}\PYG{o}{=}\PYG{n}{obs\PYGZus{}data}\PYG{p}{,} \PYG{n}{score}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Pearson}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{n}{month\PYGZus{}of\PYGZus{}initialization}\PYG{o}{=}\PYG{l+m+mi}{3}\PYG{p}{,} \PYG{n}{clim\PYGZus{}year\PYGZus{}start}\PYG{o}{=}\PYG{l+m+mi}{1981}\PYG{p}{,} \PYG{n}{clim\PYGZus{}year\PYGZus{}end}\PYG{o}{=}\PYG{l+m+mi}{2010}\PYG{p}{,}
    \PYG{n}{dir\PYGZus{}to\PYGZus{}save\PYGZus{}roc\PYGZus{}reliability}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{./scores}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{lead\PYGZus{}time}\PYG{o}{=}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}
\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Compute weighted GCM forecasts}
\PYG{n}{hindcast\PYGZus{}det}\PYG{p}{,} \PYG{n}{hindcast\PYGZus{}prob}\PYG{p}{,} \PYG{n}{forecast\PYGZus{}prob} \PYG{o}{=} \PYG{n}{verifier}\PYG{o}{.}\PYG{n}{weighted\PYGZus{}gcm\PYGZus{}forecasts}\PYG{p}{(}
    \PYG{n}{Obs}\PYG{o}{=}\PYG{n}{obs\PYGZus{}data}\PYG{p}{,} \PYG{n}{best\PYGZus{}models}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{model1\PYGZus{}MarIc\PYGZus{}JFM\PYGZus{}1}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{score1}\PYG{p}{\PYGZcb{}}\PYG{p}{,} \PYG{n}{scores}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{GROC}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{x\PYGZus{}metric}\PYG{p}{\PYGZcb{}}\PYG{p}{,}
    \PYG{n}{lead\PYGZus{}time}\PYG{o}{=}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{,} \PYG{n}{model\PYGZus{}dir}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{./models}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{clim\PYGZus{}year\PYGZus{}start}\PYG{o}{=}\PYG{l+m+mi}{1981}\PYG{p}{,} \PYG{n}{clim\PYGZus{}year\PYGZus{}end}\PYG{o}{=}\PYG{l+m+mi}{2010}\PYG{p}{,} \PYG{n}{variable}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{PRCP}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{p}{)}
\end{sphinxVerbatim}


\subsection{Annual Year Validation}
\label{\detokenize{Verification:annual-year-validation}}
\sphinxAtStartPar
The module provides utilities to validate forecasts for a specific year, including ratio\sphinxhyphen{}to\sphinxhyphen{}average classification and RPSS computation.

\sphinxAtStartPar
\sphinxstylestrong{Key Methods}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxtitleref{ratio\_to\_average}: Classifies forecast data relative to the climatological mean into categories (e.g., Well Above Average, Near Average).

\item {} 
\sphinxAtStartPar
\sphinxtitleref{compute\_one\_year\_rpss}: Computes RPSS for a specific year and visualizes it on a map.

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Example Usage}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Classify ratio to average for a specific year}
\PYG{n}{verifier}\PYG{o}{.}\PYG{n}{ratio\PYGZus{}to\PYGZus{}average}\PYG{p}{(}\PYG{n}{predictant}\PYG{o}{=}\PYG{n}{obs\PYGZus{}data}\PYG{p}{,} \PYG{n}{clim\PYGZus{}year\PYGZus{}start}\PYG{o}{=}\PYG{l+m+mi}{1981}\PYG{p}{,} \PYG{n}{clim\PYGZus{}year\PYGZus{}end}\PYG{o}{=}\PYG{l+m+mi}{2010}\PYG{p}{,} \PYG{n}{year}\PYG{o}{=}\PYG{l+m+mi}{2020}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Compute RPSS for a specific year}
\PYG{n}{verifier}\PYG{o}{.}\PYG{n}{compute\PYGZus{}one\PYGZus{}year\PYGZus{}rpss}\PYG{p}{(}
    \PYG{n}{obs}\PYG{o}{=}\PYG{n}{obs\PYGZus{}data}\PYG{p}{,} \PYG{n}{prob\PYGZus{}pred}\PYG{o}{=}\PYG{n}{proba\PYGZus{}forecast}\PYG{p}{,} \PYG{n}{clim\PYGZus{}year\PYGZus{}start}\PYG{o}{=}\PYG{l+m+mi}{1981}\PYG{p}{,} \PYG{n}{clim\PYGZus{}year\PYGZus{}end}\PYG{o}{=}\PYG{l+m+mi}{2010}\PYG{p}{,} \PYG{n}{year}\PYG{o}{=}\PYG{l+m+mi}{2020}
\PYG{p}{)}
\end{sphinxVerbatim}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Placeholder Functions}: Some methods (e.g., \sphinxtitleref{taylor\_diagram}) are placeholders and require implementation based on specific needs.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Gridded Data}: The module currently supports only gridded data validation. Non\sphinxhyphen{}gridded validation is not implemented.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Performance}: The use of \sphinxtitleref{dask} ensures efficient computation for large datasets, but users should ensure proper chunking of \sphinxtitleref{xarray} DataArrays.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Visualization}: Plots are saved to the specified directory and displayed using \sphinxtitleref{matplotlib}. Ensure the output directory exists.

\end{itemize}

\sphinxAtStartPar
This documentation provides an overview of the Verification module’s capabilities, along with example usage for key methods. For detailed information on each method, refer to the source code and docstrings in \sphinxtitleref{was\_verification.py}.

\sphinxstepscope


\section{Multi\sphinxhyphen{}Model Ensemble (MME) Techniques}
\label{\detokenize{mme:multi-model-ensemble-mme-techniques}}\label{\detokenize{mme::doc}}
\sphinxAtStartPar
The \sphinxtitleref{was\_mme.py} module provides classes for combining predictions from multiple models, including:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxtitleref{WAS\_mme\_ELM}: Extreme Learning Machine for MME.

\item {} 
\sphinxAtStartPar
\sphinxtitleref{WAS\_mme\_EPOELM}: Enhanced Parallel Online Extreme Learning Machine.

\item {} 
\sphinxAtStartPar
\sphinxtitleref{WAS\_mme\_MLP}: Multi\sphinxhyphen{}Layer Perceptron for MME.

\item {} 
\sphinxAtStartPar
\sphinxtitleref{WAS\_mme\_GradientBoosting}: Gradient Boosting for MME.

\item {} 
\sphinxAtStartPar
\sphinxtitleref{WAS\_mme\_XGBoosting}: XGBoost for MME.

\item {} 
\sphinxAtStartPar
\sphinxtitleref{WAS\_mme\_AdaBoost}: AdaBoost for MME.

\item {} 
\sphinxAtStartPar
\sphinxtitleref{WAS\_mme\_LGBM\_Boosting}: LightGBM Boosting for MME.

\item {} 
\sphinxAtStartPar
\sphinxtitleref{WAS\_mme\_Stack\_MLP\_RF}: Stacking model with MLP and Random Forest.

\item {} 
\sphinxAtStartPar
\sphinxtitleref{WAS\_mme\_Stack\_Lasso\_RF\_MLP}: Stacking model with Lasso, Random Forest, and MLP.

\item {} 
\sphinxAtStartPar
\sphinxtitleref{WAS\_mme\_Stack\_MLP\_Ada\_Ridge}: Stacking model with MLP, AdaBoost, and Ridge.

\item {} 
\sphinxAtStartPar
\sphinxtitleref{WAS\_mme\_Stack\_RF\_GB\_Ridge}: Stacking model with Random Forest, Gradient Boosting, and Ridge.

\item {} 
\sphinxAtStartPar
\sphinxtitleref{WAS\_mme\_Stack\_KNN\_Tree\_SVR}: Stacking model with KNN, Decision Tree, and SVR.

\item {} 
\sphinxAtStartPar
\sphinxtitleref{WAS\_mme\_GA}: Genetic Algorithm for MME.

\end{itemize}

\sphinxAtStartPar
Each MME class includes methods for computing the ensemble model and, where applicable, computing probabilities.

\sphinxAtStartPar
\sphinxstylestrong{Example Usage with WAS\_mme\_ELM}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from}\PYG{+w}{ }\PYG{n+nn}{wass2s}\PYG{n+nn}{.}\PYG{n+nn}{was\PYGZus{}mme}\PYG{+w}{ }\PYG{k+kn}{import} \PYG{n}{WAS\PYGZus{}mme\PYGZus{}ELM}

\PYG{c+c1}{\PYGZsh{} Define ELM parameters}
\PYG{n}{elm\PYGZus{}kwargs} \PYG{o}{=} \PYG{p}{\PYGZob{}}
    \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{regularization}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+m+mi}{10}\PYG{p}{,}
    \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{hidden\PYGZus{}layer\PYGZus{}size}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+m+mi}{4}\PYG{p}{,}
    \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{activation}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{lin}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}  \PYG{c+c1}{\PYGZsh{} Options: \PYGZsq{}sigm\PYGZsq{}, \PYGZsq{}tanh\PYGZsq{}, \PYGZsq{}lin\PYGZsq{}, \PYGZsq{}relu\PYGZsq{}}
    \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{preprocessing}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{none}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}  \PYG{c+c1}{\PYGZsh{} Options: \PYGZsq{}minmax\PYGZsq{}, \PYGZsq{}std\PYGZsq{}, \PYGZsq{}none\PYGZsq{}}
    \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{n\PYGZus{}estimators}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+m+mi}{10}\PYG{p}{,}
\PYG{p}{\PYGZcb{}}

\PYG{c+c1}{\PYGZsh{} Initialize the MME ELM model}
\PYG{n}{model} \PYG{o}{=} \PYG{n}{WAS\PYGZus{}mme\PYGZus{}ELM}\PYG{p}{(}\PYG{n}{elm\PYGZus{}kwargs}\PYG{o}{=}\PYG{n}{elm\PYGZus{}kwargs}\PYG{p}{,} \PYG{n}{dist\PYGZus{}method}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{euclidean}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Process datasets for MME (user\PYGZhy{}defined function)}
\PYG{n}{all\PYGZus{}model\PYGZus{}hdcst}\PYG{p}{,} \PYG{n}{all\PYGZus{}model\PYGZus{}fcst}\PYG{p}{,} \PYG{n}{obs}\PYG{p}{,} \PYG{n}{best\PYGZus{}score} \PYG{o}{=} \PYG{n}{process\PYGZus{}datasets\PYGZus{}for\PYGZus{}mme}\PYG{p}{(}
    \PYG{n}{rainfall}\PYG{o}{.}\PYG{n}{sel}\PYG{p}{(}\PYG{n}{T}\PYG{o}{=}\PYG{n+nb}{slice}\PYG{p}{(}\PYG{n+nb}{str}\PYG{p}{(}\PYG{n}{year\PYGZus{}start}\PYG{p}{)}\PYG{p}{,} \PYG{n+nb}{str}\PYG{p}{(}\PYG{n}{year\PYGZus{}end}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}\PYG{p}{,}
    \PYG{n}{gcm}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{ELM\PYGZus{}ELR}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{dir\PYGZus{}to\PYGZus{}save\PYGZus{}model}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{./models}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{n}{best\PYGZus{}models}\PYG{o}{=}\PYG{p}{[}\PYG{p}{]}\PYG{p}{,} \PYG{n}{scores}\PYG{o}{=}\PYG{p}{[}\PYG{p}{]}\PYG{p}{,} \PYG{n}{year\PYGZus{}start}\PYG{o}{=}\PYG{l+m+mi}{1990}\PYG{p}{,} \PYG{n}{year\PYGZus{}end}\PYG{o}{=}\PYG{l+m+mi}{2020}\PYG{p}{,}
    \PYG{n}{model}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{month\PYGZus{}of\PYGZus{}initialization}\PYG{o}{=}\PYG{l+m+mi}{3}\PYG{p}{,} \PYG{n}{lead\PYGZus{}time}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{n}{year\PYGZus{}forecast}\PYG{o}{=}\PYG{l+m+mi}{2021}
\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Initialize cross\PYGZhy{}validator}
\PYG{n}{was\PYGZus{}mme\PYGZus{}gcm} \PYG{o}{=} \PYG{n}{WAS\PYGZus{}Cross\PYGZus{}Validator}\PYG{p}{(}
    \PYG{n}{n\PYGZus{}splits}\PYG{o}{=}\PYG{n+nb}{len}\PYG{p}{(}\PYG{n}{rainfall}\PYG{o}{.}\PYG{n}{sel}\PYG{p}{(}\PYG{n}{T}\PYG{o}{=}\PYG{n+nb}{slice}\PYG{p}{(}\PYG{n+nb}{str}\PYG{p}{(}\PYG{n}{year\PYGZus{}start}\PYG{p}{)}\PYG{p}{,} \PYG{n+nb}{str}\PYG{p}{(}\PYG{n}{year\PYGZus{}end}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}\PYG{o}{.}\PYG{n}{get\PYGZus{}index}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{T}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}\PYG{p}{,}
    \PYG{n}{nb\PYGZus{}omit}\PYG{o}{=}\PYG{l+m+mi}{2}
\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Perform cross\PYGZhy{}validation}
\PYG{n}{hindcast\PYGZus{}det\PYGZus{}gcm}\PYG{p}{,} \PYG{n}{hindcast\PYGZus{}prob\PYGZus{}gcm} \PYG{o}{=} \PYG{n}{was\PYGZus{}mme\PYGZus{}gcm}\PYG{o}{.}\PYG{n}{cross\PYGZus{}validate}\PYG{p}{(}
    \PYG{n}{model}\PYG{p}{,} \PYG{n}{obs}\PYG{p}{,} \PYG{n}{all\PYGZus{}model\PYGZus{}hdcst}\PYG{p}{,} \PYG{n}{clim\PYGZus{}year\PYGZus{}start}\PYG{p}{,} \PYG{n}{clim\PYGZus{}year\PYGZus{}end}
\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxstepscope


\chapter{wass2s submodules}
\label{\detokenize{api:wass2s-submodules}}\label{\detokenize{api::doc}}

\section{wass2s.was\_download module}
\label{\detokenize{api:wass2s-was-download-module}}

\section{wass2s.was\_compute\_predictand module}
\label{\detokenize{api:wass2s-was-compute-predictand-module}}

\section{wass2s.was\_merge\_predictand module}
\label{\detokenize{api:wass2s-was-merge-predictand-module}}

\section{wass2s.was\_cross\_validate module}
\label{\detokenize{api:wass2s-was-cross-validate-module}}

\section{wass2s.was\_linear\_models module}
\label{\detokenize{api:wass2s-was-linear-models-module}}

\section{wass2s.was\_eof module}
\label{\detokenize{api:wass2s-was-eof-module}}

\section{wass2s.was\_pcr module}
\label{\detokenize{api:wass2s-was-pcr-module}}

\section{wass2s.was\_cca module}
\label{\detokenize{api:wass2s-was-cca-module}}

\section{wass2s.was\_machine\_learning module}
\label{\detokenize{api:wass2s-was-machine-learning-module}}

\section{wass2s.was\_analog module}
\label{\detokenize{api:wass2s-was-analog-module}}

\section{wass2s.was\_verification module}
\label{\detokenize{api:wass2s-was-verification-module}}

\section{wass2s.was\_mme module}
\label{\detokenize{api:wass2s-was-mme-module}}

\section{wass2s.utils module}
\label{\detokenize{api:wass2s-utils-module}}


\renewcommand{\indexname}{Index}
\printindex
\end{document}