

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>wass2s.was_machine_learning &mdash; wass2s: A python-based tool for seasonal climate forecast in West Africa and the Sahel. 0.3.4 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />

  
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=1e28cc32"></script>
      <script src="../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            wass2s: A python-based tool for seasonal climate forecast in West Africa and the Sahel.
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../Installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Usage.html">Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api.html">API Reference</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">wass2s: A python-based tool for seasonal climate forecast in West Africa and the Sahel.</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">Module code</a></li>
      <li class="breadcrumb-item active">wass2s.was_machine_learning</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for wass2s.was_machine_learning</h1><div class="highlight"><pre>
<span></span><span class="c1"># Machine Learning and Statistical Modeling</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.ensemble</span><span class="w"> </span><span class="kn">import</span> <span class="n">RandomForestRegressor</span><span class="p">,</span> <span class="n">StackingRegressor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.svm</span><span class="w"> </span><span class="kn">import</span> <span class="n">SVR</span><span class="p">,</span> <span class="n">SVC</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">GridSearchCV</span><span class="p">,</span> <span class="n">RandomizedSearchCV</span><span class="p">,</span> <span class="n">cross_val_score</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">PolynomialFeatures</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">,</span> <span class="n">RobustScaler</span><span class="p">,</span> <span class="n">MinMaxScaler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.base</span><span class="w"> </span><span class="kn">import</span> <span class="n">clone</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.neural_network</span><span class="w"> </span><span class="kn">import</span> <span class="n">MLPRegressor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.cluster</span><span class="w"> </span><span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.pipeline</span><span class="w"> </span><span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.compose</span><span class="w"> </span><span class="kn">import</span> <span class="n">TransformedTargetRegressor</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">xgboost</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">xgb</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">statsmodels.api</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sm</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">statsmodels.stats.outliers_influence</span><span class="w"> </span><span class="kn">import</span> <span class="n">variance_inflation_factor</span> <span class="k">as</span> <span class="n">VIF</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">statsmodels.stats.anova</span><span class="w"> </span><span class="kn">import</span> <span class="n">anova_lm</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">wass2s.utils</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">optuna</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">uniform</span><span class="p">,</span> <span class="n">loguniform</span><span class="p">,</span> <span class="n">randint</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">LogisticRegression</span>

<span class="c1"># Data Manipulation and Analysis</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">xarray</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">xr</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="c1"># Signal Processing and Interpolation</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">scipy.signal</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sig</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy.interpolate</span><span class="w"> </span><span class="kn">import</span> <span class="n">CubicSpline</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy.optimize</span><span class="w"> </span><span class="kn">import</span> <span class="n">fsolve</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy.special</span><span class="w"> </span><span class="kn">import</span> <span class="n">gamma</span> <span class="k">as</span> <span class="n">gamma_function</span>

<span class="c1"># Statistical Distributions</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">norm</span><span class="p">,</span> <span class="n">lognorm</span><span class="p">,</span> <span class="n">expon</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">weibull_min</span><span class="p">,</span>
    <span class="n">t</span> <span class="k">as</span> <span class="n">t_dist</span><span class="p">,</span> <span class="n">poisson</span><span class="p">,</span> <span class="n">nbinom</span>
<span class="p">)</span>

<span class="c1"># EOF Analysis</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">xeofs</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">xe</span>

<span class="c1"># Parallel Computing</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">multiprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">cpu_count</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">dask.distributed</span><span class="w"> </span><span class="kn">import</span> <span class="n">Client</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">dask.array</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">da</span>

<span class="c1"># Typing and Utilities</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Optional</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">collections</span><span class="w"> </span><span class="kn">import</span> <span class="n">defaultdict</span>

<span class="c1"># Warnings</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>

<span class="c1"># import numpy as np</span>
<span class="c1"># import optuna</span>
<span class="c1"># from sklearn.base import clone</span>
<span class="c1"># from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV</span>
<span class="c1"># from scipy.stats import randint, uniform, loguniform</span>

<div class="viewcode-block" id="BaseOptimizer">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.BaseOptimizer">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">BaseOptimizer</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Unified Optimizer. Supports SVR (multi-grid), MLP, and Stacking architectures.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
<div class="viewcode-block" id="BaseOptimizer.__init__">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.BaseOptimizer.__init__">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optimization_method</span><span class="o">=</span><span class="s2">&quot;grid&quot;</span><span class="p">,</span> <span class="n">n_trials</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimization_method</span> <span class="o">=</span> <span class="n">optimization_method</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_trials</span> <span class="o">=</span> <span class="n">n_trials</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cv</span> <span class="o">=</span> <span class="n">cv</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span></div>


<div class="viewcode-block" id="BaseOptimizer.optimize">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.BaseOptimizer.optimize">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">optimize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">param_space</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;neg_mean_squared_error&#39;</span><span class="p">):</span>
        <span class="c1"># Ensure data is in numpy format for sklearn stability</span>
        <span class="n">X_data</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">values</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="s1">&#39;values&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="n">X</span>
        <span class="n">y_data</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">values</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="s1">&#39;values&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="n">y</span>
        
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimization_method</span> <span class="o">==</span> <span class="s2">&quot;grid&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_grid_search</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">param_space</span><span class="p">,</span> <span class="n">X_data</span><span class="p">,</span> <span class="n">y_data</span><span class="p">,</span> <span class="n">scoring</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimization_method</span> <span class="o">==</span> <span class="s2">&quot;random&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_random_search</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">param_space</span><span class="p">,</span> <span class="n">X_data</span><span class="p">,</span> <span class="n">y_data</span><span class="p">,</span> <span class="n">scoring</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimization_method</span> <span class="o">==</span> <span class="s2">&quot;bayesian&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optuna_search</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">param_space</span><span class="p">,</span> <span class="n">X_data</span><span class="p">,</span> <span class="n">y_data</span><span class="p">,</span> <span class="n">scoring</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unknown method: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">optimization_method</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span></div>


<div class="viewcode-block" id="BaseOptimizer._prepare_space">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.BaseOptimizer._prepare_space">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">_prepare_space</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">param_space</span><span class="p">,</span> <span class="n">is_wrapped</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Adds &#39;regressor__&#39; prefix if model is a TransformedTargetRegressor.&quot;&quot;&quot;</span>
        <span class="n">prefix</span> <span class="o">=</span> <span class="s2">&quot;regressor__&quot;</span> <span class="k">if</span> <span class="n">is_wrapped</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span>
        
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">param_space</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="k">return</span> <span class="p">[{</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}{</span><span class="n">k</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">d</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">param_space</span><span class="p">]</span>
        <span class="k">return</span> <span class="p">{</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}{</span><span class="n">k</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">param_space</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span></div>


<div class="viewcode-block" id="BaseOptimizer._clean_best_params">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.BaseOptimizer._clean_best_params">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">_clean_best_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">best_params</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Removes &#39;regressor__&#39; prefix from results for class compatibility.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">{</span><span class="n">k</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;regressor__&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">):</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">best_params</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span></div>


<div class="viewcode-block" id="BaseOptimizer._grid_search">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.BaseOptimizer._grid_search">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">_grid_search</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">param_space</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">scoring</span><span class="p">):</span>
        <span class="n">space</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prepare_space</span><span class="p">(</span><span class="n">param_space</span><span class="p">,</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;regressor&#39;</span><span class="p">))</span>
        <span class="n">gs</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">space</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cv</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">scoring</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">gs</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_clean_best_params</span><span class="p">(</span><span class="n">gs</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span></div>


<div class="viewcode-block" id="BaseOptimizer._random_search">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.BaseOptimizer._random_search">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">_random_search</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">param_space</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">scoring</span><span class="p">):</span>
        <span class="c1"># Handle SVR list of dicts by consolidating for RandomSearch</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">param_space</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">consolidated</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">param_space</span><span class="p">:</span> <span class="n">consolidated</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
            <span class="n">param_space</span> <span class="o">=</span> <span class="n">consolidated</span>
            
        <span class="n">space</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prepare_space</span><span class="p">(</span><span class="n">param_space</span><span class="p">,</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;regressor&#39;</span><span class="p">))</span>
        <span class="c1"># Convert lists to random distributions</span>
        <span class="n">dist_space</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="p">(</span><span class="n">v</span> <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="k">else</span> <span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">space</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
        
        <span class="n">rs</span> <span class="o">=</span> <span class="n">RandomizedSearchCV</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dist_space</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_trials</span><span class="p">,</span> 
                                <span class="n">cv</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cv</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">scoring</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">rs</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_clean_best_params</span><span class="p">(</span><span class="n">rs</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span></div>


<div class="viewcode-block" id="BaseOptimizer._optuna_search">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.BaseOptimizer._optuna_search">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">_optuna_search</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">param_space</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">scoring</span><span class="p">):</span>
            <span class="c1"># 1. Prepare the search space</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">param_space</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                <span class="n">flat_space</span> <span class="o">=</span> <span class="p">{}</span>
                <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">param_space</span><span class="p">:</span> <span class="n">flat_space</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">flat_space</span> <span class="o">=</span> <span class="n">param_space</span>
    
            <span class="k">def</span><span class="w"> </span><span class="nf">objective</span><span class="p">(</span><span class="n">trial</span><span class="p">):</span>
                <span class="n">suggestions</span> <span class="o">=</span> <span class="p">{}</span>
                <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">values</span> <span class="ow">in</span> <span class="n">flat_space</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                        <span class="n">suggestions</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_categorical</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">values</span><span class="p">)</span>
                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
                        <span class="n">low</span><span class="p">,</span> <span class="n">high</span> <span class="o">=</span> <span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">values</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
                        <span class="n">log</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">values</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span> <span class="ow">and</span> <span class="n">values</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;log&#39;</span>
                        <span class="n">suggestions</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_float</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">low</span><span class="p">,</span> <span class="n">high</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="n">log</span><span class="p">)</span>
    
                <span class="n">model_instance</span> <span class="o">=</span> <span class="n">clone</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
                <span class="n">prefix</span> <span class="o">=</span> <span class="s2">&quot;regressor__&quot;</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;regressor&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span>
                <span class="n">prefixed_suggestions</span> <span class="o">=</span> <span class="p">{</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}{</span><span class="n">k</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">suggestions</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
                <span class="n">model_instance</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="o">**</span><span class="n">prefixed_suggestions</span><span class="p">)</span>
    
                <span class="c1"># 2. Implementation of Early Stopping (Pruning)</span>
                <span class="c1"># Instead of a simple cross_val_score, we iterate through the CV folds manually</span>
                <span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">KFold</span>
                <span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_scorer</span>
                
                <span class="n">cv_splitter</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cv</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>
                <span class="n">scorer</span> <span class="o">=</span> <span class="n">get_scorer</span><span class="p">(</span><span class="n">scoring</span><span class="p">)</span>
                <span class="n">cv_scores</span> <span class="o">=</span> <span class="p">[]</span>
    
                <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">train_idx</span><span class="p">,</span> <span class="n">val_idx</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">cv_splitter</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)):</span>
                    <span class="n">X_train_cv</span><span class="p">,</span> <span class="n">X_val_cv</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">train_idx</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">val_idx</span><span class="p">]</span>
                    <span class="n">y_train_cv</span><span class="p">,</span> <span class="n">y_val_cv</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">train_idx</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">val_idx</span><span class="p">]</span>
                    
                    <span class="k">try</span><span class="p">:</span>
                        <span class="n">model_instance</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_cv</span><span class="p">,</span> <span class="n">y_train_cv</span><span class="p">)</span>
                        <span class="n">score</span> <span class="o">=</span> <span class="n">scorer</span><span class="p">(</span><span class="n">model_instance</span><span class="p">,</span> <span class="n">X_val_cv</span><span class="p">,</span> <span class="n">y_val_cv</span><span class="p">)</span>
                        <span class="n">cv_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
                        
                        <span class="c1"># Report intermediate result to Optuna</span>
                        <span class="n">trial</span><span class="o">.</span><span class="n">report</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">cv_scores</span><span class="p">),</span> <span class="n">i</span><span class="p">)</span>
                        
                        <span class="c1"># 3. Check if we should stop this trial early</span>
                        <span class="k">if</span> <span class="n">trial</span><span class="o">.</span><span class="n">should_prune</span><span class="p">():</span>
                            <span class="k">raise</span> <span class="n">optuna</span><span class="o">.</span><span class="n">TrialPruned</span><span class="p">()</span>
                    <span class="k">except</span> <span class="p">(</span><span class="ne">ValueError</span><span class="p">,</span> <span class="ne">RuntimeError</span><span class="p">,</span> <span class="n">optuna</span><span class="o">.</span><span class="n">TrialPruned</span><span class="p">)</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">optuna</span><span class="o">.</span><span class="n">TrialPruned</span><span class="p">):</span>
                            <span class="k">raise</span> <span class="c1"># Re-raise pruning to let Optuna handle it</span>
                        <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span> <span class="c1"># Penalize math errors</span>
    
                <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">cv_scores</span><span class="p">)</span>
    
            <span class="c1"># 4. Study creation with a MedianPruner</span>
            <span class="c1"># It prunes trials whose best intermediate value is worse than the median </span>
            <span class="c1"># of previous trials at the same step.</span>
            <span class="n">study</span> <span class="o">=</span> <span class="n">optuna</span><span class="o">.</span><span class="n">create_study</span><span class="p">(</span>
                <span class="n">direction</span><span class="o">=</span><span class="s2">&quot;maximize&quot;</span><span class="p">,</span> 
                <span class="n">sampler</span><span class="o">=</span><span class="n">optuna</span><span class="o">.</span><span class="n">samplers</span><span class="o">.</span><span class="n">TPESampler</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">),</span>
                <span class="n">pruner</span><span class="o">=</span><span class="n">optuna</span><span class="o">.</span><span class="n">pruners</span><span class="o">.</span><span class="n">MedianPruner</span><span class="p">(</span><span class="n">n_startup_trials</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_warmup_steps</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="p">)</span>
            
            <span class="n">study</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span><span class="n">objective</span><span class="p">,</span> <span class="n">n_trials</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_trials</span><span class="p">,</span> <span class="n">show_progress_bar</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">study</span><span class="o">.</span><span class="n">best_params</span></div>
</div>



<span class="c1"># class BaseOptimizer__:</span>
<span class="c1">#     &quot;&quot;&quot;</span>
<span class="c1">#     Base class for hyperparameter optimization with support for:</span>
<span class="c1">#     - GridSearchCV (exhaustive)a</span>
<span class="c1">#     - RandomizedSearchCV (random)</span>
<span class="c1">#     - Optuna (Bayesian/Bayesian)</span>
<span class="c1">#     &quot;&quot;&quot;</span>
    
<span class="c1">#     def __init__(self, optimization_method=&quot;grid&quot;, n_trials=20, cv=3, random_state=42):</span>
<span class="c1">#         self.optimization_method = optimization_method</span>
<span class="c1">#         self.n_trials = n_trials</span>
<span class="c1">#         self.cv = cv</span>
<span class="c1">#         self.random_state = random_state</span>
        
<span class="c1">#     def optimize(self, model, param_space, X, y, scoring=&#39;neg_mean_squared_error&#39;):</span>
<span class="c1">#         if self.optimization_method == &quot;grid&quot;:</span>
<span class="c1">#             return self._grid_search(model, param_space, X, y, scoring)</span>
<span class="c1">#         elif self.optimization_method == &quot;random&quot;:</span>
<span class="c1">#             return self._random_search(model, param_space, X, y, scoring)</span>
<span class="c1">#         elif self.optimization_method == &quot;bayesian&quot;:</span>
<span class="c1">#             return self._optuna_search(model, param_space, X, y, scoring)</span>
<span class="c1">#         else:</span>
<span class="c1">#             raise ValueError(f&quot;Unknown optimization method: {self.optimization_method}&quot;)</span>

<span class="c1">#     def _apply_params(self, model_instance, params):</span>
<span class="c1">#         &quot;&quot;&quot;</span>
<span class="c1">#         Helper to apply parameters to a model, handling TransformedTargetRegressor </span>
<span class="c1">#         or Pipelines by adding the appropriate prefix.</span>
<span class="c1">#         &quot;&quot;&quot;</span>
<span class="c1">#         if hasattr(model_instance, &#39;regressor&#39;):</span>
<span class="c1">#             # It&#39;s a TransformedTargetRegressor</span>
<span class="c1">#             keyed_params = {f&quot;regressor__{k}&quot;: v for k, v in params.items()}</span>
<span class="c1">#             model_instance.set_params(**keyed_params)</span>
<span class="c1">#         elif hasattr(model_instance, &#39;steps&#39;):</span>
<span class="c1">#             # It&#39;s a Pipeline (assuming &#39;mlp&#39; is the final step name)</span>
<span class="c1">#             # You might need to adjust &#39;mlp&#39; if your pipeline step name differs</span>
<span class="c1">#             keyed_params = {f&quot;mlp__{k}&quot;: v for k, v in params.items()}</span>
<span class="c1">#             model_instance.set_params(**keyed_params)</span>
<span class="c1">#         else:</span>
<span class="c1">#             # Standard model</span>
<span class="c1">#             model_instance.set_params(**params)</span>
<span class="c1">#         return model_instance</span>

<span class="c1">#     def _optuna_search(self, model, param_space, X, y, scoring):</span>
<span class="c1">#         def objective(trial):</span>
<span class="c1">#             params = {}</span>
<span class="c1">#             for param_name, param_values in param_space.items():</span>
<span class="c1">#                 if isinstance(param_values, list):</span>
<span class="c1">#                     params[param_name] = trial.suggest_categorical(param_name, param_values)</span>
<span class="c1">#                 elif isinstance(param_values, tuple) and len(param_values) &gt;= 2:</span>
<span class="c1">#                     low, high = param_values[0], param_values[1]</span>
<span class="c1">#                     is_log = len(param_values) == 3 and param_values[2] == &#39;log&#39;</span>
<span class="c1">#                     params[param_name] = trial.suggest_float(param_name, low, high, log=is_log)</span>
            
<span class="c1">#             # FIX: Clone the original model (wrapper and all)</span>
<span class="c1">#             model_instance = clone(model)</span>
<span class="c1">#             # FIX: Route the suggested params to the internal regressor</span>
<span class="c1">#             model_instance = self._apply_params(model_instance, params)</span>
            
<span class="c1">#             scores = cross_val_score(model_instance, X, y, cv=self.cv, scoring=scoring, n_jobs=1)</span>
<span class="c1">#             return scores.mean()</span>

<span class="c1">#         study = optuna.create_study(direction=&quot;maximize&quot;, </span>
<span class="c1">#                                     sampler=optuna.samplers.TPESampler(seed=self.random_state))</span>
<span class="c1">#         study.optimize(objective, n_trials=self.n_trials, show_progress_bar=False)</span>
<span class="c1">#         return study.best_params</span>

<span class="c1">#     def _grid_search(self, model, param_space, X, y, scoring):</span>
<span class="c1">#         from sklearn.model_selection import GridSearchCV</span>
<span class="c1">#         # Prefix keys for the grid search if model is wrapped</span>
<span class="c1">#         if hasattr(model, &#39;regressor&#39;):</span>
<span class="c1">#             param_space = {f&quot;regressor__{k}&quot;: v for k, v in param_space.items()}</span>
        
<span class="c1">#         gs = GridSearchCV(model, param_space, cv=self.cv, scoring=scoring, n_jobs=-1)</span>
<span class="c1">#         gs.fit(X, y)</span>
        
<span class="c1">#         # Clean the double underscores from keys before returning</span>
<span class="c1">#         best_params = {k.split(&#39;__&#39;)[-1]: v for k, v in gs.best_params_.items()}</span>
<span class="c1">#         return best_params</span>

<span class="c1">#     def _random_search(self, model, param_space, X, y, scoring):</span>
<span class="c1">#         from sklearn.model_selection import RandomizedSearchCV</span>
<span class="c1">#         param_dist = self._convert_to_distributions(param_space)</span>
        
<span class="c1">#         if hasattr(model, &#39;regressor&#39;):</span>
<span class="c1">#             param_dist = {f&quot;regressor__{k}&quot;: v for k, v in param_dist.items()}</span>
            
<span class="c1">#         rs = RandomizedSearchCV(model, param_dist, n_iter=self.n_trials, </span>
<span class="c1">#                                 cv=self.cv, scoring=scoring, random_state=self.random_state, n_jobs=-1)</span>
<span class="c1">#         rs.fit(X, y)</span>
        
<span class="c1">#         best_params = {k.split(&#39;__&#39;)[-1]: v for k, v in rs.best_params_.items()}</span>
<span class="c1">#         return best_params</span>

<span class="c1">#     def _convert_to_distributions(self, param_space):</span>
<span class="c1">#         &quot;&quot;&quot;Convert parameter space to distributions for random search.&quot;&quot;&quot;</span>
<span class="c1">#         param_distributions = {}</span>
<span class="c1">#         for param_name, param_values in param_space.items():</span>
<span class="c1">#             if isinstance(param_values, list):</span>
<span class="c1">#                 if all(isinstance(v, int) for v in param_values):</span>
<span class="c1">#                     param_distributions[param_name] = randint(min(param_values), max(param_values) + 1)</span>
<span class="c1">#                 elif all(isinstance(v, float) for v in param_values):</span>
<span class="c1">#                     param_distributions[param_name] = uniform(min(param_values), max(param_values) - min(param_values))</span>
<span class="c1">#                 else:</span>
<span class="c1">#                     param_distributions[param_name] = param_values</span>
<span class="c1">#             elif isinstance(param_values, tuple):</span>
<span class="c1">#                 if len(param_values) == 2:</span>
<span class="c1">#                     if all(isinstance(v, int) for v in param_values):</span>
<span class="c1">#                         param_distributions[param_name] = randint(param_values[0], param_values[1] + 1)</span>
<span class="c1">#                     else:</span>
<span class="c1">#                         param_distributions[param_name] = uniform(param_values[0], param_values[1] - param_values[0])</span>
<span class="c1">#                 elif len(param_values) == 3 and param_values[2] == &#39;log&#39;:</span>
<span class="c1">#                     param_distributions[param_name] = loguniform(param_values[0], param_values[1])</span>
<span class="c1">#         return param_distributions</span>




<span class="c1"># class BaseOptimizer_:</span>
<span class="c1">#     &quot;&quot;&quot;</span>
<span class="c1">#     Base class for hyperparameter optimization with support for:</span>
<span class="c1">#     - GridSearchCV (exhaustive)</span>
<span class="c1">#     - RandomizedSearchCV (random)</span>
<span class="c1">#     - Optuna (Bayesian)</span>
<span class="c1">#     &quot;&quot;&quot;</span>
    
<span class="c1">#     def __init__(self, optimization_method=&quot;grid&quot;, n_trials=20, cv=3, random_state=42):</span>
<span class="c1">#         &quot;&quot;&quot;</span>
<span class="c1">#         Parameters</span>
<span class="c1">#         ----------</span>
<span class="c1">#         optimization_method : str</span>
<span class="c1">#             One of: &quot;grid&quot;, &quot;random&quot;, &quot;optuna&quot;</span>
<span class="c1">#         n_trials : int</span>
<span class="c1">#             Number of trials for random/optuna optimization</span>
<span class="c1">#         cv : int</span>
<span class="c1">#             Cross-validation folds</span>
<span class="c1">#         random_state : int</span>
<span class="c1">#             Random seed for reproducibility</span>
<span class="c1">#         &quot;&quot;&quot;</span>
<span class="c1">#         self.optimization_method = optimization_method</span>
<span class="c1">#         self.n_trials = n_trials</span>
<span class="c1">#         self.cv = cv</span>
<span class="c1">#         self.random_state = random_state</span>
        
<span class="c1">#     def optimize(self, model, param_space, X, y, scoring=&#39;neg_mean_squared_error&#39;):</span>
<span class="c1">#         &quot;&quot;&quot;</span>
<span class="c1">#         Optimize hyperparameters using specified method.</span>
        
<span class="c1">#         Parameters</span>
<span class="c1">#         ----------</span>
<span class="c1">#         model : sklearn estimator</span>
<span class="c1">#             Model to optimize</span>
<span class="c1">#         param_space : dict</span>
<span class="c1">#             Parameter space for optimization</span>
<span class="c1">#         X : array-like</span>
<span class="c1">#             Features</span>
<span class="c1">#         y : array-like</span>
<span class="c1">#             Target</span>
<span class="c1">#         scoring : str</span>
<span class="c1">#             Scoring metric</span>
            
<span class="c1">#         Returns</span>
<span class="c1">#         -------</span>
<span class="c1">#         dict</span>
<span class="c1">#             Best parameters</span>
<span class="c1">#         &quot;&quot;&quot;</span>
<span class="c1">#         if self.optimization_method == &quot;grid&quot;:</span>
<span class="c1">#             return self._grid_search(model, param_space, X, y, scoring)</span>
<span class="c1">#         elif self.optimization_method == &quot;random&quot;:</span>
<span class="c1">#             return self._random_search(model, param_space, X, y, scoring)</span>
<span class="c1">#         elif self.optimization_method == &quot;bayesian&quot;:</span>
<span class="c1">#             return self._optuna_search(model, param_space, X, y, scoring)</span>
<span class="c1">#         else:</span>
<span class="c1">#             raise ValueError(f&quot;Unknown optimization method: {self.optimization_method}&quot;)</span>
    
<span class="c1">#     def _grid_search(self, model, param_space, X, y, scoring):</span>
<span class="c1">#         &quot;&quot;&quot;Grid search optimization.&quot;&quot;&quot;</span>
<span class="c1">#         from sklearn.model_selection import GridSearchCV</span>
<span class="c1">#         grid_search = GridSearchCV(</span>
<span class="c1">#             estimator=model,</span>
<span class="c1">#             param_grid=param_space,</span>
<span class="c1">#             cv=self.cv,</span>
<span class="c1">#             scoring=scoring,</span>
<span class="c1">#             n_jobs=-1</span>
<span class="c1">#         )</span>
<span class="c1">#         grid_search.fit(X, y)</span>
<span class="c1">#         return grid_search.best_params_</span>
    
<span class="c1">#     def _random_search(self, model, param_space, X, y, scoring):</span>
<span class="c1">#         &quot;&quot;&quot;Random search optimization.&quot;&quot;&quot;</span>
<span class="c1">#         from sklearn.model_selection import RandomizedSearchCV</span>
<span class="c1">#         # Convert lists to distributions for random search</span>
<span class="c1">#         param_distributions = self._convert_to_distributions(param_space)</span>
        
<span class="c1">#         random_search = RandomizedSearchCV(</span>
<span class="c1">#             estimator=model,</span>
<span class="c1">#             param_distributions=param_distributions,</span>
<span class="c1">#             n_iter=self.n_trials,</span>
<span class="c1">#             cv=self.cv,</span>
<span class="c1">#             scoring=scoring,</span>
<span class="c1">#             random_state=self.random_state,</span>
<span class="c1">#             n_jobs=-1</span>
<span class="c1">#         )</span>
<span class="c1">#         random_search.fit(X, y)</span>
<span class="c1">#         return random_search.best_params_</span>
    
<span class="c1">#     def _optuna_search(self, model, param_space, X, y, scoring):</span>
<span class="c1">#         &quot;&quot;&quot;Optuna Bayesian optimization.&quot;&quot;&quot;</span>
<span class="c1">#         # Define objective function for Optuna</span>
<span class="c1">#         def objective(trial):</span>
<span class="c1">#             # Suggest parameters based on param_space</span>
<span class="c1">#             params = {}</span>
<span class="c1">#             for param_name, param_values in param_space.items():</span>
<span class="c1">#                 if isinstance(param_values, list):</span>
<span class="c1">#                     if all(isinstance(v, int) for v in param_values):</span>
<span class="c1">#                         params[param_name] = trial.suggest_categorical(param_name, param_values)</span>
<span class="c1">#                     elif all(isinstance(v, float) for v in param_values):</span>
<span class="c1">#                         params[param_name] = trial.suggest_float(param_name, min(param_values), max(param_values))</span>
<span class="c1">#                     else:</span>
<span class="c1">#                         params[param_name] = trial.suggest_categorical(param_name, param_values)</span>
<span class="c1">#                 elif isinstance(param_values, tuple) and len(param_values) == 2:</span>
<span class="c1">#                     # Assume (low, high) for continuous or (low, high, &#39;log&#39;) for log scale</span>
<span class="c1">#                     if len(param_values) == 3 and param_values[2] == &#39;log&#39;:</span>
<span class="c1">#                         params[param_name] = trial.suggest_float(param_name, param_values[0], param_values[1], log=True)</span>
<span class="c1">#                     else:</span>
<span class="c1">#                         params[param_name] = trial.suggest_float(param_name, param_values[0], param_values[1])</span>
            
<span class="c1">#             # Create and cross-validate model</span>
<span class="c1">#             model_instance = model.__class__(**params)</span>
<span class="c1">#             from sklearn.model_selection import cross_val_score</span>
<span class="c1">#             scores = cross_val_score(model_instance, X, y, cv=self.cv, scoring=scoring)</span>
<span class="c1">#             return scores.mean()</span>
        
<span class="c1">#         # Create study and optimize</span>
<span class="c1">#         study = optuna.create_study(direction=&quot;maximize&quot;, sampler=optuna.samplers.TPESampler(seed=self.random_state))</span>
<span class="c1">#         study.optimize(objective, n_trials=self.n_trials, show_progress_bar=False)</span>
        
<span class="c1">#         return study.best_params</span>
    
<span class="c1">#     def _convert_to_distributions(self, param_space):</span>
<span class="c1">#         &quot;&quot;&quot;Convert parameter space to distributions for random search.&quot;&quot;&quot;</span>
<span class="c1">#         param_distributions = {}</span>
<span class="c1">#         for param_name, param_values in param_space.items():</span>
<span class="c1">#             if isinstance(param_values, list):</span>
<span class="c1">#                 if all(isinstance(v, int) for v in param_values):</span>
<span class="c1">#                     param_distributions[param_name] = randint(min(param_values), max(param_values) + 1)</span>
<span class="c1">#                 elif all(isinstance(v, float) for v in param_values):</span>
<span class="c1">#                     param_distributions[param_name] = uniform(min(param_values), max(param_values) - min(param_values))</span>
<span class="c1">#                 else:</span>
<span class="c1">#                     param_distributions[param_name] = param_values</span>
<span class="c1">#             elif isinstance(param_values, tuple):</span>
<span class="c1">#                 if len(param_values) == 2:</span>
<span class="c1">#                     if all(isinstance(v, int) for v in param_values):</span>
<span class="c1">#                         param_distributions[param_name] = randint(param_values[0], param_values[1] + 1)</span>
<span class="c1">#                     else:</span>
<span class="c1">#                         param_distributions[param_name] = uniform(param_values[0], param_values[1] - param_values[0])</span>
<span class="c1">#                 elif len(param_values) == 3 and param_values[2] == &#39;log&#39;:</span>
<span class="c1">#                     param_distributions[param_name] = loguniform(param_values[0], param_values[1])</span>
<span class="c1">#         return param_distributions</span>


<div class="viewcode-block" id="WAS_SVR">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_SVR">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">WAS_SVR</span><span class="p">:</span>
<div class="viewcode-block" id="WAS_SVR.__init__">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_SVR.__init__">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> 
        <span class="n">nb_cores</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
        <span class="n">n_clusters</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> 
        <span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span>
        <span class="n">gamma</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">C_range</span><span class="o">=</span><span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span> 
        <span class="n">epsilon_range</span><span class="o">=</span><span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> 
        <span class="n">degree_range</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span>
        <span class="n">dist_method</span><span class="o">=</span><span class="s2">&quot;nonparam&quot;</span><span class="p">,</span>
        <span class="n">optimization_method</span><span class="o">=</span><span class="s2">&quot;grid&quot;</span><span class="p">,</span>  <span class="c1"># optimization method &quot;grid&quot;, &quot;random&quot;, &quot;bayesian&quot; </span>
        <span class="n">n_trials</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>   <span class="c1"># number of trials for random/optuna</span>
        <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>  
        <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>  <span class="c1"># random seed</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span> <span class="o">=</span> <span class="n">nb_cores</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span> <span class="o">=</span> <span class="n">n_clusters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="o">=</span> <span class="n">kernel</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">gamma</span> <span class="k">if</span> <span class="n">gamma</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">[</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="s2">&quot;scale&quot;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">C_range</span> <span class="o">=</span> <span class="n">C_range</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon_range</span> <span class="o">=</span> <span class="n">epsilon_range</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">degree_range</span> <span class="o">=</span> <span class="n">degree_range</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dist_method</span> <span class="o">=</span> <span class="n">dist_method</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimization_method</span> <span class="o">=</span> <span class="n">optimization_method</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_trials</span> <span class="o">=</span> <span class="n">n_trials</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cv</span> <span class="o">=</span> <span class="n">cv</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span>
        
        <span class="c1"># Initialize optimizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">BaseOptimizer</span><span class="p">(</span>
            <span class="n">optimization_method</span><span class="o">=</span><span class="n">optimization_method</span><span class="p">,</span>
            <span class="n">n_trials</span><span class="o">=</span><span class="n">n_trials</span><span class="p">,</span>
            <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span>
            <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="WAS_SVR.compute_hyperparameters">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_SVR.compute_hyperparameters">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">compute_hyperparameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">predictand</span><span class="p">,</span> <span class="n">predictor</span><span class="p">,</span> <span class="n">clim_year_start</span><span class="p">,</span> <span class="n">clim_year_end</span><span class="p">):</span>
        <span class="n">predictor</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">predictand</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Optimized version with Bayesian optimization.&quot;&quot;&quot;</span>
        <span class="c1"># Step 1: Perform KMeans clustering</span>
        <span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
        
        <span class="n">predictand_dropna</span> <span class="o">=</span> <span class="n">predictand</span><span class="o">.</span><span class="n">to_dataframe</span><span class="p">()</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">])</span>
        <span class="n">variable_column</span> <span class="o">=</span> <span class="n">predictand_dropna</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
        <span class="n">predictand_dropna</span><span class="p">[</span><span class="s1">&#39;cluster&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span>
            <span class="n">predictand_dropna</span><span class="p">[[</span><span class="n">variable_column</span><span class="p">]]</span>
        <span class="p">)</span>
        
        <span class="n">df_unique</span> <span class="o">=</span> <span class="n">predictand_dropna</span><span class="o">.</span><span class="n">drop_duplicates</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">])</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">df_unique</span><span class="o">.</span><span class="n">set_index</span><span class="p">([</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">to_xarray</span><span class="p">()</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="o">~</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">predictand</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="mi">0</span><span class="p">)),</span> <span class="mi">1</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
        <span class="n">Cluster</span> <span class="o">=</span> <span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;cluster&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="n">mask</span><span class="p">)</span>
        
        <span class="n">xarray1</span><span class="p">,</span> <span class="n">xarray2</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">align</span><span class="p">(</span><span class="n">predictand</span><span class="p">,</span> <span class="n">Cluster</span><span class="p">,</span> <span class="n">join</span><span class="o">=</span><span class="s2">&quot;outer&quot;</span><span class="p">)</span>
        <span class="n">clusters</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">xarray2</span><span class="p">)</span>
        <span class="n">clusters</span> <span class="o">=</span> <span class="n">clusters</span><span class="p">[</span><span class="o">~</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">clusters</span><span class="p">)]</span>
        
        <span class="n">cluster_means</span> <span class="o">=</span> <span class="p">{</span>
            <span class="nb">int</span><span class="p">(</span><span class="n">cluster</span><span class="p">):</span> <span class="n">xarray1</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">xarray2</span> <span class="o">==</span> <span class="n">cluster</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">],</span> <span class="n">skipna</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">cluster</span> <span class="ow">in</span> <span class="n">clusters</span>
        <span class="p">}</span>

        <span class="c1"># Step 2: Prepare parameter space based on kernel</span>
        <span class="n">param_space</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="s1">&#39;all&#39;</span><span class="p">]:</span>
            <span class="n">param_space</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                <span class="s1">&#39;kernel&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;linear&#39;</span><span class="p">],</span> 
                <span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">C_range</span><span class="p">,</span> 
                <span class="s1">&#39;epsilon&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon_range</span>
            <span class="p">})</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;poly&#39;</span><span class="p">,</span> <span class="s1">&#39;all&#39;</span><span class="p">]:</span>
            <span class="n">param_space</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                <span class="s1">&#39;kernel&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;poly&#39;</span><span class="p">],</span> 
                <span class="s1">&#39;degree&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree_range</span><span class="p">,</span> 
                <span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">C_range</span><span class="p">,</span> 
                <span class="s1">&#39;epsilon&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon_range</span>
            <span class="p">})</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;rbf&#39;</span><span class="p">,</span> <span class="s1">&#39;all&#39;</span><span class="p">]:</span>
            <span class="n">param_space</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                <span class="s1">&#39;kernel&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;rbf&#39;</span><span class="p">],</span> 
                <span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">C_range</span><span class="p">,</span> 
                <span class="s1">&#39;epsilon&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon_range</span><span class="p">,</span> 
                <span class="s1">&#39;gamma&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span>
            <span class="p">})</span>

        <span class="n">hyperparams_cluster</span> <span class="o">=</span> <span class="p">{}</span>
        
        <span class="c1"># Step 3: Optimize for each cluster</span>
        <span class="k">for</span> <span class="n">cluster_label</span> <span class="ow">in</span> <span class="n">clusters</span><span class="p">:</span>
            <span class="n">cluster_mean</span> <span class="o">=</span> <span class="n">cluster_means</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">cluster_label</span><span class="p">)]</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="s1">&#39;T&#39;</span><span class="p">)</span>
            <span class="n">predictor</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">cluster_mean</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span>
            <span class="n">common_times</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">intersect1d</span><span class="p">(</span><span class="n">cluster_mean</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">predictor</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
            
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">common_times</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">continue</span>

            <span class="n">cluster_mean_common</span> <span class="o">=</span> <span class="n">cluster_mean</span><span class="o">.</span><span class="n">sel</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="n">common_times</span><span class="p">)</span>
            <span class="n">predictor_common</span> <span class="o">=</span> <span class="n">predictor</span><span class="o">.</span><span class="n">sel</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="n">common_times</span><span class="p">)</span>

            <span class="n">y_cluster</span> <span class="o">=</span> <span class="n">cluster_mean_common</span><span class="o">.</span><span class="n">values</span>
            <span class="k">if</span> <span class="n">y_cluster</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="c1"># Use optimizer to find best parameters</span>
                <span class="n">svr</span> <span class="o">=</span> <span class="n">SVR</span><span class="p">()</span>
                <span class="n">model</span> <span class="o">=</span> <span class="n">TransformedTargetRegressor</span><span class="p">(</span><span class="n">regressor</span><span class="o">=</span><span class="n">svr</span><span class="p">,</span>
                                                          <span class="n">transformer</span><span class="o">=</span><span class="n">StandardScaler</span><span class="p">()</span>
                                                         <span class="p">)</span>
                <span class="n">best_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span>
                    <span class="n">model</span><span class="p">,</span> 
                    <span class="n">param_space</span><span class="p">,</span> 
                    <span class="n">predictor_common</span><span class="p">,</span> 
                    <span class="n">y_cluster</span>
                <span class="p">)</span>
                
                <span class="n">hyperparams_cluster</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">cluster_label</span><span class="p">)]</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="n">best_params</span><span class="p">[</span><span class="s1">&#39;C&#39;</span><span class="p">],</span>
                    <span class="s1">&#39;epsilon&#39;</span><span class="p">:</span> <span class="n">best_params</span><span class="p">[</span><span class="s1">&#39;epsilon&#39;</span><span class="p">],</span>
                    <span class="s1">&#39;kernel&#39;</span><span class="p">:</span> <span class="n">best_params</span><span class="p">[</span><span class="s1">&#39;kernel&#39;</span><span class="p">],</span>
                    <span class="s1">&#39;degree&#39;</span><span class="p">:</span> <span class="n">best_params</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;degree&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
                    <span class="s1">&#39;gamma&#39;</span><span class="p">:</span> <span class="n">best_params</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;gamma&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
                <span class="p">}</span>
    
        <span class="c1"># Step 4: Create DataArrays for best parameters</span>
        <span class="n">C_array</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">Cluster</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
        <span class="n">epsilon_array</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">Cluster</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
        <span class="n">degree_array</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">Cluster</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
        <span class="n">kernel_array</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">Cluster</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">object</span><span class="p">)</span>
        <span class="n">gamma_array</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">Cluster</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">object</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">cluster_label</span><span class="p">,</span> <span class="n">params</span> <span class="ow">in</span> <span class="n">hyperparams_cluster</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">mask</span> <span class="o">=</span> <span class="n">Cluster</span> <span class="o">==</span> <span class="n">cluster_label</span>
            <span class="n">C_array</span> <span class="o">=</span> <span class="n">C_array</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="o">~</span><span class="n">mask</span><span class="p">,</span> <span class="n">other</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;C&#39;</span><span class="p">])</span>
            <span class="n">epsilon_array</span> <span class="o">=</span> <span class="n">epsilon_array</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="o">~</span><span class="n">mask</span><span class="p">,</span> <span class="n">other</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;epsilon&#39;</span><span class="p">])</span>
            <span class="n">degree_array</span> <span class="o">=</span> <span class="n">degree_array</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="o">~</span><span class="n">mask</span><span class="p">,</span> <span class="n">other</span><span class="o">=</span><span class="n">params</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;degree&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">))</span>
            <span class="n">kernel_array</span> <span class="o">=</span> <span class="n">kernel_array</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="o">~</span><span class="n">mask</span><span class="p">,</span> <span class="n">other</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;kernel&#39;</span><span class="p">])</span>
            <span class="n">gamma_array</span> <span class="o">=</span> <span class="n">gamma_array</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="o">~</span><span class="n">mask</span><span class="p">,</span> <span class="n">other</span><span class="o">=</span><span class="n">params</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;gamma&#39;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">))</span>
    
        <span class="n">C_array</span><span class="p">,</span> <span class="n">epsilon_array</span><span class="p">,</span> <span class="n">degree_array</span><span class="p">,</span> <span class="n">Cluster</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">align</span><span class="p">(</span>
            <span class="n">C_array</span><span class="p">,</span> <span class="n">epsilon_array</span><span class="p">,</span> <span class="n">degree_array</span><span class="p">,</span> <span class="n">Cluster</span><span class="p">,</span> 
            <span class="n">predictand</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">drop_vars</span><span class="p">(</span><span class="s1">&#39;T&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> 
            <span class="n">join</span><span class="o">=</span><span class="s2">&quot;outer&quot;</span>
        <span class="p">)</span>
        
        <span class="c1"># Align kernel and gamma arrays</span>
        <span class="n">kernel_array</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">align</span><span class="p">(</span><span class="n">kernel_array</span><span class="p">,</span> <span class="n">Cluster</span><span class="p">,</span> <span class="n">join</span><span class="o">=</span><span class="s2">&quot;outer&quot;</span><span class="p">)</span>
        <span class="n">gamma_array</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">align</span><span class="p">(</span><span class="n">gamma_array</span><span class="p">,</span> <span class="n">Cluster</span><span class="p">,</span> <span class="n">join</span><span class="o">=</span><span class="s2">&quot;outer&quot;</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">C_array</span><span class="p">,</span> <span class="n">epsilon_array</span><span class="p">,</span> <span class="n">degree_array</span><span class="p">,</span> <span class="n">Cluster</span><span class="p">,</span> <span class="n">kernel_array</span><span class="p">,</span> <span class="n">gamma_array</span></div>


<div class="viewcode-block" id="WAS_SVR.fit_predict">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_SVR.fit_predict">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">fit_predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">degree</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fits an SVR model to the provided training data, makes predictions on the test data, </span>
<span class="sd">        and calculates the prediction error.</span>

<span class="sd">        We handle data-type issues (e.g., bytes input), set up the SVR with the requested</span>
<span class="sd">        parameters, fit it, and return both the error and the prediction.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        x : array-like, shape (n_samples, n_features)</span>
<span class="sd">            Training predictors.</span>
<span class="sd">        y : array-like, shape (n_samples,)</span>
<span class="sd">            Training targets.</span>
<span class="sd">        x_test : array-like, shape (n_features,)</span>
<span class="sd">            Test predictors.</span>
<span class="sd">        y_test : float or None</span>
<span class="sd">            Test target value. Used to calculate error if available.</span>
<span class="sd">        epsilon : float</span>
<span class="sd">            Epsilon parameter for SVR (defines epsilon-tube).</span>
<span class="sd">        C : float</span>
<span class="sd">            Regularization parameter for SVR.</span>
<span class="sd">        degree : int, optional</span>
<span class="sd">            Degree for &#39;poly&#39; kernel. Ignored if kernel != &#39;poly&#39;.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        np.ndarray</span>
<span class="sd">            A 2-element array containing [error, prediction].</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Convert any byte-string parameters to standard Python strings/integers</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="p">,</span> <span class="nb">bytes</span><span class="p">):</span>
            <span class="n">kernel</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">degree</span><span class="p">,</span> <span class="nb">bytes</span><span class="p">)</span> <span class="ow">and</span> <span class="n">degree</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">degree</span><span class="p">):</span>
            <span class="n">degree</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">degree</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gamma</span><span class="p">,</span> <span class="nb">bytes</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">gamma</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span>
        
        <span class="c1"># Ensure &#39;degree&#39; has a valid numeric default if not properly set</span>
        <span class="k">if</span> <span class="n">degree</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">degree</span> <span class="o">==</span> <span class="s1">&#39;nan&#39;</span> <span class="ow">or</span> <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">degree</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span> <span class="ow">and</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">degree</span><span class="p">)):</span>
            <span class="n">degree</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">degree</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">degree</span><span class="p">))</span>

        <span class="c1"># Prepare model parameters based on kernel type</span>
        <span class="n">model_params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;kernel&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="p">,</span> <span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="n">C</span><span class="p">,</span> <span class="s1">&#39;epsilon&#39;</span><span class="p">:</span> <span class="n">epsilon</span><span class="p">}</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="o">==</span> <span class="s1">&#39;poly&#39;</span> <span class="ow">and</span> <span class="n">degree</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">model_params</span><span class="p">[</span><span class="s1">&#39;degree&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">degree</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="o">==</span> <span class="s1">&#39;rbf&#39;</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">model_params</span><span class="p">[</span><span class="s1">&#39;gamma&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># Instantiate the SVR model with chosen parameters</span>
        <span class="n">svr</span> <span class="o">=</span> <span class="n">SVR</span><span class="p">(</span><span class="o">**</span><span class="n">model_params</span><span class="p">)</span>
        
        <span class="n">model</span> <span class="o">=</span> <span class="n">TransformedTargetRegressor</span><span class="p">(</span>
            <span class="n">regressor</span><span class="o">=</span><span class="n">svr</span><span class="p">,</span>
            <span class="n">transformer</span><span class="o">=</span><span class="n">StandardScaler</span><span class="p">()</span>
<span class="p">)</span>

        <span class="c1"># Check for valid (finite) training data</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">&amp;</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Train only if there&#39;s valid data</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">mask</span><span class="p">):</span>
            <span class="n">y_clean</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>
            <span class="n">x_clean</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">mask</span><span class="p">,</span> <span class="p">:]</span>

            <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_clean</span><span class="p">,</span> <span class="n">y_clean</span><span class="p">)</span>

            <span class="c1"># If x_test is 1-D, reshape into 2-D for prediction</span>
            <span class="k">if</span> <span class="n">x_test</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">x_test</span> <span class="o">=</span> <span class="n">x_test</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

            <span class="c1"># Make predictions</span>
            <span class="n">preds</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>

            <span class="c1"># Ensuring no negative predictions (if that applies to your data domain, e.g., rainfall)</span>
            <span class="n">preds</span><span class="p">[</span><span class="n">preds</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="c1"># Calculate error, if y_test is valid</span>
            <span class="k">if</span> <span class="n">y_test</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">y_test</span><span class="p">):</span>
                <span class="n">error_</span> <span class="o">=</span> <span class="n">y_test</span> <span class="o">-</span> <span class="n">preds</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">error_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>

            <span class="c1"># Return [error, prediction] as a flattened array</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">error_</span><span class="p">,</span> <span class="n">preds</span><span class="p">])</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># If there&#39;s no valid training data, return NaNs</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">])</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span></div>


    
<div class="viewcode-block" id="WAS_SVR.compute_model">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_SVR.compute_model">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">compute_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">degree_array</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes predictions for spatiotemporal data using SVR with parallel processing via Dask.</span>

<span class="sd">        We break the data into chunks, apply the `fit_predict` function in parallel,</span>
<span class="sd">        and combine the results into an output DataArray.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X_train : xarray.DataArray</span>
<span class="sd">            Training predictors with dimensions (&#39;T&#39;, &#39;features&#39;).</span>
<span class="sd">        y_train : xarray.DataArray</span>
<span class="sd">            Training targets with dimensions (&#39;T&#39;, &#39;Y&#39;, &#39;X&#39;).</span>
<span class="sd">        X_test : xarray.DataArray</span>
<span class="sd">            Test predictors with dimensions (&#39;features&#39;,).</span>
<span class="sd">        y_test : xarray.DataArray</span>
<span class="sd">            Test target values with dimensions (&#39;Y&#39;, &#39;X&#39;).</span>
<span class="sd">        epsilon : xarray.DataArray</span>
<span class="sd">            Epsilon hyperparameters per grid point.</span>
<span class="sd">        C : xarray.DataArray</span>
<span class="sd">            C hyperparameters per grid point.</span>
<span class="sd">        degree_array : xarray.DataArray, optional</span>
<span class="sd">            Polynomial degrees per grid point (only used if kernel=&#39;poly&#39;).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        xarray.DataArray</span>
<span class="sd">            Predictions &amp; errors, stacked along a new &#39;output&#39; dimension (size=2).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Determine chunk sizes so each worker handles a portion of the spatial domain</span>
        <span class="n">chunksize_x</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="o">.</span><span class="n">get_index</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">))</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span><span class="p">))</span>
        <span class="n">chunksize_y</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="o">.</span><span class="n">get_index</span><span class="p">(</span><span class="s2">&quot;Y&quot;</span><span class="p">))</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span><span class="p">))</span>

        <span class="c1"># Align time dimension in X_train with y_train</span>
        <span class="n">X_train</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span>
        <span class="n">y_train</span> <span class="o">=</span> <span class="n">y_train</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="s1">&#39;T&#39;</span><span class="p">,</span> <span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">)</span>
        
        <span class="c1"># Squeeze out any singleton dimension in X_test / y_test</span>
        <span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
        <span class="n">y_test</span> <span class="o">=</span> <span class="n">y_test</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">)</span>

        <span class="c1"># Create a Dask client for parallel processing</span>
        <span class="n">client</span> <span class="o">=</span> <span class="n">Client</span><span class="p">(</span><span class="n">n_workers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span><span class="p">,</span> <span class="n">threads_per_worker</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Apply `fit_predict` across each (Y,X) grid cell in parallel</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">,</span>
            <span class="n">X_train</span><span class="p">,</span>
            <span class="n">y_train</span><span class="o">.</span><span class="n">chunk</span><span class="p">({</span><span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">chunksize_y</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">chunksize_x</span><span class="p">}),</span>
            <span class="n">X_test</span><span class="p">,</span>
            <span class="n">y_test</span><span class="o">.</span><span class="n">chunk</span><span class="p">({</span><span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">chunksize_y</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">chunksize_x</span><span class="p">}),</span>
            <span class="n">epsilon</span><span class="o">.</span><span class="n">chunk</span><span class="p">({</span><span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">chunksize_y</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">chunksize_x</span><span class="p">}),</span>
            <span class="n">C</span><span class="o">.</span><span class="n">chunk</span><span class="p">({</span><span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">chunksize_y</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">chunksize_x</span><span class="p">}),</span>
            <span class="n">degree_array</span><span class="o">.</span><span class="n">chunk</span><span class="p">({</span><span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">chunksize_y</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">chunksize_x</span><span class="p">})</span> <span class="k">if</span> <span class="n">degree_array</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">xr</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">epsilon</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
            <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[</span>
                <span class="p">(</span><span class="s1">&#39;T&#39;</span><span class="p">,</span> <span class="s1">&#39;features&#39;</span><span class="p">),</span>  <span class="c1"># x</span>
                <span class="p">(</span><span class="s1">&#39;T&#39;</span><span class="p">,),</span>             <span class="c1"># y</span>
                <span class="p">(</span><span class="s1">&#39;features&#39;</span><span class="p">,),</span>      <span class="c1"># x_test</span>
                <span class="p">(),</span>                 <span class="c1"># y_test</span>
                <span class="p">(),</span>                 <span class="c1"># epsilon</span>
                <span class="p">(),</span>                 <span class="c1"># C</span>
                <span class="p">()</span>                  <span class="c1"># degree</span>
            <span class="p">],</span>
            <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s1">&#39;output&#39;</span><span class="p">,)],</span>
            <span class="n">dask</span><span class="o">=</span><span class="s1">&#39;parallelized&#39;</span><span class="p">,</span>
            <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;float&#39;</span><span class="p">],</span>
            <span class="n">dask_gufunc_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;output_sizes&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;output&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">}},</span>
        <span class="p">)</span>

        <span class="c1"># Trigger actual computation</span>
        <span class="n">result_</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>

        <span class="c1"># Close the Dask client</span>
        <span class="n">client</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

        <span class="c1"># Return the results, containing both errors and predictions</span>
        <span class="k">return</span> <span class="n">result_</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">output</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></div>


<div class="viewcode-block" id="WAS_SVR._ppf_terciles_from_code">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_SVR._ppf_terciles_from_code">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="c1"># ------------------ Probability Calculation Methods ------------------</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_ppf_terciles_from_code</span><span class="p">(</span><span class="n">dist_code</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return tercile thresholds (T1, T2) from best-fit distribution parameters.</span>
<span class="sd">    </span>
<span class="sd">        dist_code:</span>
<span class="sd">            1: norm</span>
<span class="sd">            2: lognorm</span>
<span class="sd">            3: expon</span>
<span class="sd">            4: gamma</span>
<span class="sd">            5: weibull_min</span>
<span class="sd">            6: t</span>
<span class="sd">            7: poisson</span>
<span class="sd">            8: nbinom</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">dist_code</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
    
        <span class="n">code</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">dist_code</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                    <span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">lognorm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                    <span class="n">lognorm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">expon</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                    <span class="n">expon</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">gamma</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                    <span class="n">gamma</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">5</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">weibull_min</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                    <span class="n">weibull_min</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">6</span><span class="p">:</span>
                <span class="c1"># Note: Renamed &#39;t_dist&#39; to &#39;t&#39; for standard scipy.stats</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">t</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                    <span class="n">t</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">7</span><span class="p">:</span>
                <span class="c1"># Poisson: poisson.ppf(q, mu, loc=0)</span>
                <span class="c1"># ASSUMPTION: &#39;mu&#39; (mean) is passed as &#39;shape&#39;</span>
                <span class="c1">#             &#39;loc&#39; is passed as &#39;loc&#39;</span>
                <span class="c1">#             &#39;scale&#39; is unused</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">poisson</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">),</span>
                    <span class="n">poisson</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">8</span><span class="p">:</span>
                <span class="c1"># Negative Binomial: nbinom.ppf(q, n, p, loc=0)</span>
                <span class="c1"># ASSUMPTION: &#39;n&#39; (successes) is passed as &#39;shape&#39;</span>
                <span class="c1">#             &#39;p&#39; (probability) is passed as &#39;scale&#39;</span>
                <span class="c1">#             &#39;loc&#39; is passed as &#39;loc&#39;</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">nbinom</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">scale</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">),</span>
                    <span class="n">nbinom</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">scale</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">),</span>
                <span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
    
        <span class="c1"># Fallback if code is not 1-8</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span></div>

        
<div class="viewcode-block" id="WAS_SVR.weibull_shape_solver">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_SVR.weibull_shape_solver">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">weibull_shape_solver</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">V</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Function to find the root of the Weibull shape parameter &#39;k&#39;.</span>
<span class="sd">        We find &#39;k&#39; such that the theoretical variance/mean^2 ratio</span>
<span class="sd">        matches the observed V/M^2 ratio.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Guard against invalid &#39;k&#39; values during solving</span>
        <span class="k">if</span> <span class="n">k</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">g1</span> <span class="o">=</span> <span class="n">gamma_function</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="mi">1</span><span class="o">/</span><span class="n">k</span><span class="p">)</span>
            <span class="n">g2</span> <span class="o">=</span> <span class="n">gamma_function</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="mi">2</span><span class="o">/</span><span class="n">k</span><span class="p">)</span>
            
            <span class="c1"># This is the V/M^2 ratio *implied by k*</span>
            <span class="n">implied_v_over_m_sq</span> <span class="o">=</span> <span class="p">(</span><span class="n">g2</span> <span class="o">/</span> <span class="p">(</span><span class="n">g1</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span> <span class="o">-</span> <span class="mi">1</span>
            
            <span class="c1"># This is the *observed* ratio</span>
            <span class="n">observed_v_over_m_sq</span> <span class="o">=</span> <span class="n">V</span> <span class="o">/</span> <span class="p">(</span><span class="n">M</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
            
            <span class="c1"># Return the difference (we want this to be 0)</span>
            <span class="k">return</span> <span class="n">observed_v_over_m_sq</span> <span class="o">-</span> <span class="n">implied_v_over_m_sq</span>
        <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
            <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span> <span class="c1"># Handle math errors</span></div>


<div class="viewcode-block" id="WAS_SVR.calculate_tercile_probabilities_bestfit">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_SVR.calculate_tercile_probabilities_bestfit">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">calculate_tercile_probabilities_bestfit</span><span class="p">(</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">error_variance</span><span class="p">,</span> <span class="n">T1</span><span class="p">,</span> <span class="n">T2</span><span class="p">,</span> <span class="n">dist_code</span><span class="p">,</span> <span class="n">dof</span> 
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generic tercile probabilities using best-fit family per grid cell.</span>

<span class="sd">        Inputs (per grid cell):</span>
<span class="sd">        - best_guess : 1D array over T (hindcast_det or forecast_det)</span>
<span class="sd">        - T1, T2     : scalar terciles from climatological best-fit distribution</span>
<span class="sd">        - dist_code  : int, as in _ppf_terciles_from_code</span>
<span class="sd">        - shape, loc, scale : scalars from climatology fit</span>

<span class="sd">        Strategy:</span>
<span class="sd">        - For each time step, build a predictive distribution of the same family:</span>
<span class="sd">            * Use best_guess[t] to adjust mean / location;</span>
<span class="sd">            * Keep shape parameters from climatology.</span>
<span class="sd">        - Then compute probabilities:</span>
<span class="sd">            P(B) = F(T1), P(N) = F(T2) - F(T1), P(A) = 1 - F(T2).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        
        <span class="n">best_guess</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">best_guess</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span>
        <span class="n">error_variance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">error_variance</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
        <span class="c1"># T1 = np.asarray(T1, dtype=float)</span>
        <span class="c1"># T2 = np.asarray(T2, dtype=float)</span>
        <span class="n">n_time</span> <span class="o">=</span> <span class="n">best_guess</span><span class="o">.</span><span class="n">size</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="n">n_time</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">best_guess</span><span class="p">))</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">dist_code</span><span class="p">)</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">T1</span><span class="p">)</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">T2</span><span class="p">)</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">error_variance</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">out</span>

        <span class="n">code</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">dist_code</span><span class="p">)</span>

        <span class="c1"># Normal: loc = forecast; scale from clim</span>
        <span class="k">if</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">error_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">error_variance</span><span class="p">)</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">error_std</span><span class="p">)</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">error_std</span><span class="p">)</span> <span class="o">-</span> <span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">error_std</span><span class="p">)</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">error_std</span><span class="p">)</span>

        <span class="c1"># Lognormal: shape = sigma from clim; enforce mean = best_guess</span>
        <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">sigma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">error_variance</span> <span class="o">/</span> <span class="p">(</span><span class="n">best_guess</span><span class="o">**</span><span class="mi">2</span><span class="p">)))</span>
            <span class="n">mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">best_guess</span><span class="p">)</span> <span class="o">-</span> <span class="n">sigma</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="mi">2</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">lognorm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">mu</span><span class="p">))</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">lognorm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">mu</span><span class="p">))</span> <span class="o">-</span> <span class="n">lognorm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">mu</span><span class="p">))</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">lognorm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">mu</span><span class="p">))</span>      


        <span class="c1"># Exponential: keep scale from clim; shift loc so mean = best_guess</span>
        <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
            <span class="n">c1</span> <span class="o">=</span> <span class="n">expon</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">error_variance</span><span class="p">))</span>
            <span class="n">c2</span> <span class="o">=</span> <span class="n">expon</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc_t</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">error_variance</span><span class="p">))</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c2</span> <span class="o">-</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">c2</span>

        <span class="c1"># Gamma: use shape from clim; set scale so mean = best_guess</span>
        <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
            <span class="n">alpha</span> <span class="o">=</span> <span class="p">(</span><span class="n">best_guess</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="n">error_variance</span>
            <span class="n">theta</span> <span class="o">=</span> <span class="n">error_variance</span> <span class="o">/</span> <span class="n">best_guess</span>
            <span class="n">c1</span> <span class="o">=</span> <span class="n">gamma</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">theta</span><span class="p">)</span>
            <span class="n">c2</span> <span class="o">=</span> <span class="n">gamma</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">theta</span><span class="p">)</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c2</span> <span class="o">-</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">c2</span>

        <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">5</span><span class="p">:</span> <span class="c1"># Assuming 5 is for Weibull   </span>
        
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_time</span><span class="p">):</span>
                <span class="c1"># Get the scalar values for this specific element (e.g., grid cell)</span>
                <span class="n">M</span> <span class="o">=</span> <span class="n">best_guess</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">M</span><span class="p">)</span>
                <span class="n">V</span> <span class="o">=</span> <span class="n">error_variance</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">V</span><span class="p">)</span>
                
                <span class="c1"># Handle cases with no variance to avoid division by zero</span>
                <span class="k">if</span> <span class="n">V</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">M</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                    <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                    <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                    <span class="k">continue</span> <span class="c1"># Skip to the next element</span>
        
                <span class="c1"># --- 1. Numerically solve for shape &#39;k&#39; ---</span>
                <span class="c1"># We need a reasonable starting guess. 2.0 is common (Rayleigh dist.)</span>
                <span class="n">initial_guess</span> <span class="o">=</span> <span class="mf">2.0</span>
                
                <span class="c1"># fsolve finds the root of our helper function</span>
                <span class="n">k</span> <span class="o">=</span> <span class="n">fsolve</span><span class="p">(</span><span class="n">weibull_shape_solver</span><span class="p">,</span> <span class="n">initial_guess</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">V</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>
        
                <span class="c1"># --- 2. Check for bad solution and calculate scale &#39;lambda&#39; ---</span>
                <span class="k">if</span> <span class="n">k</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="c1"># Solver failed</span>
                    <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                    <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                    <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                    <span class="k">continue</span>
                
                <span class="c1"># With &#39;k&#39; found, we can now algebraically find scale &#39;lambda&#39;</span>
                <span class="c1"># In scipy.stats, scale is &#39;scale&#39;</span>
                <span class="n">lambda_scale</span> <span class="o">=</span> <span class="n">M</span> <span class="o">/</span> <span class="n">gamma_function</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="mi">1</span><span class="o">/</span><span class="n">k</span><span class="p">)</span>
        
                <span class="c1"># --- 3. Calculate Probabilities ---</span>
                <span class="c1"># In scipy.stats, shape &#39;k&#39; is &#39;c&#39;</span>
                <span class="c1"># Use the T1 and T2 values for this specific element</span>
                
                <span class="n">c1</span> <span class="o">=</span> <span class="n">weibull_min</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">lambda_scale</span><span class="p">)</span>
                <span class="n">c2</span> <span class="o">=</span> <span class="n">weibull_min</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">lambda_scale</span><span class="p">)</span>
        
                <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">c1</span>
                <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">c2</span> <span class="o">-</span> <span class="n">c1</span>
                <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">c2</span>

        <span class="c1"># Student-t: df from clim; scale from clim; loc = best_guess</span>
        <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">6</span><span class="p">:</span>       
            <span class="c1"># Check if df is valid for variance calculation</span>
            <span class="k">if</span> <span class="n">dof</span> <span class="o">&lt;=</span> <span class="mi">2</span><span class="p">:</span>
                <span class="c1"># Cannot calculate scale, fill with NaNs</span>
                <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># 1. Calculate t-distribution parameters</span>
                <span class="c1"># &#39;loc&#39; (mean) is just the best_guess</span>
                <span class="n">loc</span> <span class="o">=</span> <span class="n">best_guess</span>
                <span class="c1"># &#39;scale&#39; is calculated from the variance and df</span>
                <span class="c1"># Variance = scale**2 * (df / (df - 2))</span>
                <span class="n">scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">error_variance</span> <span class="o">*</span> <span class="p">(</span><span class="n">dof</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="n">dof</span><span class="p">)</span>
                
                <span class="c1"># 2. Calculate probabilities</span>
                <span class="n">c1</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">dof</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">)</span>
                <span class="n">c2</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">dof</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">)</span>

                <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c1</span>
                <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c2</span> <span class="o">-</span> <span class="n">c1</span>
                <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">c2</span>

        <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">7</span><span class="p">:</span> <span class="c1"># Assuming 7 is for Poisson</span>
            
            <span class="c1"># --- 1. Set the Poisson parameter &#39;mu&#39; ---</span>
            <span class="c1"># The &#39;mu&#39; parameter is the mean.</span>
            
            <span class="c1"># A warning is strongly recommended if error_variance is different from best_guess</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">error_variance</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Warning: &#39;error_variance&#39; is not equal to &#39;best_guess&#39;.&quot;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Poisson model assumes mean=variance and is likely inappropriate.&quot;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Consider using Negative Binomial.&quot;</span><span class="p">)</span>
            
            <span class="n">mu</span> <span class="o">=</span> <span class="n">best_guess</span>
        
            <span class="c1"># --- 2. Calculate Probabilities ---</span>
            <span class="c1"># poisson.cdf(k, mu) calculates P(X &lt;= k)</span>
            
            <span class="n">c1</span> <span class="o">=</span> <span class="n">poisson</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">mu</span><span class="p">)</span>
            <span class="n">c2</span> <span class="o">=</span> <span class="n">poisson</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">mu</span><span class="p">)</span>
            
            <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c2</span> <span class="o">-</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">c2</span>

        <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">8</span><span class="p">:</span> <span class="c1"># Assuming 8 is for Negative Binomial</span>
            
            <span class="c1"># --- 1. Calculate Negative Binomial Parameters ---</span>
            <span class="c1"># This model is ONLY valid for overdispersion (Variance &gt; Mean).</span>
            <span class="c1"># We will use np.where to set parameters to NaN if V &lt;= M.</span>
            
            <span class="c1"># p = Mean / Variance</span>
            <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">error_variance</span> <span class="o">&gt;</span> <span class="n">best_guess</span><span class="p">,</span> 
                         <span class="n">best_guess</span> <span class="o">/</span> <span class="n">error_variance</span><span class="p">,</span> 
                         <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
            
            <span class="c1"># n = Mean^2 / (Variance - Mean)</span>
            <span class="n">n</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">error_variance</span> <span class="o">&gt;</span> <span class="n">best_guess</span><span class="p">,</span> 
                         <span class="p">(</span><span class="n">best_guess</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">error_variance</span> <span class="o">-</span> <span class="n">best_guess</span><span class="p">),</span> 
                         <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
            
            <span class="c1"># --- 2. Calculate Probabilities ---</span>
            <span class="c1"># The nbinom.cdf function will propagate NaNs, correctly</span>
            <span class="c1"># handling the cases where the model was invalid.</span>
            
            <span class="n">c1</span> <span class="o">=</span> <span class="n">nbinom</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">)</span>
            <span class="n">c2</span> <span class="o">=</span> <span class="n">nbinom</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">)</span>
            
            <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c2</span> <span class="o">-</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">c2</span>
            
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid distribution&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">out</span></div>


<div class="viewcode-block" id="WAS_SVR.calculate_tercile_probabilities_nonparametric">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_SVR.calculate_tercile_probabilities_nonparametric">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">calculate_tercile_probabilities_nonparametric</span><span class="p">(</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">error_samples</span><span class="p">,</span> <span class="n">first_tercile</span><span class="p">,</span> <span class="n">second_tercile</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Non-parametric method using historical error samples.&quot;&quot;&quot;</span>
        <span class="n">n_time</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">best_guess</span><span class="p">)</span>
        <span class="n">pred_prob</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="n">n_time</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_time</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">best_guess</span><span class="p">[</span><span class="n">t</span><span class="p">]):</span>
                <span class="k">continue</span>
            <span class="n">dist</span> <span class="o">=</span> <span class="n">best_guess</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">+</span> <span class="n">error_samples</span>
            <span class="n">dist</span> <span class="o">=</span> <span class="n">dist</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">dist</span><span class="p">)]</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">dist</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="n">p_below</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dist</span> <span class="o">&lt;</span> <span class="n">first_tercile</span><span class="p">)</span>
            <span class="n">p_between</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">dist</span> <span class="o">&gt;=</span> <span class="n">first_tercile</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">dist</span> <span class="o">&lt;</span> <span class="n">second_tercile</span><span class="p">))</span>
            <span class="n">p_above</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="p">(</span><span class="n">p_below</span> <span class="o">+</span> <span class="n">p_between</span><span class="p">)</span>
            <span class="n">pred_prob</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">p_below</span>
            <span class="n">pred_prob</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">p_between</span>
            <span class="n">pred_prob</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">p_above</span>
        <span class="k">return</span> <span class="n">pred_prob</span></div>




<div class="viewcode-block" id="WAS_SVR.compute_prob">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_SVR.compute_prob">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">compute_prob</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">Predictant</span><span class="p">:</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span><span class="p">,</span>
        <span class="n">clim_year_start</span><span class="p">,</span>
        <span class="n">clim_year_end</span><span class="p">,</span>
        <span class="n">hindcast_det</span><span class="p">:</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span><span class="p">,</span>
        <span class="n">best_code_da</span><span class="p">:</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">best_shape_da</span><span class="p">:</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">best_loc_da</span><span class="p">:</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">best_scale_da</span><span class="p">:</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute tercile probabilities for deterministic hindcasts.</span>

<span class="sd">        If dist_method == &#39;bestfit&#39;:</span>
<span class="sd">            - Use cluster-based best-fit distributions to:</span>
<span class="sd">                * derive terciles analytically from (best_code_da, best_shape_da, best_loc_da, best_scale_da),</span>
<span class="sd">                * compute predictive probabilities using the same family.</span>

<span class="sd">        Otherwise:</span>
<span class="sd">            - Use empirical terciles from Predictant climatology and the selected</span>
<span class="sd">              parametric / nonparametric method.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Predictant : xarray.DataArray</span>
<span class="sd">            Observed data (T, Y, X) or (T, Y, X, M).</span>
<span class="sd">        clim_year_start, clim_year_end : int or str</span>
<span class="sd">            Climatology period (inclusive) for thresholds.</span>
<span class="sd">        hindcast_det : xarray.DataArray</span>
<span class="sd">            Deterministic hindcast (T, Y, X).</span>
<span class="sd">        best_code_da, best_shape_da, best_loc_da, best_scale_da : xarray.DataArray, optional</span>
<span class="sd">            Output from WAS_TransformData.fit_best_distribution_grid, required for &#39;bestfit&#39;.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        hindcast_prob : xarray.DataArray</span>
<span class="sd">            Probabilities with dims (probability=[&#39;PB&#39;,&#39;PN&#39;,&#39;PA&#39;], T, Y, X).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Handle member dimension if present</span>
        <span class="k">if</span> <span class="s2">&quot;M&quot;</span> <span class="ow">in</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">dims</span><span class="p">:</span>
            <span class="n">Predictant</span> <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">M</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">drop_vars</span><span class="p">(</span><span class="s2">&quot;M&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>

        <span class="c1"># Ensure dimension order</span>
        <span class="n">Predictant</span> <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="s2">&quot;Y&quot;</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">)</span>

        <span class="c1"># Spatial mask</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="o">~</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">Predictant</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="mi">0</span><span class="p">)),</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>

        <span class="c1"># Climatology subset</span>
        <span class="n">clim</span> <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">sel</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="nb">slice</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">clim_year_start</span><span class="p">),</span> <span class="nb">str</span><span class="p">(</span><span class="n">clim_year_end</span><span class="p">)))</span>
        <span class="k">if</span> <span class="n">clim</span><span class="o">.</span><span class="n">sizes</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">3</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Not enough years in climatology period for terciles.&quot;</span><span class="p">)</span>

        <span class="c1"># Error variance for predictive distributions</span>
        <span class="n">error_variance</span> <span class="o">=</span> <span class="p">(</span><span class="n">Predictant</span> <span class="o">-</span> <span class="n">hindcast_det</span><span class="p">)</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="s2">&quot;T&quot;</span><span class="p">)</span>
        <span class="n">dof</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">clim</span><span class="o">.</span><span class="n">sizes</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">])</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

        <span class="c1"># Empirical terciles (used by non-bestfit methods)</span>
        <span class="n">terciles_emp</span> <span class="o">=</span> <span class="n">clim</span><span class="o">.</span><span class="n">quantile</span><span class="p">([</span><span class="mf">0.32</span><span class="p">,</span> <span class="mf">0.67</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="s2">&quot;T&quot;</span><span class="p">)</span>
        <span class="n">T1_emp</span> <span class="o">=</span> <span class="n">terciles_emp</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">quantile</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">drop_vars</span><span class="p">(</span><span class="s2">&quot;quantile&quot;</span><span class="p">)</span>
        <span class="n">T2_emp</span> <span class="o">=</span> <span class="n">terciles_emp</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">quantile</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">drop_vars</span><span class="p">(</span><span class="s2">&quot;quantile&quot;</span><span class="p">)</span>
        

        <span class="n">dm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dist_method</span>

        <span class="c1"># ---------- BESTFIT: zone-wise optimal distributions ----------</span>
        <span class="k">if</span> <span class="n">dm</span> <span class="o">==</span> <span class="s2">&quot;bestfit&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">v</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="p">(</span><span class="n">best_code_da</span><span class="p">,</span> <span class="n">best_shape_da</span><span class="p">,</span> <span class="n">best_loc_da</span><span class="p">,</span> <span class="n">best_scale_da</span><span class="p">)):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;dist_method=&#39;bestfit&#39; requires best_code_da, best_shape_da_da, best_loc_da, best_scale_da.&quot;</span>
                <span class="p">)</span>

            <span class="c1"># T1, T2 from best-fit distributions (per grid)</span>
            <span class="n">T1</span><span class="p">,</span> <span class="n">T2</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_ppf_terciles_from_code</span><span class="p">,</span>
                <span class="n">best_code_da</span><span class="p">,</span>
                <span class="n">best_shape_da</span><span class="p">,</span>
                <span class="n">best_loc_da</span><span class="p">,</span>
                <span class="n">best_scale_da</span><span class="p">,</span>
                <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[(),</span> <span class="p">(),</span> <span class="p">(),</span> <span class="p">()],</span>
                <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(),</span> <span class="p">()],</span>
                <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">dask</span><span class="o">=</span><span class="s2">&quot;parallelized&quot;</span><span class="p">,</span>
                <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span>
            <span class="p">)</span>

            <span class="c1"># Predictive probabilities using same family</span>
            <span class="n">hindcast_prob</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">calculate_tercile_probabilities_bestfit</span><span class="p">,</span>
                <span class="n">hindcast_det</span><span class="p">,</span>
                <span class="n">error_variance</span><span class="p">,</span>
                <span class="n">T1</span><span class="p">,</span>
                <span class="n">T2</span><span class="p">,</span>
                <span class="n">best_code_da</span><span class="p">,</span>
                <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;T&quot;</span><span class="p">,),</span> <span class="p">(),</span> <span class="p">(),</span> <span class="p">(),</span> <span class="p">()],</span>
                <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;probability&quot;</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">)],</span>
                <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;dof&#39;</span><span class="p">:</span> <span class="n">dof</span><span class="p">},</span>
                <span class="n">dask</span><span class="o">=</span><span class="s2">&quot;parallelized&quot;</span><span class="p">,</span>
                <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>
                <span class="n">dask_gufunc_kwargs</span><span class="o">=</span><span class="p">{</span>
                    <span class="s2">&quot;output_sizes&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;probability&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">},</span>
                    <span class="s2">&quot;allow_rechunk&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                <span class="p">},</span>
            <span class="p">)</span>

        <span class="c1"># ---------- Nonparametric ----------</span>
        <span class="k">elif</span> <span class="n">dm</span> <span class="o">==</span> <span class="s2">&quot;nonparam&quot;</span><span class="p">:</span>
            <span class="n">error_samples</span> <span class="o">=</span> <span class="n">Predictant</span> <span class="o">-</span> <span class="n">hindcast_det</span>
            <span class="n">hindcast_prob</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">calculate_tercile_probabilities_nonparametric</span><span class="p">,</span>
                <span class="n">hindcast_det</span><span class="p">,</span>
                <span class="n">error_samples</span><span class="p">,</span>
                <span class="n">T1_emp</span><span class="p">,</span>
                <span class="n">T2_emp</span><span class="p">,</span>
                <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;T&quot;</span><span class="p">,),</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,),</span> <span class="p">(),</span> <span class="p">()],</span>
                <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;probability&quot;</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">)],</span>
                <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">dask</span><span class="o">=</span><span class="s2">&quot;parallelized&quot;</span><span class="p">,</span>
                <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>
                <span class="n">dask_gufunc_kwargs</span><span class="o">=</span><span class="p">{</span>
                    <span class="s2">&quot;output_sizes&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;probability&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">},</span>
                    <span class="s2">&quot;allow_rechunk&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                <span class="p">},</span>
            <span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid dist_method: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">dist_method</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">hindcast_prob</span> <span class="o">=</span> <span class="n">hindcast_prob</span><span class="o">.</span><span class="n">assign_coords</span><span class="p">(</span>
            <span class="n">probability</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;probability&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;PB&quot;</span><span class="p">,</span> <span class="s2">&quot;PN&quot;</span><span class="p">,</span> <span class="s2">&quot;PA&quot;</span><span class="p">])</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">hindcast_prob</span> <span class="o">*</span> <span class="n">mask</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="s2">&quot;probability&quot;</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="s2">&quot;Y&quot;</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">)</span></div>


        
<div class="viewcode-block" id="WAS_SVR.forecast">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_SVR.forecast">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">forecast</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> 
        <span class="n">Predictant</span><span class="p">,</span> 
        <span class="n">clim_year_start</span><span class="p">,</span> 
        <span class="n">clim_year_end</span><span class="p">,</span> 
        <span class="n">Predictor</span><span class="p">,</span> 
        <span class="n">hindcast_det</span><span class="p">,</span> 
        <span class="n">Predictor_for_year</span><span class="p">,</span> 
        <span class="n">epsilon</span><span class="p">,</span> 
        <span class="n">C</span><span class="p">,</span> 
        <span class="n">kernel_array</span><span class="p">,</span> 
        <span class="n">degree_array</span><span class="p">,</span> 
        <span class="n">gamma_array</span><span class="p">,</span> <span class="n">best_code_da</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">best_shape_da</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">best_loc_da</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">best_scale_da</span><span class="o">=</span><span class="kc">None</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generates forecasts and computes probabilities for a specific year.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Predictant : xarray.DataArray</span>
<span class="sd">            Target variable (T, Y, X).</span>
<span class="sd">        clim_year_start : int</span>
<span class="sd">            Start year for climatology.</span>
<span class="sd">        clim_year_end : int</span>
<span class="sd">            End year for climatology.</span>
<span class="sd">        Predictor : xarray.DataArray</span>
<span class="sd">            Historical predictor data (T, features).</span>
<span class="sd">        hindcast_det : xarray.DataArray</span>
<span class="sd">            Deterministic hindcasts (includes &#39;prediction&#39; and &#39;error&#39; outputs).</span>
<span class="sd">        Predictor_for_year : xarray.DataArray</span>
<span class="sd">            Predictor data for the target forecast year (features).</span>
<span class="sd">        epsilon, C, kernel_array, degree_array, gamma_array : xarray.DataArray</span>
<span class="sd">            Hyperparameter grids for the model.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        tuple</span>
<span class="sd">            1) The forecast results (error, prediction) for that year.</span>
<span class="sd">            2) The corresponding tercile probabilities (PB, PN, PA).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Divide the spatial domain into chunks for parallel computation</span>
        <span class="n">chunksize_x</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">Predictant</span><span class="o">.</span><span class="n">get_index</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">))</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span><span class="p">))</span>
        <span class="n">chunksize_y</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">Predictant</span><span class="o">.</span><span class="n">get_index</span><span class="p">(</span><span class="s2">&quot;Y&quot;</span><span class="p">))</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span><span class="p">))</span>

        <span class="c1"># Ensure time dimension alignment</span>
        <span class="n">Predictor</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">Predictant</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span>
        <span class="n">Predictant</span> <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="s1">&#39;T&#39;</span><span class="p">,</span> <span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">)</span>
        <span class="n">Predictor_for_year_</span> <span class="o">=</span> <span class="n">Predictor_for_year</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>

        <span class="c1"># We don&#39;t have an actual observed y_test for the forecast year, so fill with NaNs</span>
        <span class="n">y_test</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">epsilon</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>

        <span class="c1"># Create a Dask client for parallelization</span>
        <span class="n">client</span> <span class="o">=</span> <span class="n">Client</span><span class="p">(</span><span class="n">n_workers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span><span class="p">,</span> <span class="n">threads_per_worker</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Apply `fit_predict` in parallel across the grid, using the forecast year&#39;s predictors</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">,</span>
            <span class="n">Predictor</span><span class="p">,</span>
            <span class="n">Predictant</span><span class="o">.</span><span class="n">chunk</span><span class="p">({</span><span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">chunksize_y</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">chunksize_x</span><span class="p">}),</span>
            <span class="n">Predictor_for_year_</span><span class="p">,</span>
            <span class="n">y_test</span><span class="o">.</span><span class="n">chunk</span><span class="p">({</span><span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">chunksize_y</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">chunksize_x</span><span class="p">}),</span>
            <span class="n">epsilon</span><span class="o">.</span><span class="n">chunk</span><span class="p">({</span><span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">chunksize_y</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">chunksize_x</span><span class="p">}),</span>
            <span class="n">C</span><span class="o">.</span><span class="n">chunk</span><span class="p">({</span><span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">chunksize_y</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">chunksize_x</span><span class="p">}),</span>
            <span class="n">kernel_array</span><span class="o">.</span><span class="n">chunk</span><span class="p">({</span><span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">chunksize_y</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">chunksize_x</span><span class="p">}),</span>
            <span class="n">degree_array</span><span class="o">.</span><span class="n">chunk</span><span class="p">({</span><span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">chunksize_y</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">chunksize_x</span><span class="p">}),</span>
            <span class="n">gamma_array</span><span class="o">.</span><span class="n">chunk</span><span class="p">({</span><span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">chunksize_y</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">chunksize_x</span><span class="p">}),</span>
            <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[</span>
                <span class="p">(</span><span class="s1">&#39;T&#39;</span><span class="p">,</span> <span class="s1">&#39;features&#39;</span><span class="p">),</span>  <span class="c1"># x (training)</span>
                <span class="p">(</span><span class="s1">&#39;T&#39;</span><span class="p">,),</span>             <span class="c1"># y (training target)</span>
                <span class="p">(</span><span class="s1">&#39;features&#39;</span><span class="p">,),</span>      <span class="c1"># x_test (forecast-year predictors)</span>
                <span class="p">(),</span>                 <span class="c1"># y_test (unknown, hence NaN)</span>
                <span class="p">(),</span>                 <span class="c1"># epsilon</span>
                <span class="p">(),</span>                 <span class="c1"># C</span>
                <span class="p">(),</span>                 <span class="c1"># kernel</span>
                <span class="p">(),</span>                 <span class="c1"># degree</span>
                <span class="p">()</span>                  <span class="c1"># gamma</span>
            <span class="p">],</span>
            <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s1">&#39;output&#39;</span><span class="p">,)],</span>
            <span class="n">dask</span><span class="o">=</span><span class="s1">&#39;parallelized&#39;</span><span class="p">,</span>
            <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;float&#39;</span><span class="p">],</span>
            <span class="n">dask_gufunc_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;output_sizes&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;output&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">}},</span>
        <span class="p">)</span>
        <span class="n">result_</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
        <span class="n">client</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
        <span class="n">result_</span> <span class="o">=</span> <span class="n">result_</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">output</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># result_ =&gt; dims (output=2, Y, X). </span>
        <span class="c1"># For a real future forecast, &quot;error&quot; is NaN, &quot;prediction&quot; is the forecast.</span>

        <span class="c1"># 2) Compute thresholds T1, T2 from climatology</span>
        <span class="n">index_start</span> <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">get_index</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">get_loc</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">clim_year_start</span><span class="p">))</span><span class="o">.</span><span class="n">start</span>
        <span class="n">index_end</span>   <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">get_index</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">get_loc</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">clim_year_end</span><span class="p">))</span><span class="o">.</span><span class="n">stop</span>
        <span class="n">rainfall_for_tercile</span> <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="nb">slice</span><span class="p">(</span><span class="n">index_start</span><span class="p">,</span> <span class="n">index_end</span><span class="p">))</span>
        <span class="n">terciles</span> <span class="o">=</span> <span class="n">rainfall_for_tercile</span><span class="o">.</span><span class="n">quantile</span><span class="p">([</span><span class="mf">0.32</span><span class="p">,</span> <span class="mf">0.67</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="s1">&#39;T&#39;</span><span class="p">)</span>
        <span class="n">T1_emp</span> <span class="o">=</span> <span class="n">terciles</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">quantile</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">drop_vars</span><span class="p">(</span><span class="s1">&#39;quantile&#39;</span><span class="p">)</span>
        <span class="n">T2_emp</span> <span class="o">=</span> <span class="n">terciles</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">quantile</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">drop_vars</span><span class="p">(</span><span class="s1">&#39;quantile&#39;</span><span class="p">)</span>
        <span class="n">error_variance</span> <span class="o">=</span> <span class="p">(</span><span class="n">Predictant</span> <span class="o">-</span> <span class="n">hindcast_det</span><span class="p">)</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="s1">&#39;T&#39;</span><span class="p">)</span>
        
        <span class="c1"># Expand single prediction to T=1 so probability methods can handle it</span>
        <span class="n">forecast_expanded</span> <span class="o">=</span> <span class="n">result_</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span>
            <span class="n">T</span><span class="o">=</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">Timestamp</span><span class="p">(</span><span class="n">Predictor_for_year</span><span class="o">.</span><span class="n">coords</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">to_pydatetime</span><span class="p">()]</span>
        <span class="p">)</span>
        <span class="n">year</span> <span class="o">=</span> <span class="n">Predictor_for_year</span><span class="o">.</span><span class="n">coords</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;datetime64[Y]&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1970</span>
        <span class="c1"># year = Predictor_for_year.coords[&#39;T&#39;].values.astype(&#39;datetime64[Y]&#39;).astype(int)[0] + 1970  </span>
        <span class="n">T_value_1</span> <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">coords</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>  <span class="c1"># Get the datetime64 value from da1</span>
        <span class="n">month_1</span> <span class="o">=</span> <span class="n">T_value_1</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;datetime64[M]&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span> <span class="o">%</span> <span class="mi">12</span> <span class="o">+</span> <span class="mi">1</span>  <span class="c1"># Extract month</span>
        <span class="n">new_T_value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">datetime64</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">year</span><span class="si">}</span><span class="s2">-</span><span class="si">{</span><span class="n">month_1</span><span class="si">:</span><span class="s2">02d</span><span class="si">}</span><span class="s2">-</span><span class="si">{</span><span class="mi">1</span><span class="si">:</span><span class="s2">02d</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        
        <span class="n">forecast_expanded</span> <span class="o">=</span> <span class="n">forecast_expanded</span><span class="o">.</span><span class="n">assign_coords</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span><span class="p">([</span><span class="n">new_T_value</span><span class="p">],</span> <span class="n">dims</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">]))</span>
        <span class="n">forecast_expanded</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">forecast_expanded</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;datetime64[ns]&#39;</span><span class="p">)</span>

        <span class="n">dof</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">rainfall_for_tercile</span><span class="o">.</span><span class="n">sizes</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">])</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

        <span class="n">dm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dist_method</span>

        <span class="c1"># ---------- BESTFIT ----------</span>
        <span class="k">if</span> <span class="n">dm</span> <span class="o">==</span> <span class="s2">&quot;bestfit&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">v</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="p">(</span><span class="n">best_code_da</span><span class="p">,</span> <span class="n">best_shape_da</span><span class="p">,</span> <span class="n">best_loc_da</span><span class="p">,</span> <span class="n">best_scale_da</span><span class="p">)):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;dist_method=&#39;bestfit&#39; requires best_code_da, best_shape_da, best_loc_da, best_scale_da.&quot;</span>
                <span class="p">)</span>
            
            <span class="n">T1</span><span class="p">,</span> <span class="n">T2</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_ppf_terciles_from_code</span><span class="p">,</span>
                <span class="n">best_code_da</span><span class="p">,</span>
                <span class="n">best_shape_da</span><span class="p">,</span>
                <span class="n">best_loc_da</span><span class="p">,</span>
                <span class="n">best_scale_da</span><span class="p">,</span>
                <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[(),</span> <span class="p">(),</span> <span class="p">(),</span> <span class="p">()],</span>
                <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(),</span> <span class="p">()],</span>
                <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">dask</span><span class="o">=</span><span class="s2">&quot;parallelized&quot;</span><span class="p">,</span>
                <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span>
            <span class="p">)</span>

            <span class="n">forecast_prob</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">calculate_tercile_probabilities_bestfit</span><span class="p">,</span>
                <span class="n">forecast_expanded</span><span class="p">,</span>
                <span class="n">error_variance</span><span class="p">,</span>
                <span class="n">T1</span><span class="p">,</span>
                <span class="n">T2</span><span class="p">,</span>
                <span class="n">best_code_da</span><span class="p">,</span>
                <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;T&quot;</span><span class="p">,),</span> <span class="p">(),</span> <span class="p">(),</span> <span class="p">(),</span> <span class="p">()],</span>
                <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;probability&quot;</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">)],</span>
                <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">dask</span><span class="o">=</span><span class="s2">&quot;parallelized&quot;</span><span class="p">,</span>
                <span class="n">kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;dof&quot;</span><span class="p">:</span> <span class="n">dof</span><span class="p">},</span>
                <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>
                <span class="n">dask_gufunc_kwargs</span><span class="o">=</span><span class="p">{</span>
                    <span class="s2">&quot;output_sizes&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;probability&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">},</span>
                    <span class="s2">&quot;allow_rechunk&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                <span class="p">},</span>
            <span class="p">)</span>

        <span class="c1"># ---------- Nonparametric ----------</span>
        <span class="k">elif</span> <span class="n">dm</span> <span class="o">==</span> <span class="s2">&quot;nonparam&quot;</span><span class="p">:</span>
            <span class="n">error_samples</span> <span class="o">=</span> <span class="n">Predictant</span> <span class="o">-</span> <span class="n">hindcast_det</span>
            <span class="n">forecast_prob</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">calculate_tercile_probabilities_nonparametric</span><span class="p">,</span>
                <span class="n">forecast_expanded</span><span class="p">,</span>
                <span class="n">error_samples</span><span class="p">,</span>
                <span class="n">T1_emp</span><span class="p">,</span>
                <span class="n">T2_emp</span><span class="p">,</span>
                <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;T&quot;</span><span class="p">,),</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,),</span> <span class="p">(),</span> <span class="p">()],</span>
                <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;probability&quot;</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">)],</span>
                <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">dask</span><span class="o">=</span><span class="s2">&quot;parallelized&quot;</span><span class="p">,</span>
                <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>
                <span class="n">dask_gufunc_kwargs</span><span class="o">=</span><span class="p">{</span>
                    <span class="s2">&quot;output_sizes&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;probability&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">},</span>
                    <span class="s2">&quot;allow_rechunk&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                <span class="p">},</span>
            <span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid dist_method: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">dist_method</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">forecast_prob</span> <span class="o">=</span> <span class="n">forecast_prob</span><span class="o">.</span><span class="n">assign_coords</span><span class="p">(</span><span class="n">probability</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;probability&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;PB&#39;</span><span class="p">,</span> <span class="s1">&#39;PN&#39;</span><span class="p">,</span> <span class="s1">&#39;PA&#39;</span><span class="p">]))</span>
        <span class="k">return</span> <span class="n">result_da</span><span class="p">,</span> <span class="n">forecast_prob</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="s1">&#39;probability&#39;</span><span class="p">,</span> <span class="s1">&#39;T&#39;</span><span class="p">,</span> <span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">)</span></div>
</div>







<div class="viewcode-block" id="WAS_MLP">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_MLP">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">WAS_MLP</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A class to perform MLP (Multi-Layer Perceptron) regression on spatiotemporal</span>
<span class="sd">    datasets for climate prediction, with hyperparameter tuning via clustering + grid search.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    nb_cores : int</span>
<span class="sd">        Number of CPU cores to use for parallel computation.</span>
<span class="sd">    dist_method : str</span>
<span class="sd">        Distribution method for tercile probability calculations. </span>
<span class="sd">        One of {&#39;gamma&#39;, &#39;t&#39;, &#39;normal&#39;, &#39;lognormal&#39;, &#39;nonparam&#39;}.</span>
<span class="sd">    n_clusters : int</span>
<span class="sd">        Number of clusters to use for KMeans.</span>
<span class="sd">    param_grid : dict or None</span>
<span class="sd">        The hyperparameter search grid for MLPRegressor. </span>
<span class="sd">        If None, a default grid is used.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    nb_cores, dist_method, n_clusters, param_grid</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="WAS_MLP.__init__">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_MLP.__init__">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">nb_cores</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">dist_method</span><span class="o">=</span><span class="s2">&quot;nonparam&quot;</span><span class="p">,</span>
        <span class="n">n_clusters</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
        <span class="n">param_grid</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">optimization_method</span><span class="o">=</span><span class="s2">&quot;grid&quot;</span><span class="p">,</span>  <span class="c1"># New parameter</span>
        <span class="n">n_trials</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>  <span class="c1"># New parameter</span>
        <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>  <span class="c1"># New parameter</span>
        <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>  <span class="c1"># New parameter</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initializes the WAS_MLP with specified hyperparameter ranges.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        nb_cores : int, optional</span>
<span class="sd">            Number of CPU cores to use for parallel computation.</span>
<span class="sd">        n_clusters : int, optional</span>
<span class="sd">            Number of clusters for KMeans.</span>
<span class="sd">        kernel : str, optional</span>
<span class="sd">            Kernel type to be used in SVR (&#39;linear&#39;, &#39;poly&#39;, &#39;rbf&#39;, or &#39;all&#39;).</span>
<span class="sd">        gamma : str, optional</span>
<span class="sd">            Kernel coefficient for &#39;rbf&#39; kernel. Ignored otherwise.</span>
<span class="sd">        C_range : list, optional</span>
<span class="sd">            List of C values for hyperparameter tuning.</span>
<span class="sd">        epsilon_range : list, optional</span>
<span class="sd">            List of epsilon values for hyperparameter tuning.</span>
<span class="sd">        degree_range : list, optional</span>
<span class="sd">            List of polynomial degrees for &#39;poly&#39; kernel.</span>
<span class="sd">        dist_method : str, optional</span>
<span class="sd">            Distribution method for tercile probability calculations.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span> <span class="o">=</span> <span class="n">nb_cores</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dist_method</span> <span class="o">=</span> <span class="n">dist_method</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span> <span class="o">=</span> <span class="n">n_clusters</span>
        
        <span class="c1"># Define default parameter grid if none provided</span>
        <span class="k">if</span> <span class="n">param_grid</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s1">&#39;hidden_layer_sizes&#39;</span><span class="p">:</span> <span class="p">[(</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="mi">10</span><span class="p">,),</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">10</span><span class="p">),</span> <span class="p">(</span><span class="mi">50</span><span class="p">,)],</span>
                <span class="s1">&#39;activation&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="s1">&#39;tanh&#39;</span><span class="p">,</span> <span class="s1">&#39;logistic&#39;</span><span class="p">],</span>
                <span class="s1">&#39;solver&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span> <span class="s1">&#39;lbfgs&#39;</span><span class="p">],</span>
                <span class="s1">&#39;alpha&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.0001</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">],</span>
                <span class="s1">&#39;learning_rate_init&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span>
                <span class="s1">&#39;max_iter&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">200</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">1000</span><span class="p">]</span>
            <span class="p">}</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">param_grid</span> <span class="o">=</span> <span class="n">param_grid</span>
            
        <span class="bp">self</span><span class="o">.</span><span class="n">optimization_method</span> <span class="o">=</span> <span class="n">optimization_method</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_trials</span> <span class="o">=</span> <span class="n">n_trials</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cv</span> <span class="o">=</span> <span class="n">cv</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span>
        
        <span class="c1"># Initialize optimizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">BaseOptimizer</span><span class="p">(</span>
            <span class="n">optimization_method</span><span class="o">=</span><span class="n">optimization_method</span><span class="p">,</span>
            <span class="n">n_trials</span><span class="o">=</span><span class="n">n_trials</span><span class="p">,</span>
            <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span>
            <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="WAS_MLP.compute_hyperparameters">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_MLP.compute_hyperparameters">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">compute_hyperparameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">predictand</span><span class="p">,</span> <span class="n">predictor</span><span class="p">,</span> <span class="n">clim_year_start</span><span class="p">,</span> <span class="n">clim_year_end</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Optimized version with Bayesian optimization.&quot;&quot;&quot;</span>
        <span class="n">predictor</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">predictand</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span>
        <span class="n">predictand_</span> <span class="o">=</span> <span class="n">standardize_timeseries</span><span class="p">(</span><span class="n">predictand</span><span class="p">)</span>

        <span class="c1"># (a) KMeans clustering</span>
        <span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
        <span class="n">predictand_dropna</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">predictand</span><span class="o">.</span><span class="n">to_dataframe</span><span class="p">()</span>
                      <span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
                      <span class="o">.</span><span class="n">dropna</span><span class="p">()</span>
                      <span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">])</span>
        <span class="p">)</span>
        
        <span class="n">col_name</span> <span class="o">=</span> <span class="n">predictand_dropna</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
        <span class="n">predictand_dropna</span><span class="p">[</span><span class="s1">&#39;cluster&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span>
            <span class="n">predictand_dropna</span><span class="p">[[</span><span class="n">col_name</span><span class="p">]]</span>
        <span class="p">)</span>
        
        <span class="n">df_unique</span> <span class="o">=</span> <span class="n">predictand_dropna</span><span class="o">.</span><span class="n">drop_duplicates</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">])</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">df_unique</span><span class="o">.</span><span class="n">set_index</span><span class="p">([</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">to_xarray</span><span class="p">()</span>
        
        <span class="n">cluster_da</span> <span class="o">=</span> <span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;cluster&#39;</span><span class="p">]</span> <span class="o">*</span>
                      <span class="n">xr</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="o">~</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">predictand</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="mi">0</span><span class="p">)),</span> <span class="mi">1</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
                     <span class="p">)</span><span class="o">.</span><span class="n">drop_vars</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
        
        <span class="n">_</span><span class="p">,</span> <span class="n">cluster_da</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">align</span><span class="p">(</span><span class="n">predictand</span><span class="p">,</span> <span class="n">cluster_da</span><span class="p">,</span> <span class="n">join</span><span class="o">=</span><span class="s2">&quot;outer&quot;</span><span class="p">)</span>
        <span class="n">clusters</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">cluster_da</span><span class="p">)</span>
        <span class="n">clusters</span> <span class="o">=</span> <span class="n">clusters</span><span class="p">[</span><span class="o">~</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">clusters</span><span class="p">)]</span>
    
        <span class="n">hyperparams_cluster</span> <span class="o">=</span> <span class="p">{}</span>
    
        <span class="c1"># (b) Optimize for each cluster</span>
        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">clusters</span><span class="p">:</span>
            <span class="n">mask_c</span> <span class="o">=</span> <span class="p">(</span><span class="n">cluster_da</span> <span class="o">==</span> <span class="n">c</span><span class="p">)</span>
            <span class="n">y_cluster</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">predictand_</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">mask_c</span><span class="p">)</span>
                          <span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Y&quot;</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">],</span> <span class="n">skipna</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                          <span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="s2">&quot;T&quot;</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_cluster</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">])</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">continue</span>
    
            <span class="n">predictor_cluster</span> <span class="o">=</span> <span class="n">predictor</span><span class="o">.</span><span class="n">sel</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="n">y_cluster</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">])</span>
            <span class="n">X_mat</span> <span class="o">=</span> <span class="n">predictor_cluster</span><span class="o">.</span><span class="n">values</span>
            <span class="n">y_vec</span> <span class="o">=</span> <span class="n">y_cluster</span><span class="o">.</span><span class="n">values</span>
            
            <span class="c1"># # Wrap MLP in a pipeline with scaling</span>
            <span class="c1"># mlp_pipeline = Pipeline([</span>
            <span class="c1">#     (&#39;scaler&#39;, StandardScaler()),  # Scales features to mean=0, std=1</span>
            <span class="c1">#     (&#39;mlp&#39;, MLPRegressor(random_state=42))</span>
            <span class="c1"># ])</span>

            <span class="c1"># MLP with NO X scaling</span>
            <span class="n">mlp</span> <span class="o">=</span> <span class="n">MLPRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
            
            <span class="c1"># Scale ONLY y for the MLP</span>
            <span class="n">mlp_y_scaled</span> <span class="o">=</span> <span class="n">TransformedTargetRegressor</span><span class="p">(</span>
                <span class="n">regressor</span><span class="o">=</span><span class="n">mlp</span><span class="p">,</span>
                <span class="n">transformer</span><span class="o">=</span><span class="n">StandardScaler</span><span class="p">()</span>
            <span class="p">)</span>
            
            <span class="c1"># # Use optimizer to find best parameters</span>
            <span class="c1"># model = MLPRegressor(random_state=42)</span>
            <span class="n">best_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span>
                <span class="n">mlp_y_scaled</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">param_grid</span><span class="p">,</span>
                <span class="n">X_mat</span><span class="p">,</span>
                <span class="n">y_vec</span><span class="p">,</span>
                <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;neg_mean_squared_error&#39;</span>
            <span class="p">)</span>
            
            <span class="n">hyperparams_cluster</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">c</span><span class="p">)]</span> <span class="o">=</span> <span class="n">best_params</span>
    
        <span class="c1"># (c) Broadcast best hyperparameters to each grid cell</span>
        <span class="n">hl_array</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">cluster_da</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">object</span><span class="p">)</span>
        <span class="n">act_array</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">cluster_da</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">object</span><span class="p">)</span>
        <span class="n">solver_array</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">cluster_da</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">object</span><span class="p">)</span>
        <span class="n">alpha_array</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">cluster_da</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
        <span class="n">lr_array</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">cluster_da</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
        <span class="n">maxiter_array</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">cluster_da</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
        
        <span class="k">for</span> <span class="n">c</span><span class="p">,</span> <span class="n">bp</span> <span class="ow">in</span> <span class="n">hyperparams_cluster</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">c_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">cluster_da</span> <span class="o">==</span> <span class="n">c</span><span class="p">)</span>
            <span class="n">hl_str</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">bp</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;hidden_layer_sizes&#39;</span><span class="p">,</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">)))</span>
            <span class="n">act_str</span> <span class="o">=</span> <span class="n">bp</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;activation&#39;</span><span class="p">,</span> <span class="s1">&#39;relu&#39;</span><span class="p">)</span>
            <span class="n">solver_str</span> <span class="o">=</span> <span class="n">bp</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;solver&#39;</span><span class="p">,</span> <span class="s1">&#39;adam&#39;</span><span class="p">)</span>
            <span class="n">alpha_val</span> <span class="o">=</span> <span class="n">bp</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;alpha&#39;</span><span class="p">,</span> <span class="mf">0.0001</span><span class="p">)</span>
            <span class="n">lr_val</span> <span class="o">=</span> <span class="n">bp</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;learning_rate_init&#39;</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">)</span>
            <span class="n">maxiter_val</span> <span class="o">=</span> <span class="n">bp</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;max_iter&#39;</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>
            
            <span class="n">hl_array</span> <span class="o">=</span> <span class="n">hl_array</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="o">~</span><span class="n">c_mask</span><span class="p">,</span> <span class="n">other</span><span class="o">=</span><span class="n">hl_str</span><span class="p">)</span>
            <span class="n">act_array</span> <span class="o">=</span> <span class="n">act_array</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="o">~</span><span class="n">c_mask</span><span class="p">,</span> <span class="n">other</span><span class="o">=</span><span class="n">act_str</span><span class="p">)</span>
            <span class="n">solver_array</span> <span class="o">=</span> <span class="n">solver_array</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="o">~</span><span class="n">c_mask</span><span class="p">,</span> <span class="n">other</span><span class="o">=</span><span class="n">solver_str</span><span class="p">)</span>
            <span class="n">alpha_array</span> <span class="o">=</span> <span class="n">alpha_array</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="o">~</span><span class="n">c_mask</span><span class="p">,</span> <span class="n">other</span><span class="o">=</span><span class="n">alpha_val</span><span class="p">)</span>
            <span class="n">lr_array</span> <span class="o">=</span> <span class="n">lr_array</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="o">~</span><span class="n">c_mask</span><span class="p">,</span> <span class="n">other</span><span class="o">=</span><span class="n">lr_val</span><span class="p">)</span>
            <span class="n">maxiter_array</span> <span class="o">=</span> <span class="n">maxiter_array</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="o">~</span><span class="n">c_mask</span><span class="p">,</span> <span class="n">other</span><span class="o">=</span><span class="n">maxiter_val</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">hl_array</span><span class="p">,</span> <span class="n">act_array</span><span class="p">,</span> <span class="n">solver_array</span><span class="p">,</span> <span class="n">alpha_array</span><span class="p">,</span> <span class="n">lr_array</span><span class="p">,</span> <span class="n">maxiter_array</span><span class="p">,</span> <span class="n">cluster_da</span></div>


    <span class="c1"># ------------------------------------------------------------------</span>
    <span class="c1"># 2) FIT + PREDICT ON A SINGLE GRID CELL</span>
    <span class="c1"># ------------------------------------------------------------------</span>
<div class="viewcode-block" id="WAS_MLP.fit_predict">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_MLP.fit_predict">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">fit_predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span>
                    <span class="n">hl_sizes</span><span class="p">,</span> <span class="n">activation</span><span class="p">,</span> <span class="n">lr_init</span><span class="p">,</span> <span class="n">maxiter</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Trains an MLP (with local hyperparams) on the provided training data, then predicts on X_test.</span>
<span class="sd">        Returns [error, prediction].</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X_train : np.ndarray, shape (n_samples, n_features)</span>
<span class="sd">        y_train : np.ndarray, shape (n_samples,)</span>
<span class="sd">        X_test  : np.ndarray, shape (n_features,) or (1, n_features)</span>
<span class="sd">        y_test  : float or np.nan</span>
<span class="sd">        hl_sizes : str (stored as string in xarray) or None</span>
<span class="sd">        activation : str</span>
<span class="sd">        lr_init : float</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        np.ndarray of shape (2,)</span>
<span class="sd">            [error, predicted_value]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Convert hidden_layer_sizes from string if needed</span>
        <span class="k">if</span> <span class="n">hl_sizes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">hl_sizes</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">hl_sizes</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="n">hl_sizes</span><span class="p">)</span>  <span class="c1"># parse string into tuple</span>

        <span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span> <span class="o">&amp;</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">X_train</span><span class="p">),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># mlp_model = Pipeline([</span>
        <span class="c1">#     (&#39;scaler&#39;, StandardScaler()),</span>
        <span class="c1">#     (&#39;mlp&#39;, MLPRegressor(</span>
        <span class="c1">#     hidden_layer_sizes=hl_sizes if hl_sizes else (10,5),</span>
        <span class="c1">#     activation=activation if activation else &#39;relu&#39;,</span>
        <span class="c1">#     solver=&#39;adam&#39;,</span>
        <span class="c1">#     max_iter=int(maxiter) if not np.isnan(maxiter) else 1000,</span>
        <span class="c1">#     learning_rate_init=lr_init if not np.isnan(lr_init) else 0.001</span>
        <span class="c1">#     # learning_rate_init=lr_init if lr_init else 0.001</span>
        <span class="c1"># ))</span>
        <span class="c1"># ])</span>
        
        <span class="c1"># MLP with NO X scaling</span>
        <span class="n">mlp</span> <span class="o">=</span> <span class="n">MLPRegressor</span><span class="p">(</span>
        <span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="n">hl_sizes</span> <span class="k">if</span> <span class="n">hl_sizes</span> <span class="k">else</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span>
        <span class="n">activation</span><span class="o">=</span><span class="n">activation</span> <span class="k">if</span> <span class="n">activation</span> <span class="k">else</span> <span class="s1">&#39;relu&#39;</span><span class="p">,</span>
        <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span>
        <span class="n">max_iter</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">maxiter</span><span class="p">)</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">maxiter</span><span class="p">)</span> <span class="k">else</span> <span class="mi">1000</span><span class="p">,</span>
        <span class="n">learning_rate_init</span><span class="o">=</span><span class="n">lr_init</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">lr_init</span><span class="p">)</span> <span class="k">else</span> <span class="mf">0.001</span>
        <span class="c1"># learning_rate_init=lr_init if lr_init else 0.001</span>
        <span class="p">)</span>
            
        <span class="c1"># Scale ONLY y for the MLP</span>
        <span class="n">mlp_model</span> <span class="o">=</span> <span class="n">TransformedTargetRegressor</span><span class="p">(</span>
            <span class="n">regressor</span><span class="o">=</span><span class="n">mlp</span><span class="p">,</span>
            <span class="n">transformer</span><span class="o">=</span><span class="n">StandardScaler</span><span class="p">()</span>
        <span class="p">)</span>
        
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">mask</span><span class="p">):</span>
            <span class="n">X_c</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="n">mask</span><span class="p">,</span> <span class="p">:]</span>
            <span class="n">y_c</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>
            <span class="n">mlp_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_c</span><span class="p">,</span> <span class="n">y_c</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">X_test</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">mlp_preds</span> <span class="o">=</span> <span class="n">mlp_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
            <span class="n">mlp_preds</span><span class="p">[</span><span class="n">mlp_preds</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># clip negative if it&#39;s precipitation</span>

            <span class="n">err</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span> <span class="k">if</span> <span class="p">(</span><span class="n">y_test</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">y_test</span><span class="p">))</span> <span class="k">else</span> <span class="p">(</span><span class="n">y_test</span> <span class="o">-</span> <span class="n">mlp_preds</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">err</span><span class="p">,</span> <span class="n">mlp_preds</span><span class="p">])</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">])</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span></div>


    <span class="c1"># ------------------------------------------------------------------</span>
    <span class="c1"># 3) PARALLELIZED MODEL PREDICTION OVER SPACE</span>
    <span class="c1"># ------------------------------------------------------------------</span>
<div class="viewcode-block" id="WAS_MLP.compute_model">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_MLP.compute_model">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">compute_model</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> 
        <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> 
        <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span>
        <span class="n">hl_array</span><span class="p">,</span> <span class="n">act_array</span><span class="p">,</span> <span class="n">lr_array</span><span class="p">,</span> <span class="n">maxiter_array</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Runs MLP fit/predict for each (Y,X) cell in parallel, using cluster-based hyperparams.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X_train : xarray.DataArray</span>
<span class="sd">            Training predictors with dims (&#39;T&#39;,&#39;features&#39;).</span>
<span class="sd">        y_train : xarray.DataArray</span>
<span class="sd">            Training target with dims (&#39;T&#39;,&#39;Y&#39;,&#39;X&#39;).</span>
<span class="sd">        X_test : xarray.DataArray</span>
<span class="sd">            Test predictors, shape (&#39;features&#39;,) or broadcastable.</span>
<span class="sd">        y_test : xarray.DataArray</span>
<span class="sd">            Test target with dims (&#39;Y&#39;,&#39;X&#39;).</span>
<span class="sd">        hl_array, act_array, lr_array : xarray.DataArray</span>
<span class="sd">            Local best hyperparameters from compute_hyperparameters.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        xarray.DataArray</span>
<span class="sd">            dims (&#39;output&#39;, &#39;Y&#39;, &#39;X&#39;), where &#39;output&#39; = [error, prediction].</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">chunksize_x</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="o">.</span><span class="n">get_index</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">))</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span><span class="p">))</span>
        <span class="n">chunksize_y</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="o">.</span><span class="n">get_index</span><span class="p">(</span><span class="s2">&quot;Y&quot;</span><span class="p">))</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span><span class="p">))</span>

        <span class="c1"># Align time</span>
        <span class="n">X_train</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span>
        <span class="n">y_train</span> <span class="o">=</span> <span class="n">y_train</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="s1">&#39;T&#39;</span><span class="p">,</span> <span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">)</span>

        <span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
        <span class="n">y_test</span> <span class="o">=</span> <span class="n">y_test</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">)</span>

        <span class="n">client</span> <span class="o">=</span> <span class="n">Client</span><span class="p">(</span><span class="n">n_workers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span><span class="p">,</span> <span class="n">threads_per_worker</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">result_da</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">,</span>
            <span class="n">X_train</span><span class="p">,</span>                           
            <span class="n">y_train</span><span class="o">.</span><span class="n">chunk</span><span class="p">({</span><span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">chunksize_y</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">chunksize_x</span><span class="p">}),</span>
            <span class="n">X_test</span><span class="p">,</span>
            <span class="n">y_test</span><span class="o">.</span><span class="n">chunk</span><span class="p">({</span><span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">chunksize_y</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">chunksize_x</span><span class="p">}),</span>
            <span class="n">hl_array</span><span class="o">.</span><span class="n">chunk</span><span class="p">({</span><span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">chunksize_y</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">chunksize_x</span><span class="p">}),</span>
            <span class="n">act_array</span><span class="o">.</span><span class="n">chunk</span><span class="p">({</span><span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">chunksize_y</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">chunksize_x</span><span class="p">}),</span>
            <span class="n">lr_array</span><span class="o">.</span><span class="n">chunk</span><span class="p">({</span><span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">chunksize_y</span><span class="p">,</span>  <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">chunksize_x</span><span class="p">}),</span>
            <span class="n">maxiter_array</span><span class="o">.</span><span class="n">chunk</span><span class="p">({</span><span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">chunksize_y</span><span class="p">,</span>  <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">chunksize_x</span><span class="p">}),</span>
            
            <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[</span>
                <span class="p">(</span><span class="s1">&#39;T&#39;</span><span class="p">,</span><span class="s1">&#39;features&#39;</span><span class="p">),</span>  <span class="c1"># X_train</span>
                <span class="p">(</span><span class="s1">&#39;T&#39;</span><span class="p">,),</span>           <span class="c1"># y_train</span>
                <span class="p">(</span><span class="s1">&#39;features&#39;</span><span class="p">,),</span>    <span class="c1"># X_test</span>
                <span class="p">(),</span>               <span class="c1"># y_test</span>
                <span class="p">(),</span>               <span class="c1"># hidden_layer_sizes</span>
                <span class="p">(),</span>               <span class="c1"># activation</span>
                <span class="p">(),</span>                <span class="c1"># learning_rate_init</span>
                <span class="p">()</span>                <span class="c1"># max_iter                </span>
            <span class="p">],</span>
            <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">dask</span><span class="o">=</span><span class="s1">&#39;parallelized&#39;</span><span class="p">,</span>
            <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s1">&#39;output&#39;</span><span class="p">,)],</span>
            <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>
            <span class="n">dask_gufunc_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;output_sizes&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;output&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">}},</span>
        <span class="p">)</span>
        <span class="n">result_</span> <span class="o">=</span> <span class="n">result_da</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
        <span class="n">client</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

        <span class="c1"># Return DataArray with dims (&#39;output&#39;,&#39;Y&#39;,&#39;X&#39;) =&gt; [error, prediction]</span>
        <span class="k">return</span> <span class="n">result_</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">output</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></div>


    <span class="c1"># ------------------ Probability Calculation Methods ------------------</span>

<div class="viewcode-block" id="WAS_MLP._ppf_terciles_from_code">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_MLP._ppf_terciles_from_code">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_ppf_terciles_from_code</span><span class="p">(</span><span class="n">dist_code</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return tercile thresholds (T1, T2) from best-fit distribution parameters.</span>
<span class="sd">    </span>
<span class="sd">        dist_code:</span>
<span class="sd">            1: norm</span>
<span class="sd">            2: lognorm</span>
<span class="sd">            3: expon</span>
<span class="sd">            4: gamma</span>
<span class="sd">            5: weibull_min</span>
<span class="sd">            6: t</span>
<span class="sd">            7: poisson</span>
<span class="sd">            8: nbinom</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">dist_code</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
    
        <span class="n">code</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">dist_code</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                    <span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">lognorm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                    <span class="n">lognorm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">expon</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                    <span class="n">expon</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">gamma</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                    <span class="n">gamma</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">5</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">weibull_min</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                    <span class="n">weibull_min</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">6</span><span class="p">:</span>
                <span class="c1"># Note: Renamed &#39;t_dist&#39; to &#39;t&#39; for standard scipy.stats</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">t</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                    <span class="n">t</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">7</span><span class="p">:</span>
                <span class="c1"># Poisson: poisson.ppf(q, mu, loc=0)</span>
                <span class="c1"># ASSUMPTION: &#39;mu&#39; (mean) is passed as &#39;shape&#39;</span>
                <span class="c1">#             &#39;loc&#39; is passed as &#39;loc&#39;</span>
                <span class="c1">#             &#39;scale&#39; is unused</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">poisson</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">),</span>
                    <span class="n">poisson</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">8</span><span class="p">:</span>
                <span class="c1"># Negative Binomial: nbinom.ppf(q, n, p, loc=0)</span>
                <span class="c1"># ASSUMPTION: &#39;n&#39; (successes) is passed as &#39;shape&#39;</span>
                <span class="c1">#             &#39;p&#39; (probability) is passed as &#39;scale&#39;</span>
                <span class="c1">#             &#39;loc&#39; is passed as &#39;loc&#39;</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">nbinom</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">scale</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">),</span>
                    <span class="n">nbinom</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">scale</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">),</span>
                <span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
    
        <span class="c1"># Fallback if code is not 1-8</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span></div>

        
<div class="viewcode-block" id="WAS_MLP.weibull_shape_solver">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_MLP.weibull_shape_solver">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">weibull_shape_solver</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">V</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Function to find the root of the Weibull shape parameter &#39;k&#39;.</span>
<span class="sd">        We find &#39;k&#39; such that the theoretical variance/mean^2 ratio</span>
<span class="sd">        matches the observed V/M^2 ratio.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Guard against invalid &#39;k&#39; values during solving</span>
        <span class="k">if</span> <span class="n">k</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">g1</span> <span class="o">=</span> <span class="n">gamma_function</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="mi">1</span><span class="o">/</span><span class="n">k</span><span class="p">)</span>
            <span class="n">g2</span> <span class="o">=</span> <span class="n">gamma_function</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="mi">2</span><span class="o">/</span><span class="n">k</span><span class="p">)</span>
            
            <span class="c1"># This is the V/M^2 ratio *implied by k*</span>
            <span class="n">implied_v_over_m_sq</span> <span class="o">=</span> <span class="p">(</span><span class="n">g2</span> <span class="o">/</span> <span class="p">(</span><span class="n">g1</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span> <span class="o">-</span> <span class="mi">1</span>
            
            <span class="c1"># This is the *observed* ratio</span>
            <span class="n">observed_v_over_m_sq</span> <span class="o">=</span> <span class="n">V</span> <span class="o">/</span> <span class="p">(</span><span class="n">M</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
            
            <span class="c1"># Return the difference (we want this to be 0)</span>
            <span class="k">return</span> <span class="n">observed_v_over_m_sq</span> <span class="o">-</span> <span class="n">implied_v_over_m_sq</span>
        <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
            <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span> <span class="c1"># Handle math errors</span></div>


<div class="viewcode-block" id="WAS_MLP.calculate_tercile_probabilities_bestfit">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_MLP.calculate_tercile_probabilities_bestfit">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">calculate_tercile_probabilities_bestfit</span><span class="p">(</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">error_variance</span><span class="p">,</span> <span class="n">T1</span><span class="p">,</span> <span class="n">T2</span><span class="p">,</span> <span class="n">dist_code</span><span class="p">,</span> <span class="n">dof</span> 
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generic tercile probabilities using best-fit family per grid cell.</span>

<span class="sd">        Inputs (per grid cell):</span>
<span class="sd">        - best_guess : 1D array over T (hindcast_det or forecast_det)</span>
<span class="sd">        - T1, T2     : scalar terciles from climatological best-fit distribution</span>
<span class="sd">        - dist_code  : int, as in _ppf_terciles_from_code</span>
<span class="sd">        - shape, loc, scale : scalars from climatology fit</span>

<span class="sd">        Strategy:</span>
<span class="sd">        - For each time step, build a predictive distribution of the same family:</span>
<span class="sd">            * Use best_guess[t] to adjust mean / location;</span>
<span class="sd">            * Keep shape parameters from climatology.</span>
<span class="sd">        - Then compute probabilities:</span>
<span class="sd">            P(B) = F(T1), P(N) = F(T2) - F(T1), P(A) = 1 - F(T2).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        
        <span class="n">best_guess</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">best_guess</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span>
        <span class="n">error_variance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">error_variance</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
        <span class="c1"># T1 = np.asarray(T1, dtype=float)</span>
        <span class="c1"># T2 = np.asarray(T2, dtype=float)</span>
        <span class="n">n_time</span> <span class="o">=</span> <span class="n">best_guess</span><span class="o">.</span><span class="n">size</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="n">n_time</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">best_guess</span><span class="p">))</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">dist_code</span><span class="p">)</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">T1</span><span class="p">)</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">T2</span><span class="p">)</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">error_variance</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">out</span>

        <span class="n">code</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">dist_code</span><span class="p">)</span>

        <span class="c1"># Normal: loc = forecast; scale from clim</span>
        <span class="k">if</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">error_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">error_variance</span><span class="p">)</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">error_std</span><span class="p">)</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">error_std</span><span class="p">)</span> <span class="o">-</span> <span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">error_std</span><span class="p">)</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">error_std</span><span class="p">)</span>

        <span class="c1"># Lognormal: shape = sigma from clim; enforce mean = best_guess</span>
        <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">sigma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">error_variance</span> <span class="o">/</span> <span class="p">(</span><span class="n">best_guess</span><span class="o">**</span><span class="mi">2</span><span class="p">)))</span>
            <span class="n">mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">best_guess</span><span class="p">)</span> <span class="o">-</span> <span class="n">sigma</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="mi">2</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">lognorm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">mu</span><span class="p">))</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">lognorm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">mu</span><span class="p">))</span> <span class="o">-</span> <span class="n">lognorm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">mu</span><span class="p">))</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">lognorm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">mu</span><span class="p">))</span>      


        <span class="c1"># Exponential: keep scale from clim; shift loc so mean = best_guess</span>
        <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
            <span class="n">c1</span> <span class="o">=</span> <span class="n">expon</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">error_variance</span><span class="p">))</span>
            <span class="n">c2</span> <span class="o">=</span> <span class="n">expon</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc_t</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">error_variance</span><span class="p">))</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c2</span> <span class="o">-</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">c2</span>

        <span class="c1"># Gamma: use shape from clim; set scale so mean = best_guess</span>
        <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
            <span class="n">alpha</span> <span class="o">=</span> <span class="p">(</span><span class="n">best_guess</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="n">error_variance</span>
            <span class="n">theta</span> <span class="o">=</span> <span class="n">error_variance</span> <span class="o">/</span> <span class="n">best_guess</span>
            <span class="n">c1</span> <span class="o">=</span> <span class="n">gamma</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">theta</span><span class="p">)</span>
            <span class="n">c2</span> <span class="o">=</span> <span class="n">gamma</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">theta</span><span class="p">)</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c2</span> <span class="o">-</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">c2</span>

        <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">5</span><span class="p">:</span> <span class="c1"># Assuming 5 is for Weibull   </span>
        
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_time</span><span class="p">):</span>
                <span class="c1"># Get the scalar values for this specific element (e.g., grid cell)</span>
                <span class="n">M</span> <span class="o">=</span> <span class="n">best_guess</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">M</span><span class="p">)</span>
                <span class="n">V</span> <span class="o">=</span> <span class="n">error_variance</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">V</span><span class="p">)</span>
                
                <span class="c1"># Handle cases with no variance to avoid division by zero</span>
                <span class="k">if</span> <span class="n">V</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">M</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                    <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                    <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                    <span class="k">continue</span> <span class="c1"># Skip to the next element</span>
        
                <span class="c1"># --- 1. Numerically solve for shape &#39;k&#39; ---</span>
                <span class="c1"># We need a reasonable starting guess. 2.0 is common (Rayleigh dist.)</span>
                <span class="n">initial_guess</span> <span class="o">=</span> <span class="mf">2.0</span>
                
                <span class="c1"># fsolve finds the root of our helper function</span>
                <span class="n">k</span> <span class="o">=</span> <span class="n">fsolve</span><span class="p">(</span><span class="n">weibull_shape_solver</span><span class="p">,</span> <span class="n">initial_guess</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">V</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>
        
                <span class="c1"># --- 2. Check for bad solution and calculate scale &#39;lambda&#39; ---</span>
                <span class="k">if</span> <span class="n">k</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="c1"># Solver failed</span>
                    <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                    <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                    <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                    <span class="k">continue</span>
                
                <span class="c1"># With &#39;k&#39; found, we can now algebraically find scale &#39;lambda&#39;</span>
                <span class="c1"># In scipy.stats, scale is &#39;scale&#39;</span>
                <span class="n">lambda_scale</span> <span class="o">=</span> <span class="n">M</span> <span class="o">/</span> <span class="n">gamma_function</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="mi">1</span><span class="o">/</span><span class="n">k</span><span class="p">)</span>
        
                <span class="c1"># --- 3. Calculate Probabilities ---</span>
                <span class="c1"># In scipy.stats, shape &#39;k&#39; is &#39;c&#39;</span>
                <span class="c1"># Use the T1 and T2 values for this specific element</span>
                
                <span class="n">c1</span> <span class="o">=</span> <span class="n">weibull_min</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">lambda_scale</span><span class="p">)</span>
                <span class="n">c2</span> <span class="o">=</span> <span class="n">weibull_min</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">lambda_scale</span><span class="p">)</span>
        
                <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">c1</span>
                <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">c2</span> <span class="o">-</span> <span class="n">c1</span>
                <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">c2</span>

        <span class="c1"># Student-t: df from clim; scale from clim; loc = best_guess</span>
        <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">6</span><span class="p">:</span>       
            <span class="c1"># Check if df is valid for variance calculation</span>
            <span class="k">if</span> <span class="n">dof</span> <span class="o">&lt;=</span> <span class="mi">2</span><span class="p">:</span>
                <span class="c1"># Cannot calculate scale, fill with NaNs</span>
                <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># 1. Calculate t-distribution parameters</span>
                <span class="c1"># &#39;loc&#39; (mean) is just the best_guess</span>
                <span class="n">loc</span> <span class="o">=</span> <span class="n">best_guess</span>
                <span class="c1"># &#39;scale&#39; is calculated from the variance and df</span>
                <span class="c1"># Variance = scale**2 * (df / (df - 2))</span>
                <span class="n">scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">error_variance</span> <span class="o">*</span> <span class="p">(</span><span class="n">dof</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="n">dof</span><span class="p">)</span>
                
                <span class="c1"># 2. Calculate probabilities</span>
                <span class="n">c1</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">dof</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">)</span>
                <span class="n">c2</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">dof</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">)</span>

                <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c1</span>
                <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c2</span> <span class="o">-</span> <span class="n">c1</span>
                <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">c2</span>

        <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">7</span><span class="p">:</span> <span class="c1"># Assuming 7 is for Poisson</span>
            
            <span class="c1"># --- 1. Set the Poisson parameter &#39;mu&#39; ---</span>
            <span class="c1"># The &#39;mu&#39; parameter is the mean.</span>
            
            <span class="c1"># A warning is strongly recommended if error_variance is different from best_guess</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">error_variance</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Warning: &#39;error_variance&#39; is not equal to &#39;best_guess&#39;.&quot;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Poisson model assumes mean=variance and is likely inappropriate.&quot;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Consider using Negative Binomial.&quot;</span><span class="p">)</span>
            
            <span class="n">mu</span> <span class="o">=</span> <span class="n">best_guess</span>
        
            <span class="c1"># --- 2. Calculate Probabilities ---</span>
            <span class="c1"># poisson.cdf(k, mu) calculates P(X &lt;= k)</span>
            
            <span class="n">c1</span> <span class="o">=</span> <span class="n">poisson</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">mu</span><span class="p">)</span>
            <span class="n">c2</span> <span class="o">=</span> <span class="n">poisson</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">mu</span><span class="p">)</span>
            
            <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c2</span> <span class="o">-</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">c2</span>

        <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">8</span><span class="p">:</span> <span class="c1"># Assuming 8 is for Negative Binomial</span>
            
            <span class="c1"># --- 1. Calculate Negative Binomial Parameters ---</span>
            <span class="c1"># This model is ONLY valid for overdispersion (Variance &gt; Mean).</span>
            <span class="c1"># We will use np.where to set parameters to NaN if V &lt;= M.</span>
            
            <span class="c1"># p = Mean / Variance</span>
            <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">error_variance</span> <span class="o">&gt;</span> <span class="n">best_guess</span><span class="p">,</span> 
                         <span class="n">best_guess</span> <span class="o">/</span> <span class="n">error_variance</span><span class="p">,</span> 
                         <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
            
            <span class="c1"># n = Mean^2 / (Variance - Mean)</span>
            <span class="n">n</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">error_variance</span> <span class="o">&gt;</span> <span class="n">best_guess</span><span class="p">,</span> 
                         <span class="p">(</span><span class="n">best_guess</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">error_variance</span> <span class="o">-</span> <span class="n">best_guess</span><span class="p">),</span> 
                         <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
            
            <span class="c1"># --- 2. Calculate Probabilities ---</span>
            <span class="c1"># The nbinom.cdf function will propagate NaNs, correctly</span>
            <span class="c1"># handling the cases where the model was invalid.</span>
            
            <span class="n">c1</span> <span class="o">=</span> <span class="n">nbinom</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">)</span>
            <span class="n">c2</span> <span class="o">=</span> <span class="n">nbinom</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">)</span>
            
            <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c2</span> <span class="o">-</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">c2</span>
            
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid distribution&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">out</span></div>


<div class="viewcode-block" id="WAS_MLP.calculate_tercile_probabilities_nonparametric">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_MLP.calculate_tercile_probabilities_nonparametric">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">calculate_tercile_probabilities_nonparametric</span><span class="p">(</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">error_samples</span><span class="p">,</span> <span class="n">first_tercile</span><span class="p">,</span> <span class="n">second_tercile</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Non-parametric method using historical error samples.&quot;&quot;&quot;</span>
        <span class="n">n_time</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">best_guess</span><span class="p">)</span>
        <span class="n">pred_prob</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="n">n_time</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_time</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">best_guess</span><span class="p">[</span><span class="n">t</span><span class="p">]):</span>
                <span class="k">continue</span>
            <span class="n">dist</span> <span class="o">=</span> <span class="n">best_guess</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">+</span> <span class="n">error_samples</span>
            <span class="n">dist</span> <span class="o">=</span> <span class="n">dist</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">dist</span><span class="p">)]</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">dist</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="n">p_below</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dist</span> <span class="o">&lt;</span> <span class="n">first_tercile</span><span class="p">)</span>
            <span class="n">p_between</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">dist</span> <span class="o">&gt;=</span> <span class="n">first_tercile</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">dist</span> <span class="o">&lt;</span> <span class="n">second_tercile</span><span class="p">))</span>
            <span class="n">p_above</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="p">(</span><span class="n">p_below</span> <span class="o">+</span> <span class="n">p_between</span><span class="p">)</span>
            <span class="n">pred_prob</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">p_below</span>
            <span class="n">pred_prob</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">p_between</span>
            <span class="n">pred_prob</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">p_above</span>
        <span class="k">return</span> <span class="n">pred_prob</span></div>




<div class="viewcode-block" id="WAS_MLP.compute_prob">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_MLP.compute_prob">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">compute_prob</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">Predictant</span><span class="p">:</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span><span class="p">,</span>
        <span class="n">clim_year_start</span><span class="p">,</span>
        <span class="n">clim_year_end</span><span class="p">,</span>
        <span class="n">hindcast_det</span><span class="p">:</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span><span class="p">,</span>
        <span class="n">best_code_da</span><span class="p">:</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">best_shape_da</span><span class="p">:</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">best_loc_da</span><span class="p">:</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">best_scale_da</span><span class="p">:</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute tercile probabilities for deterministic hindcasts.</span>

<span class="sd">        If dist_method == &#39;bestfit&#39;:</span>
<span class="sd">            - Use cluster-based best-fit distributions to:</span>
<span class="sd">                * derive terciles analytically from (best_code_da, best_shape_da, best_loc_da, best_scale_da),</span>
<span class="sd">                * compute predictive probabilities using the same family.</span>

<span class="sd">        Otherwise:</span>
<span class="sd">            - Use empirical terciles from Predictant climatology and the selected</span>
<span class="sd">              parametric / nonparametric method.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Predictant : xarray.DataArray</span>
<span class="sd">            Observed data (T, Y, X) or (T, Y, X, M).</span>
<span class="sd">        clim_year_start, clim_year_end : int or str</span>
<span class="sd">            Climatology period (inclusive) for thresholds.</span>
<span class="sd">        hindcast_det : xarray.DataArray</span>
<span class="sd">            Deterministic hindcast (T, Y, X).</span>
<span class="sd">        best_code_da, best_shape_da, best_loc_da, best_scale_da : xarray.DataArray, optional</span>
<span class="sd">            Output from WAS_TransformData.fit_best_distribution_grid, required for &#39;bestfit&#39;.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        hindcast_prob : xarray.DataArray</span>
<span class="sd">            Probabilities with dims (probability=[&#39;PB&#39;,&#39;PN&#39;,&#39;PA&#39;], T, Y, X).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Handle member dimension if present</span>
        <span class="k">if</span> <span class="s2">&quot;M&quot;</span> <span class="ow">in</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">dims</span><span class="p">:</span>
            <span class="n">Predictant</span> <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">M</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">drop_vars</span><span class="p">(</span><span class="s2">&quot;M&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>

        <span class="c1"># Ensure dimension order</span>
        <span class="n">Predictant</span> <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="s2">&quot;Y&quot;</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">)</span>

        <span class="c1"># Spatial mask</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="o">~</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">Predictant</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="mi">0</span><span class="p">)),</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>

        <span class="c1"># Climatology subset</span>
        <span class="n">clim</span> <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">sel</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="nb">slice</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">clim_year_start</span><span class="p">),</span> <span class="nb">str</span><span class="p">(</span><span class="n">clim_year_end</span><span class="p">)))</span>
        <span class="k">if</span> <span class="n">clim</span><span class="o">.</span><span class="n">sizes</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">3</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Not enough years in climatology period for terciles.&quot;</span><span class="p">)</span>

        <span class="c1"># Error variance for predictive distributions</span>
        <span class="n">error_variance</span> <span class="o">=</span> <span class="p">(</span><span class="n">Predictant</span> <span class="o">-</span> <span class="n">hindcast_det</span><span class="p">)</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="s2">&quot;T&quot;</span><span class="p">)</span>
        <span class="n">dof</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">clim</span><span class="o">.</span><span class="n">sizes</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">])</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

        <span class="c1"># Empirical terciles (used by non-bestfit methods)</span>
        <span class="n">terciles_emp</span> <span class="o">=</span> <span class="n">clim</span><span class="o">.</span><span class="n">quantile</span><span class="p">([</span><span class="mf">0.32</span><span class="p">,</span> <span class="mf">0.67</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="s2">&quot;T&quot;</span><span class="p">)</span>
        <span class="n">T1_emp</span> <span class="o">=</span> <span class="n">terciles_emp</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">quantile</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">drop_vars</span><span class="p">(</span><span class="s2">&quot;quantile&quot;</span><span class="p">)</span>
        <span class="n">T2_emp</span> <span class="o">=</span> <span class="n">terciles_emp</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">quantile</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">drop_vars</span><span class="p">(</span><span class="s2">&quot;quantile&quot;</span><span class="p">)</span>
        

        <span class="n">dm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dist_method</span>

        <span class="c1"># ---------- BESTFIT: zone-wise optimal distributions ----------</span>
        <span class="k">if</span> <span class="n">dm</span> <span class="o">==</span> <span class="s2">&quot;bestfit&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">v</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="p">(</span><span class="n">best_code_da</span><span class="p">,</span> <span class="n">best_shape_da</span><span class="p">,</span> <span class="n">best_loc_da</span><span class="p">,</span> <span class="n">best_scale_da</span><span class="p">)):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;dist_method=&#39;bestfit&#39; requires best_code_da, best_shape_da_da, best_loc_da, best_scale_da.&quot;</span>
                <span class="p">)</span>

            <span class="c1"># T1, T2 from best-fit distributions (per grid)</span>
            <span class="n">T1</span><span class="p">,</span> <span class="n">T2</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_ppf_terciles_from_code</span><span class="p">,</span>
                <span class="n">best_code_da</span><span class="p">,</span>
                <span class="n">best_shape_da</span><span class="p">,</span>
                <span class="n">best_loc_da</span><span class="p">,</span>
                <span class="n">best_scale_da</span><span class="p">,</span>
                <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[(),</span> <span class="p">(),</span> <span class="p">(),</span> <span class="p">()],</span>
                <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(),</span> <span class="p">()],</span>
                <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">dask</span><span class="o">=</span><span class="s2">&quot;parallelized&quot;</span><span class="p">,</span>
                <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span>
            <span class="p">)</span>

            <span class="c1"># Predictive probabilities using same family</span>
            <span class="n">hindcast_prob</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">calculate_tercile_probabilities_bestfit</span><span class="p">,</span>
                <span class="n">hindcast_det</span><span class="p">,</span>
                <span class="n">error_variance</span><span class="p">,</span>
                <span class="n">T1</span><span class="p">,</span>
                <span class="n">T2</span><span class="p">,</span>
                <span class="n">best_code_da</span><span class="p">,</span>
                <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;T&quot;</span><span class="p">,),</span> <span class="p">(),</span> <span class="p">(),</span> <span class="p">(),</span> <span class="p">()],</span>
                <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;probability&quot;</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">)],</span>
                <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;dof&#39;</span><span class="p">:</span> <span class="n">dof</span><span class="p">},</span>
                <span class="n">dask</span><span class="o">=</span><span class="s2">&quot;parallelized&quot;</span><span class="p">,</span>
                <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>
                <span class="n">dask_gufunc_kwargs</span><span class="o">=</span><span class="p">{</span>
                    <span class="s2">&quot;output_sizes&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;probability&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">},</span>
                    <span class="s2">&quot;allow_rechunk&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                <span class="p">},</span>
            <span class="p">)</span>

        <span class="c1"># ---------- Nonparametric ----------</span>
        <span class="k">elif</span> <span class="n">dm</span> <span class="o">==</span> <span class="s2">&quot;nonparam&quot;</span><span class="p">:</span>
            <span class="n">error_samples</span> <span class="o">=</span> <span class="n">Predictant</span> <span class="o">-</span> <span class="n">hindcast_det</span>
            <span class="n">hindcast_prob</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">calculate_tercile_probabilities_nonparametric</span><span class="p">,</span>
                <span class="n">hindcast_det</span><span class="p">,</span>
                <span class="n">error_samples</span><span class="p">,</span>
                <span class="n">T1_emp</span><span class="p">,</span>
                <span class="n">T2_emp</span><span class="p">,</span>
                <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;T&quot;</span><span class="p">,),</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,),</span> <span class="p">(),</span> <span class="p">()],</span>
                <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;probability&quot;</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">)],</span>
                <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">dask</span><span class="o">=</span><span class="s2">&quot;parallelized&quot;</span><span class="p">,</span>
                <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>
                <span class="n">dask_gufunc_kwargs</span><span class="o">=</span><span class="p">{</span>
                    <span class="s2">&quot;output_sizes&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;probability&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">},</span>
                    <span class="s2">&quot;allow_rechunk&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                <span class="p">},</span>
            <span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid dist_method: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">dist_method</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">hindcast_prob</span> <span class="o">=</span> <span class="n">hindcast_prob</span><span class="o">.</span><span class="n">assign_coords</span><span class="p">(</span>
            <span class="n">probability</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;probability&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;PB&quot;</span><span class="p">,</span> <span class="s2">&quot;PN&quot;</span><span class="p">,</span> <span class="s2">&quot;PA&quot;</span><span class="p">])</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">hindcast_prob</span> <span class="o">*</span> <span class="n">mask</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="s2">&quot;probability&quot;</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="s2">&quot;Y&quot;</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">)</span></div>


        
    <span class="c1"># ------------------------------------------------------------------</span>
    <span class="c1"># 6) FORECAST METHOD</span>
    <span class="c1"># ------------------------------------------------------------------</span>
<div class="viewcode-block" id="WAS_MLP.forecast">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_MLP.forecast">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">forecast</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> 
        <span class="n">Predictant</span><span class="p">,</span> 
        <span class="n">clim_year_start</span><span class="p">,</span> 
        <span class="n">clim_year_end</span><span class="p">,</span> 
        <span class="n">Predictor</span><span class="p">,</span> 
        <span class="n">hindcast_det</span><span class="p">,</span> 
        <span class="n">Predictor_for_year</span><span class="p">,</span> 
        <span class="n">hl_array</span><span class="p">,</span> <span class="n">act_array</span><span class="p">,</span> <span class="n">lr_array</span><span class="p">,</span> <span class="n">best_code_da</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">best_shape_da</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">best_loc_da</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">best_scale_da</span><span class="o">=</span><span class="kc">None</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generate a forecast for a single future time (e.g., future year), </span>
<span class="sd">        then compute tercile probabilities using the chosen distribution method.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Predictant : xarray.DataArray</span>
<span class="sd">            Observed data with dims (T, Y, X), used for computing climatological terciles.</span>
<span class="sd">        clim_year_start : int</span>
<span class="sd">            Start year of the climatology period.</span>
<span class="sd">        clim_year_end : int</span>
<span class="sd">            End year of the climatology period.</span>
<span class="sd">        Predictor : xarray.DataArray</span>
<span class="sd">            Historical predictor data with dims (T, features).</span>
<span class="sd">        hindcast_det : xarray.DataArray</span>
<span class="sd">            Historical deterministic forecast with dims (output=[error,prediction], T, Y, X).</span>
<span class="sd">            Used to compute error variance or error samples.</span>
<span class="sd">        Predictor_for_year : xarray.DataArray</span>
<span class="sd">            Predictor data for the forecast year, shape (features,) or (1, features).</span>
<span class="sd">        hl_array, act_array, lr_array : xarray.DataArray</span>
<span class="sd">            Hyperparameters from `compute_hyperparameters`, </span>
<span class="sd">            each with dims (Y, X) specifying local MLP settings.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        result_ : xarray.DataArray</span>
<span class="sd">            dims (&#39;output&#39;,&#39;Y&#39;,&#39;X&#39;), containing [error, prediction]. </span>
<span class="sd">            For a forecast, the &quot;error&quot; is generally NaN.</span>
<span class="sd">        hindcast_prob : xarray.DataArray</span>
<span class="sd">            dims (probability=3, Y, X) =&gt; PB, PN, PA tercile probabilities.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Provide a dummy y_test of NaNs (since we don&#39;t have future obs)</span>
        <span class="n">y_test_dummy</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">Predictant</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>  <span class="c1"># shape (Y, X)</span>

        <span class="c1"># Prepare chunk sizes</span>
        <span class="n">chunksize_x</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">Predictant</span><span class="o">.</span><span class="n">get_index</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">))</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span><span class="p">))</span>
        <span class="n">chunksize_y</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">Predictant</span><span class="o">.</span><span class="n">get_index</span><span class="p">(</span><span class="s2">&quot;Y&quot;</span><span class="p">))</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span><span class="p">))</span>

        <span class="c1"># Align times</span>
        <span class="n">Predictor</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">Predictant</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span>
        <span class="n">Predictant</span> <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="s1">&#39;T&#39;</span><span class="p">,</span> <span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">)</span>
        <span class="n">Predictor_for_year_</span> <span class="o">=</span> <span class="n">Predictor_for_year</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
        <span class="n">Predictant_st</span> <span class="o">=</span> <span class="n">standardize_timeseries</span><span class="p">(</span><span class="n">Predictant</span><span class="p">,</span> <span class="n">clim_year_start</span><span class="p">,</span> <span class="n">clim_year_end</span><span class="p">)</span>
        
        <span class="c1"># 1) Fit+predict in parallel for each grid cell</span>
        <span class="n">client</span> <span class="o">=</span> <span class="n">Client</span><span class="p">(</span><span class="n">n_workers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span><span class="p">,</span> <span class="n">threads_per_worker</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">result_da</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">,</span>
            <span class="n">Predictor</span><span class="p">,</span>                              <span class="c1"># X_train</span>
            <span class="n">Predictant</span><span class="o">.</span><span class="n">chunk</span><span class="p">({</span><span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">chunksize_y</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">chunksize_x</span><span class="p">}),</span>  <span class="c1"># y_train</span>
            <span class="n">Predictor_for_year_</span><span class="p">,</span>                   <span class="c1"># X_test</span>
            <span class="n">y_test_dummy</span><span class="o">.</span><span class="n">chunk</span><span class="p">({</span><span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">chunksize_y</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">chunksize_x</span><span class="p">}),</span>
            <span class="n">hl_array</span><span class="o">.</span><span class="n">chunk</span><span class="p">({</span><span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">chunksize_y</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">chunksize_x</span><span class="p">}),</span>
            <span class="n">act_array</span><span class="o">.</span><span class="n">chunk</span><span class="p">({</span><span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">chunksize_y</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">chunksize_x</span><span class="p">}),</span>
            <span class="n">lr_array</span><span class="o">.</span><span class="n">chunk</span><span class="p">({</span><span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">chunksize_y</span><span class="p">,</span>  <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">chunksize_x</span><span class="p">}),</span>

            <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[</span>
                <span class="p">(</span><span class="s1">&#39;T&#39;</span><span class="p">,</span><span class="s1">&#39;features&#39;</span><span class="p">),</span>  <span class="c1"># X_train</span>
                <span class="p">(</span><span class="s1">&#39;T&#39;</span><span class="p">,),</span>           <span class="c1"># y_train</span>
                <span class="p">(</span><span class="s1">&#39;features&#39;</span><span class="p">,),</span>    <span class="c1"># X_test</span>
                <span class="p">(),</span>               <span class="c1"># y_test</span>
                <span class="p">(),</span>               <span class="c1"># hidden_layer_sizes</span>
                <span class="p">(),</span>               <span class="c1"># activation</span>
                <span class="p">()</span>                <span class="c1"># learning_rate_init</span>
            <span class="p">],</span>
            <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">dask</span><span class="o">=</span><span class="s1">&#39;parallelized&#39;</span><span class="p">,</span>
            <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s1">&#39;output&#39;</span><span class="p">,)],</span>
            <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>
            <span class="n">dask_gufunc_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;output_sizes&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;output&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">}},</span>
        <span class="p">)</span>
        <span class="n">result_</span> <span class="o">=</span> <span class="n">result_da</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
        <span class="n">client</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
        <span class="n">result_</span> <span class="o">=</span> <span class="n">result_</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">output</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="n">result_</span> <span class="o">=</span> <span class="n">reverse_standardize</span><span class="p">(</span><span class="n">result_</span><span class="p">,</span> <span class="n">Predictant</span><span class="p">,</span>
                                        <span class="n">clim_year_start</span><span class="p">,</span> <span class="n">clim_year_end</span><span class="p">)</span>
        <span class="c1"># result_ =&gt; dims (output=2, Y, X). </span>
        <span class="c1"># For a real future forecast, &quot;error&quot; is NaN, &quot;prediction&quot; is the forecast.</span>

        <span class="c1"># 2) Compute thresholds T1, T2 from climatology</span>
        <span class="n">index_start</span> <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">get_index</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">get_loc</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">clim_year_start</span><span class="p">))</span><span class="o">.</span><span class="n">start</span>
        <span class="n">index_end</span>   <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">get_index</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">get_loc</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">clim_year_end</span><span class="p">))</span><span class="o">.</span><span class="n">stop</span>
        <span class="n">rainfall_for_tercile</span> <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="nb">slice</span><span class="p">(</span><span class="n">index_start</span><span class="p">,</span> <span class="n">index_end</span><span class="p">))</span>
        <span class="n">terciles</span> <span class="o">=</span> <span class="n">rainfall_for_tercile</span><span class="o">.</span><span class="n">quantile</span><span class="p">([</span><span class="mf">0.32</span><span class="p">,</span> <span class="mf">0.67</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="s1">&#39;T&#39;</span><span class="p">)</span>
        <span class="n">T1_emp</span> <span class="o">=</span> <span class="n">terciles</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">quantile</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">drop_vars</span><span class="p">(</span><span class="s1">&#39;quantile&#39;</span><span class="p">)</span>
        <span class="n">T2_emp</span> <span class="o">=</span> <span class="n">terciles</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">quantile</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">drop_vars</span><span class="p">(</span><span class="s1">&#39;quantile&#39;</span><span class="p">)</span>
        <span class="n">error_variance</span> <span class="o">=</span> <span class="p">(</span><span class="n">Predictant</span> <span class="o">-</span> <span class="n">hindcast_det</span><span class="p">)</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="s1">&#39;T&#39;</span><span class="p">)</span>
        
        <span class="c1"># Expand single prediction to T=1 so probability methods can handle it</span>
        <span class="n">forecast_expanded</span> <span class="o">=</span> <span class="n">result_</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span>
            <span class="n">T</span><span class="o">=</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">Timestamp</span><span class="p">(</span><span class="n">Predictor_for_year</span><span class="o">.</span><span class="n">coords</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">to_pydatetime</span><span class="p">()]</span>
        <span class="p">)</span>
        <span class="n">year</span> <span class="o">=</span> <span class="n">Predictor_for_year</span><span class="o">.</span><span class="n">coords</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;datetime64[Y]&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1970</span>
        <span class="c1"># year = Predictor_for_year.coords[&#39;T&#39;].values.astype(&#39;datetime64[Y]&#39;).astype(int)[0] + 1970  </span>
        <span class="n">T_value_1</span> <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">coords</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>  <span class="c1"># Get the datetime64 value from da1</span>
        <span class="n">month_1</span> <span class="o">=</span> <span class="n">T_value_1</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;datetime64[M]&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span> <span class="o">%</span> <span class="mi">12</span> <span class="o">+</span> <span class="mi">1</span>  <span class="c1"># Extract month</span>
        <span class="n">new_T_value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">datetime64</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">year</span><span class="si">}</span><span class="s2">-</span><span class="si">{</span><span class="n">month_1</span><span class="si">:</span><span class="s2">02d</span><span class="si">}</span><span class="s2">-</span><span class="si">{</span><span class="mi">1</span><span class="si">:</span><span class="s2">02d</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        
        <span class="n">forecast_expanded</span> <span class="o">=</span> <span class="n">forecast_expanded</span><span class="o">.</span><span class="n">assign_coords</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span><span class="p">([</span><span class="n">new_T_value</span><span class="p">],</span> <span class="n">dims</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">]))</span>
        <span class="n">forecast_expanded</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">forecast_expanded</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;datetime64[ns]&#39;</span><span class="p">)</span>

        <span class="n">dof</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">rainfall_for_tercile</span><span class="o">.</span><span class="n">sizes</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">])</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

        <span class="n">dm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dist_method</span>

        <span class="c1"># ---------- BESTFIT ----------</span>
        <span class="k">if</span> <span class="n">dm</span> <span class="o">==</span> <span class="s2">&quot;bestfit&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">v</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="p">(</span><span class="n">best_code_da</span><span class="p">,</span> <span class="n">best_shape_da</span><span class="p">,</span> <span class="n">best_loc_da</span><span class="p">,</span> <span class="n">best_scale_da</span><span class="p">)):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;dist_method=&#39;bestfit&#39; requires best_code_da, best_shape_da, best_loc_da, best_scale_da.&quot;</span>
                <span class="p">)</span>
            
            <span class="n">T1</span><span class="p">,</span> <span class="n">T2</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_ppf_terciles_from_code</span><span class="p">,</span>
                <span class="n">best_code_da</span><span class="p">,</span>
                <span class="n">best_shape_da</span><span class="p">,</span>
                <span class="n">best_loc_da</span><span class="p">,</span>
                <span class="n">best_scale_da</span><span class="p">,</span>
                <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[(),</span> <span class="p">(),</span> <span class="p">(),</span> <span class="p">()],</span>
                <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(),</span> <span class="p">()],</span>
                <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">dask</span><span class="o">=</span><span class="s2">&quot;parallelized&quot;</span><span class="p">,</span>
                <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span>
            <span class="p">)</span>

            <span class="n">forecast_prob</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">calculate_tercile_probabilities_bestfit</span><span class="p">,</span>
                <span class="n">forecast_expanded</span><span class="p">,</span>
                <span class="n">error_variance</span><span class="p">,</span>
                <span class="n">T1</span><span class="p">,</span>
                <span class="n">T2</span><span class="p">,</span>
                <span class="n">best_code_da</span><span class="p">,</span>
                <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;T&quot;</span><span class="p">,),</span> <span class="p">(),</span> <span class="p">(),</span> <span class="p">(),</span> <span class="p">()],</span>
                <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;probability&quot;</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">)],</span>
                <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">dask</span><span class="o">=</span><span class="s2">&quot;parallelized&quot;</span><span class="p">,</span>
                <span class="n">kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;dof&quot;</span><span class="p">:</span> <span class="n">dof</span><span class="p">},</span>
                <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>
                <span class="n">dask_gufunc_kwargs</span><span class="o">=</span><span class="p">{</span>
                    <span class="s2">&quot;output_sizes&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;probability&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">},</span>
                    <span class="s2">&quot;allow_rechunk&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                <span class="p">},</span>
            <span class="p">)</span>

        <span class="c1"># ---------- Nonparametric ----------</span>
        <span class="k">elif</span> <span class="n">dm</span> <span class="o">==</span> <span class="s2">&quot;nonparam&quot;</span><span class="p">:</span>
            <span class="n">error_samples</span> <span class="o">=</span> <span class="n">Predictant</span> <span class="o">-</span> <span class="n">hindcast_det</span>
            <span class="n">forecast_prob</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">calculate_tercile_probabilities_nonparametric</span><span class="p">,</span>
                <span class="n">forecast_expanded</span><span class="p">,</span>
                <span class="n">error_samples</span><span class="p">,</span>
                <span class="n">T1_emp</span><span class="p">,</span>
                <span class="n">T2_emp</span><span class="p">,</span>
                <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;T&quot;</span><span class="p">,),</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,),</span> <span class="p">(),</span> <span class="p">()],</span>
                <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;probability&quot;</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">)],</span>
                <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">dask</span><span class="o">=</span><span class="s2">&quot;parallelized&quot;</span><span class="p">,</span>
                <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>
                <span class="n">dask_gufunc_kwargs</span><span class="o">=</span><span class="p">{</span>
                    <span class="s2">&quot;output_sizes&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;probability&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">},</span>
                    <span class="s2">&quot;allow_rechunk&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                <span class="p">},</span>
            <span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid dist_method: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">dist_method</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">forecast_prob</span> <span class="o">=</span> <span class="n">forecast_prob</span><span class="o">.</span><span class="n">assign_coords</span><span class="p">(</span><span class="n">probability</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;probability&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;PB&#39;</span><span class="p">,</span> <span class="s1">&#39;PN&#39;</span><span class="p">,</span> <span class="s1">&#39;PA&#39;</span><span class="p">]))</span>
        <span class="k">return</span> <span class="n">forecast_expanded</span><span class="p">,</span> <span class="n">forecast_prob</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="s1">&#39;probability&#39;</span><span class="p">,</span> <span class="s1">&#39;T&#39;</span><span class="p">,</span> <span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">)</span></div>
</div>


<div class="viewcode-block" id="WAS_RandomForest_XGBoost_ML_Stacking">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_RandomForest_XGBoost_ML_Stacking">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">WAS_RandomForest_XGBoost_ML_Stacking</span><span class="p">:</span>
<div class="viewcode-block" id="WAS_RandomForest_XGBoost_ML_Stacking.__init__">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_RandomForest_XGBoost_ML_Stacking.__init__">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">nb_cores</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">dist_method</span><span class="o">=</span><span class="s2">&quot;nonparam&quot;</span><span class="p">,</span>
        <span class="n">n_clusters</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
        <span class="n">param_grid</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">optimization_method</span><span class="o">=</span><span class="s2">&quot;grid&quot;</span><span class="p">,</span>  <span class="c1"># New parameter</span>
        <span class="n">n_trials</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>  <span class="c1"># New parameter</span>
        <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>  <span class="c1"># New parameter</span>
        <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>  <span class="c1"># New parameter</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span> <span class="o">=</span> <span class="n">nb_cores</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dist_method</span> <span class="o">=</span> <span class="n">dist_method</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span> <span class="o">=</span> <span class="n">n_clusters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimization_method</span> <span class="o">=</span> <span class="n">optimization_method</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_trials</span> <span class="o">=</span> <span class="n">n_trials</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cv</span> <span class="o">=</span> <span class="n">cv</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span>

        <span class="c1"># Define minimal default param_grid if none is provided</span>
        <span class="k">if</span> <span class="n">param_grid</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s2">&quot;rf__n_estimators&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">],</span>
                <span class="s2">&quot;rf__max_depth&quot;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">],</span>
                <span class="s2">&quot;xgb__n_estimators&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span>
                <span class="s2">&quot;xgb__max_depth&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">9</span><span class="p">],</span>
                <span class="s2">&quot;xgb__learning_rate&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span>
                <span class="s2">&quot;xgb__subsample&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span>
                <span class="s2">&quot;final_estimator__fit_intercept&quot;</span><span class="p">:</span> <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">]</span>
            <span class="p">}</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">param_grid</span> <span class="o">=</span> <span class="n">param_grid</span>
            
        <span class="c1"># Initialize optimizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">BaseOptimizer</span><span class="p">(</span>
            <span class="n">optimization_method</span><span class="o">=</span><span class="n">optimization_method</span><span class="p">,</span>
            <span class="n">n_trials</span><span class="o">=</span><span class="n">n_trials</span><span class="p">,</span>
            <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span>
            <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="WAS_RandomForest_XGBoost_ML_Stacking.compute_hyperparameters">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_RandomForest_XGBoost_ML_Stacking.compute_hyperparameters">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">compute_hyperparameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">predictand</span><span class="p">,</span> <span class="n">predictor</span><span class="p">,</span> <span class="n">clim_year_start</span><span class="p">,</span> <span class="n">clim_year_end</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Optimized version with Bayesian optimization.&quot;&quot;&quot;</span>
        <span class="n">predictor</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">predictand</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span>
        <span class="n">df</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">predictand</span><span class="o">.</span><span class="n">to_dataframe</span><span class="p">()</span>
                      <span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
                      <span class="o">.</span><span class="n">dropna</span><span class="p">()</span>
                      <span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">])</span>
        <span class="p">)</span>
        <span class="n">col_name</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
        <span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
        <span class="n">df</span><span class="p">[</span><span class="s2">&quot;cluster&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">df</span><span class="p">[[</span><span class="n">col_name</span><span class="p">]])</span>
    
        <span class="n">df_unique</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop_duplicates</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Y&quot;</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">])</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">df_unique</span><span class="o">.</span><span class="n">set_index</span><span class="p">([</span><span class="s2">&quot;Y&quot;</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">to_xarray</span><span class="p">()</span>
    
        <span class="n">cluster_da</span> <span class="o">=</span> <span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;cluster&quot;</span><span class="p">]</span> <span class="o">*</span>
                      <span class="n">xr</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="o">~</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">predictand</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="mi">0</span><span class="p">)),</span> <span class="mi">1</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
                     <span class="p">)</span><span class="o">.</span><span class="n">drop_vars</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
    
        <span class="n">_</span><span class="p">,</span> <span class="n">cluster_da</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">align</span><span class="p">(</span><span class="n">predictand</span><span class="p">,</span> <span class="n">cluster_da</span><span class="p">,</span> <span class="n">join</span><span class="o">=</span><span class="s2">&quot;outer&quot;</span><span class="p">)</span>
    
        <span class="c1"># Build the stacking model</span>
        <span class="n">base_rf</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
        <span class="n">base_xgb</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">XGBRegressor</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
        
        <span class="n">meta_pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
            <span class="p">(</span><span class="s1">&#39;scaler&#39;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>
            <span class="p">(</span><span class="s1">&#39;meta_lin&#39;</span><span class="p">,</span> <span class="n">LinearRegression</span><span class="p">())</span>
        <span class="p">])</span>
        
        
        <span class="n">stacking_core</span> <span class="o">=</span> <span class="n">StackingRegressor</span><span class="p">(</span>
            <span class="n">estimators</span><span class="o">=</span><span class="p">[</span>
                <span class="p">(</span><span class="s2">&quot;rf&quot;</span><span class="p">,</span> <span class="n">base_rf</span><span class="p">),</span> 
                <span class="p">(</span><span class="s2">&quot;xgb&quot;</span><span class="p">,</span> <span class="n">base_xgb</span><span class="p">)</span>
            <span class="p">],</span>
            <span class="n">final_estimator</span><span class="o">=</span><span class="n">meta_pipeline</span><span class="p">,</span>
            <span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
            <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span>
        <span class="p">)</span>
        
        <span class="n">stacking_model</span> <span class="o">=</span> <span class="n">TransformedTargetRegressor</span><span class="p">(</span>
            <span class="n">regressor</span><span class="o">=</span><span class="n">stacking_core</span><span class="p">,</span>
            <span class="n">transformer</span><span class="o">=</span><span class="n">StandardScaler</span><span class="p">()</span>
        <span class="p">)</span>
    
        <span class="n">unique_clusters</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">cluster_da</span><span class="p">)</span>
        <span class="n">unique_clusters</span> <span class="o">=</span> <span class="n">unique_clusters</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">unique_clusters</span><span class="p">)]</span>
        <span class="n">best_params_for_cluster</span> <span class="o">=</span> <span class="p">{}</span>
    
        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">unique_clusters</span><span class="p">:</span>
            <span class="n">mask_c</span> <span class="o">=</span> <span class="p">(</span><span class="n">cluster_da</span> <span class="o">==</span> <span class="n">c</span><span class="p">)</span>
            <span class="n">y_cluster</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">predictand</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">mask_c</span><span class="p">)</span>
                          <span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Y&quot;</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">],</span> <span class="n">skipna</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                          <span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="s2">&quot;T&quot;</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_cluster</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">])</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">continue</span>
    
            <span class="n">predictor_cluster</span> <span class="o">=</span> <span class="n">predictor</span><span class="o">.</span><span class="n">sel</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="n">y_cluster</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">])</span>
            <span class="n">X_mat</span> <span class="o">=</span> <span class="n">predictor_cluster</span><span class="o">.</span><span class="n">values</span>
            <span class="n">y_vec</span> <span class="o">=</span> <span class="n">y_cluster</span><span class="o">.</span><span class="n">values</span>
    
            <span class="c1"># Use optimizer to find best parameters</span>
            <span class="n">best_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span>
                <span class="n">stacking_model</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">param_grid</span><span class="p">,</span>
                <span class="n">X_mat</span><span class="p">,</span>
                <span class="n">y_vec</span><span class="p">,</span>
                <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;neg_mean_squared_error&#39;</span>
            <span class="p">)</span>
            <span class="n">best_params_for_cluster</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">c</span><span class="p">)]</span> <span class="o">=</span> <span class="n">best_params</span>
    
        <span class="c1"># Broadcast best hyperparameter sets back to each grid cell</span>
        <span class="n">best_param_da</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">cluster_da</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">object</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">c</span><span class="p">,</span> <span class="n">bp</span> <span class="ow">in</span> <span class="n">best_params_for_cluster</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">c_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">cluster_da</span> <span class="o">==</span> <span class="n">c</span><span class="p">)</span>
            <span class="n">best_param_da</span> <span class="o">=</span> <span class="n">best_param_da</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="o">~</span><span class="n">c_mask</span><span class="p">,</span> <span class="n">other</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">bp</span><span class="p">))</span>
    
        <span class="n">best_param_da</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">align</span><span class="p">(</span><span class="n">best_param_da</span><span class="p">,</span> <span class="n">predictand</span><span class="p">,</span> <span class="n">join</span><span class="o">=</span><span class="s2">&quot;outer&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">best_param_da</span><span class="p">,</span> <span class="n">cluster_da</span></div>


    <span class="c1"># ----------------------------------------------------------------------</span>
    <span class="c1"># 2) FIT + PREDICT FOR A SINGLE GRID CELL</span>
    <span class="c1"># ----------------------------------------------------------------------</span>
<div class="viewcode-block" id="WAS_RandomForest_XGBoost_ML_Stacking.fit_predict">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_RandomForest_XGBoost_ML_Stacking.fit_predict">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">fit_predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">best_params_str</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fit a local StackingRegressor with the best hyperparams (parsed from best_params_str),</span>
<span class="sd">        then predict on X_test, returning [error, prediction].</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X_train : np.ndarray, shape (n_samples, n_features)</span>
<span class="sd">        y_train : np.ndarray, shape (n_samples,)</span>
<span class="sd">        X_test :  np.ndarray, shape (n_features,) or (1, n_features)</span>
<span class="sd">        y_test :  float or np.nan</span>
<span class="sd">        best_params_str : str</span>
<span class="sd">            String of best_params (e.g. &quot;{&#39;estimators__rf__n_estimators&#39;:100, ...}&quot;)</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        np.ndarray of shape (2,)</span>
<span class="sd">            [error, predicted_value]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span> <span class="o">&amp;</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">X_train</span><span class="p">),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">best_params_str</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">best_params_str</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">])</span>

        <span class="c1"># Parse param dictionary</span>
        <span class="n">best_params</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="n">best_params_str</span><span class="p">)</span>  <span class="c1"># or safer parse, e.g. json.loads</span>

        <span class="c1"># Build fresh model</span>
        <span class="n">base_rf</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
        <span class="n">base_xgb</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">XGBRegressor</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
        
        <span class="n">meta_pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
            <span class="p">(</span><span class="s1">&#39;scaler&#39;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>
            <span class="p">(</span><span class="s1">&#39;meta_lin&#39;</span><span class="p">,</span> <span class="n">LinearRegression</span><span class="p">())</span>
        <span class="p">])</span>
        
        
        <span class="n">stacking_core</span> <span class="o">=</span> <span class="n">StackingRegressor</span><span class="p">(</span>
            <span class="n">estimators</span><span class="o">=</span><span class="p">[</span>
                <span class="p">(</span><span class="s2">&quot;rf&quot;</span><span class="p">,</span> <span class="n">base_rf</span><span class="p">),</span> 
                <span class="p">(</span><span class="s2">&quot;xgb&quot;</span><span class="p">,</span> <span class="n">base_xgb</span><span class="p">)</span>
            <span class="p">],</span>
            <span class="n">final_estimator</span><span class="o">=</span><span class="n">meta_pipeline</span><span class="p">,</span>
            <span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
            <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span>
        <span class="p">)</span>
        
        <span class="n">stacking_model</span> <span class="o">=</span> <span class="n">TransformedTargetRegressor</span><span class="p">(</span>
            <span class="n">regressor</span><span class="o">=</span><span class="n">stacking_core</span><span class="p">,</span>
            <span class="n">transformer</span><span class="o">=</span><span class="n">StandardScaler</span><span class="p">()</span>
        <span class="p">)</span>

        <span class="c1"># Set best_params</span>
        <span class="c1"># Call set_params on the internal stacking core</span>
        <span class="n">stacking_model</span><span class="o">.</span><span class="n">regressor</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="o">**</span><span class="n">best_params</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">mask</span><span class="p">):</span>
            <span class="n">X_c</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="n">mask</span><span class="p">,</span> <span class="p">:]</span>
            <span class="n">y_c</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>
            <span class="n">stacking_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_c</span><span class="p">,</span> <span class="n">y_c</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">X_test</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

            <span class="n">preds</span> <span class="o">=</span> <span class="n">stacking_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
            <span class="c1"># e.g., clamp negative if precipitation</span>
            <span class="n">preds</span><span class="p">[</span><span class="n">preds</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="n">err</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span> <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span> <span class="k">else</span> <span class="p">(</span><span class="n">y_test</span> <span class="o">-</span> <span class="n">preds</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">err</span><span class="p">,</span> <span class="n">preds</span><span class="p">])</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">])</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span></div>


    <span class="c1"># ----------------------------------------------------------------------</span>
    <span class="c1"># 3) PARALLELIZED MODEL TRAINING &amp; PREDICTION OVER SPACE</span>
    <span class="c1"># ----------------------------------------------------------------------</span>
<div class="viewcode-block" id="WAS_RandomForest_XGBoost_ML_Stacking.compute_model">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_RandomForest_XGBoost_ML_Stacking.compute_model">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">compute_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">best_param_da</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Parallel fit/predict across the entire spatial domain, using cluster-based hyperparams.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X_train : xarray.DataArray</span>
<span class="sd">            Training data (predictors) with dims (&#39;T&#39;,&#39;features&#39;).</span>
<span class="sd">        y_train : xarray.DataArray</span>
<span class="sd">            Training target with dims (&#39;T&#39;,&#39;Y&#39;,&#39;X&#39;).</span>
<span class="sd">        X_test : xarray.DataArray</span>
<span class="sd">            Test data (predictors), shape (features,) or broadcastable across (Y, X).</span>
<span class="sd">        y_test : xarray.DataArray</span>
<span class="sd">            Test target with dims (&#39;Y&#39;,&#39;X&#39;).</span>
<span class="sd">        best_param_da : xarray.DataArray</span>
<span class="sd">            The per-grid best_params from compute_hyperparameters (as strings).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        xarray.DataArray</span>
<span class="sd">            dims (&#39;output&#39;,&#39;Y&#39;,&#39;X&#39;), where &#39;output&#39; = [error, prediction].</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">chunksize_x</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="o">.</span><span class="n">get_index</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">))</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span><span class="p">))</span>
        <span class="n">chunksize_y</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="o">.</span><span class="n">get_index</span><span class="p">(</span><span class="s2">&quot;Y&quot;</span><span class="p">))</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span><span class="p">))</span>

        <span class="c1"># Align time</span>
        <span class="n">X_train</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span>
        <span class="n">y_train</span> <span class="o">=</span> <span class="n">y_train</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="s1">&#39;T&#39;</span><span class="p">,</span> <span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">)</span>

        <span class="c1"># Squeeze test data</span>
        <span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
        <span class="n">y_test</span> <span class="o">=</span> <span class="n">y_test</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span><span class="s1">&#39;X&#39;</span><span class="p">)</span>

        <span class="n">client</span> <span class="o">=</span> <span class="n">Client</span><span class="p">(</span><span class="n">n_workers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span><span class="p">,</span> <span class="n">threads_per_worker</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">result_da</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">,</span>
            <span class="n">X_train</span><span class="p">,</span>
            <span class="n">y_train</span><span class="o">.</span><span class="n">chunk</span><span class="p">({</span><span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">chunksize_y</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">chunksize_x</span><span class="p">}),</span>
            <span class="n">X_test</span><span class="p">,</span>
            <span class="n">y_test</span><span class="o">.</span><span class="n">chunk</span><span class="p">({</span><span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">chunksize_y</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">chunksize_x</span><span class="p">}),</span>
            <span class="n">best_param_da</span><span class="o">.</span><span class="n">chunk</span><span class="p">({</span><span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">chunksize_y</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">chunksize_x</span><span class="p">}),</span>
            <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[</span>
                <span class="p">(</span><span class="s1">&#39;T&#39;</span><span class="p">,</span><span class="s1">&#39;features&#39;</span><span class="p">),</span>  <span class="c1"># X_train</span>
                <span class="p">(</span><span class="s1">&#39;T&#39;</span><span class="p">,),</span>           <span class="c1"># y_train</span>
                <span class="p">(</span><span class="s1">&#39;features&#39;</span><span class="p">,),</span>    <span class="c1"># X_test</span>
                <span class="p">(),</span>               <span class="c1"># y_test</span>
                <span class="p">()</span>                <span class="c1"># best_params_str</span>
            <span class="p">],</span>
            <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">dask</span><span class="o">=</span><span class="s1">&#39;parallelized&#39;</span><span class="p">,</span>
            <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s1">&#39;output&#39;</span><span class="p">,)],</span>
            <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>
            <span class="n">dask_gufunc_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;output_sizes&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;output&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">}},</span>
        <span class="p">)</span>
        <span class="n">result_</span> <span class="o">=</span> <span class="n">result_da</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
        <span class="n">client</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">result_</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">output</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></div>


    <span class="c1"># ------------------ Probability Calculation Methods ------------------</span>

<div class="viewcode-block" id="WAS_RandomForest_XGBoost_ML_Stacking._ppf_terciles_from_code">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_RandomForest_XGBoost_ML_Stacking._ppf_terciles_from_code">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_ppf_terciles_from_code</span><span class="p">(</span><span class="n">dist_code</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return tercile thresholds (T1, T2) from best-fit distribution parameters.</span>
<span class="sd">    </span>
<span class="sd">        dist_code:</span>
<span class="sd">            1: norm</span>
<span class="sd">            2: lognorm</span>
<span class="sd">            3: expon</span>
<span class="sd">            4: gamma</span>
<span class="sd">            5: weibull_min</span>
<span class="sd">            6: t</span>
<span class="sd">            7: poisson</span>
<span class="sd">            8: nbinom</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">dist_code</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
    
        <span class="n">code</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">dist_code</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                    <span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">lognorm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                    <span class="n">lognorm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">expon</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                    <span class="n">expon</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">gamma</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                    <span class="n">gamma</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">5</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">weibull_min</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                    <span class="n">weibull_min</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">6</span><span class="p">:</span>
                <span class="c1"># Note: Renamed &#39;t_dist&#39; to &#39;t&#39; for standard scipy.stats</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">t</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                    <span class="n">t</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">7</span><span class="p">:</span>
                <span class="c1"># Poisson: poisson.ppf(q, mu, loc=0)</span>
                <span class="c1"># ASSUMPTION: &#39;mu&#39; (mean) is passed as &#39;shape&#39;</span>
                <span class="c1">#             &#39;loc&#39; is passed as &#39;loc&#39;</span>
                <span class="c1">#             &#39;scale&#39; is unused</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">poisson</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">),</span>
                    <span class="n">poisson</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">8</span><span class="p">:</span>
                <span class="c1"># Negative Binomial: nbinom.ppf(q, n, p, loc=0)</span>
                <span class="c1"># ASSUMPTION: &#39;n&#39; (successes) is passed as &#39;shape&#39;</span>
                <span class="c1">#             &#39;p&#39; (probability) is passed as &#39;scale&#39;</span>
                <span class="c1">#             &#39;loc&#39; is passed as &#39;loc&#39;</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">nbinom</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">scale</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">),</span>
                    <span class="n">nbinom</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">scale</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">),</span>
                <span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
    
        <span class="c1"># Fallback if code is not 1-8</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span></div>

        
<div class="viewcode-block" id="WAS_RandomForest_XGBoost_ML_Stacking.weibull_shape_solver">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_RandomForest_XGBoost_ML_Stacking.weibull_shape_solver">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">weibull_shape_solver</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">V</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Function to find the root of the Weibull shape parameter &#39;k&#39;.</span>
<span class="sd">        We find &#39;k&#39; such that the theoretical variance/mean^2 ratio</span>
<span class="sd">        matches the observed V/M^2 ratio.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Guard against invalid &#39;k&#39; values during solving</span>
        <span class="k">if</span> <span class="n">k</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">g1</span> <span class="o">=</span> <span class="n">gamma_function</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="mi">1</span><span class="o">/</span><span class="n">k</span><span class="p">)</span>
            <span class="n">g2</span> <span class="o">=</span> <span class="n">gamma_function</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="mi">2</span><span class="o">/</span><span class="n">k</span><span class="p">)</span>
            
            <span class="c1"># This is the V/M^2 ratio *implied by k*</span>
            <span class="n">implied_v_over_m_sq</span> <span class="o">=</span> <span class="p">(</span><span class="n">g2</span> <span class="o">/</span> <span class="p">(</span><span class="n">g1</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span> <span class="o">-</span> <span class="mi">1</span>
            
            <span class="c1"># This is the *observed* ratio</span>
            <span class="n">observed_v_over_m_sq</span> <span class="o">=</span> <span class="n">V</span> <span class="o">/</span> <span class="p">(</span><span class="n">M</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
            
            <span class="c1"># Return the difference (we want this to be 0)</span>
            <span class="k">return</span> <span class="n">observed_v_over_m_sq</span> <span class="o">-</span> <span class="n">implied_v_over_m_sq</span>
        <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
            <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span> <span class="c1"># Handle math errors</span></div>


<div class="viewcode-block" id="WAS_RandomForest_XGBoost_ML_Stacking.calculate_tercile_probabilities_bestfit">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_RandomForest_XGBoost_ML_Stacking.calculate_tercile_probabilities_bestfit">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">calculate_tercile_probabilities_bestfit</span><span class="p">(</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">error_variance</span><span class="p">,</span> <span class="n">T1</span><span class="p">,</span> <span class="n">T2</span><span class="p">,</span> <span class="n">dist_code</span><span class="p">,</span> <span class="n">dof</span> 
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generic tercile probabilities using best-fit family per grid cell.</span>

<span class="sd">        Inputs (per grid cell):</span>
<span class="sd">        - best_guess : 1D array over T (hindcast_det or forecast_det)</span>
<span class="sd">        - T1, T2     : scalar terciles from climatological best-fit distribution</span>
<span class="sd">        - dist_code  : int, as in _ppf_terciles_from_code</span>
<span class="sd">        - shape, loc, scale : scalars from climatology fit</span>

<span class="sd">        Strategy:</span>
<span class="sd">        - For each time step, build a predictive distribution of the same family:</span>
<span class="sd">            * Use best_guess[t] to adjust mean / location;</span>
<span class="sd">            * Keep shape parameters from climatology.</span>
<span class="sd">        - Then compute probabilities:</span>
<span class="sd">            P(B) = F(T1), P(N) = F(T2) - F(T1), P(A) = 1 - F(T2).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        
        <span class="n">best_guess</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">best_guess</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span>
        <span class="n">error_variance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">error_variance</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
        <span class="c1"># T1 = np.asarray(T1, dtype=float)</span>
        <span class="c1"># T2 = np.asarray(T2, dtype=float)</span>
        <span class="n">n_time</span> <span class="o">=</span> <span class="n">best_guess</span><span class="o">.</span><span class="n">size</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="n">n_time</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">best_guess</span><span class="p">))</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">dist_code</span><span class="p">)</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">T1</span><span class="p">)</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">T2</span><span class="p">)</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">error_variance</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">out</span>

        <span class="n">code</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">dist_code</span><span class="p">)</span>

        <span class="c1"># Normal: loc = forecast; scale from clim</span>
        <span class="k">if</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">error_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">error_variance</span><span class="p">)</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">error_std</span><span class="p">)</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">error_std</span><span class="p">)</span> <span class="o">-</span> <span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">error_std</span><span class="p">)</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">error_std</span><span class="p">)</span>

        <span class="c1"># Lognormal: shape = sigma from clim; enforce mean = best_guess</span>
        <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">sigma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">error_variance</span> <span class="o">/</span> <span class="p">(</span><span class="n">best_guess</span><span class="o">**</span><span class="mi">2</span><span class="p">)))</span>
            <span class="n">mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">best_guess</span><span class="p">)</span> <span class="o">-</span> <span class="n">sigma</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="mi">2</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">lognorm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">mu</span><span class="p">))</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">lognorm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">mu</span><span class="p">))</span> <span class="o">-</span> <span class="n">lognorm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">mu</span><span class="p">))</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">lognorm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">mu</span><span class="p">))</span>      


        <span class="c1"># Exponential: keep scale from clim; shift loc so mean = best_guess</span>
        <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
            <span class="n">c1</span> <span class="o">=</span> <span class="n">expon</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">error_variance</span><span class="p">))</span>
            <span class="n">c2</span> <span class="o">=</span> <span class="n">expon</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc_t</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">error_variance</span><span class="p">))</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c2</span> <span class="o">-</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">c2</span>

        <span class="c1"># Gamma: use shape from clim; set scale so mean = best_guess</span>
        <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
            <span class="n">alpha</span> <span class="o">=</span> <span class="p">(</span><span class="n">best_guess</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="n">error_variance</span>
            <span class="n">theta</span> <span class="o">=</span> <span class="n">error_variance</span> <span class="o">/</span> <span class="n">best_guess</span>
            <span class="n">c1</span> <span class="o">=</span> <span class="n">gamma</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">theta</span><span class="p">)</span>
            <span class="n">c2</span> <span class="o">=</span> <span class="n">gamma</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">theta</span><span class="p">)</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c2</span> <span class="o">-</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">c2</span>

        <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">5</span><span class="p">:</span> <span class="c1"># Assuming 5 is for Weibull   </span>
        
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_time</span><span class="p">):</span>
                <span class="c1"># Get the scalar values for this specific element (e.g., grid cell)</span>
                <span class="n">M</span> <span class="o">=</span> <span class="n">best_guess</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">M</span><span class="p">)</span>
                <span class="n">V</span> <span class="o">=</span> <span class="n">error_variance</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">V</span><span class="p">)</span>
                
                <span class="c1"># Handle cases with no variance to avoid division by zero</span>
                <span class="k">if</span> <span class="n">V</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">M</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                    <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                    <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                    <span class="k">continue</span> <span class="c1"># Skip to the next element</span>
        
                <span class="c1"># --- 1. Numerically solve for shape &#39;k&#39; ---</span>
                <span class="c1"># We need a reasonable starting guess. 2.0 is common (Rayleigh dist.)</span>
                <span class="n">initial_guess</span> <span class="o">=</span> <span class="mf">2.0</span>
                
                <span class="c1"># fsolve finds the root of our helper function</span>
                <span class="n">k</span> <span class="o">=</span> <span class="n">fsolve</span><span class="p">(</span><span class="n">weibull_shape_solver</span><span class="p">,</span> <span class="n">initial_guess</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">V</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>
        
                <span class="c1"># --- 2. Check for bad solution and calculate scale &#39;lambda&#39; ---</span>
                <span class="k">if</span> <span class="n">k</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="c1"># Solver failed</span>
                    <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                    <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                    <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                    <span class="k">continue</span>
                
                <span class="c1"># With &#39;k&#39; found, we can now algebraically find scale &#39;lambda&#39;</span>
                <span class="c1"># In scipy.stats, scale is &#39;scale&#39;</span>
                <span class="n">lambda_scale</span> <span class="o">=</span> <span class="n">M</span> <span class="o">/</span> <span class="n">gamma_function</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="mi">1</span><span class="o">/</span><span class="n">k</span><span class="p">)</span>
        
                <span class="c1"># --- 3. Calculate Probabilities ---</span>
                <span class="c1"># In scipy.stats, shape &#39;k&#39; is &#39;c&#39;</span>
                <span class="c1"># Use the T1 and T2 values for this specific element</span>
                
                <span class="n">c1</span> <span class="o">=</span> <span class="n">weibull_min</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">lambda_scale</span><span class="p">)</span>
                <span class="n">c2</span> <span class="o">=</span> <span class="n">weibull_min</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">lambda_scale</span><span class="p">)</span>
        
                <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">c1</span>
                <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">c2</span> <span class="o">-</span> <span class="n">c1</span>
                <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">c2</span>

        <span class="c1"># Student-t: df from clim; scale from clim; loc = best_guess</span>
        <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">6</span><span class="p">:</span>       
            <span class="c1"># Check if df is valid for variance calculation</span>
            <span class="k">if</span> <span class="n">dof</span> <span class="o">&lt;=</span> <span class="mi">2</span><span class="p">:</span>
                <span class="c1"># Cannot calculate scale, fill with NaNs</span>
                <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># 1. Calculate t-distribution parameters</span>
                <span class="c1"># &#39;loc&#39; (mean) is just the best_guess</span>
                <span class="n">loc</span> <span class="o">=</span> <span class="n">best_guess</span>
                <span class="c1"># &#39;scale&#39; is calculated from the variance and df</span>
                <span class="c1"># Variance = scale**2 * (df / (df - 2))</span>
                <span class="n">scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">error_variance</span> <span class="o">*</span> <span class="p">(</span><span class="n">dof</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="n">dof</span><span class="p">)</span>
                
                <span class="c1"># 2. Calculate probabilities</span>
                <span class="n">c1</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">dof</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">)</span>
                <span class="n">c2</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">dof</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">)</span>

                <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c1</span>
                <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c2</span> <span class="o">-</span> <span class="n">c1</span>
                <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">c2</span>

        <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">7</span><span class="p">:</span> <span class="c1"># Assuming 7 is for Poisson</span>
            
            <span class="c1"># --- 1. Set the Poisson parameter &#39;mu&#39; ---</span>
            <span class="c1"># The &#39;mu&#39; parameter is the mean.</span>
            
            <span class="c1"># A warning is strongly recommended if error_variance is different from best_guess</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">error_variance</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Warning: &#39;error_variance&#39; is not equal to &#39;best_guess&#39;.&quot;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Poisson model assumes mean=variance and is likely inappropriate.&quot;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Consider using Negative Binomial.&quot;</span><span class="p">)</span>
            
            <span class="n">mu</span> <span class="o">=</span> <span class="n">best_guess</span>
        
            <span class="c1"># --- 2. Calculate Probabilities ---</span>
            <span class="c1"># poisson.cdf(k, mu) calculates P(X &lt;= k)</span>
            
            <span class="n">c1</span> <span class="o">=</span> <span class="n">poisson</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">mu</span><span class="p">)</span>
            <span class="n">c2</span> <span class="o">=</span> <span class="n">poisson</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">mu</span><span class="p">)</span>
            
            <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c2</span> <span class="o">-</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">c2</span>

        <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">8</span><span class="p">:</span> <span class="c1"># Assuming 8 is for Negative Binomial</span>
            
            <span class="c1"># --- 1. Calculate Negative Binomial Parameters ---</span>
            <span class="c1"># This model is ONLY valid for overdispersion (Variance &gt; Mean).</span>
            <span class="c1"># We will use np.where to set parameters to NaN if V &lt;= M.</span>
            
            <span class="c1"># p = Mean / Variance</span>
            <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">error_variance</span> <span class="o">&gt;</span> <span class="n">best_guess</span><span class="p">,</span> 
                         <span class="n">best_guess</span> <span class="o">/</span> <span class="n">error_variance</span><span class="p">,</span> 
                         <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
            
            <span class="c1"># n = Mean^2 / (Variance - Mean)</span>
            <span class="n">n</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">error_variance</span> <span class="o">&gt;</span> <span class="n">best_guess</span><span class="p">,</span> 
                         <span class="p">(</span><span class="n">best_guess</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">error_variance</span> <span class="o">-</span> <span class="n">best_guess</span><span class="p">),</span> 
                         <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
            
            <span class="c1"># --- 2. Calculate Probabilities ---</span>
            <span class="c1"># The nbinom.cdf function will propagate NaNs, correctly</span>
            <span class="c1"># handling the cases where the model was invalid.</span>
            
            <span class="n">c1</span> <span class="o">=</span> <span class="n">nbinom</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">)</span>
            <span class="n">c2</span> <span class="o">=</span> <span class="n">nbinom</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">)</span>
            
            <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c2</span> <span class="o">-</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">c2</span>
            
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid distribution&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">out</span></div>


<div class="viewcode-block" id="WAS_RandomForest_XGBoost_ML_Stacking.calculate_tercile_probabilities_nonparametric">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_RandomForest_XGBoost_ML_Stacking.calculate_tercile_probabilities_nonparametric">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">calculate_tercile_probabilities_nonparametric</span><span class="p">(</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">error_samples</span><span class="p">,</span> <span class="n">first_tercile</span><span class="p">,</span> <span class="n">second_tercile</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Non-parametric method using historical error samples.&quot;&quot;&quot;</span>
        <span class="n">n_time</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">best_guess</span><span class="p">)</span>
        <span class="n">pred_prob</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="n">n_time</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_time</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">best_guess</span><span class="p">[</span><span class="n">t</span><span class="p">]):</span>
                <span class="k">continue</span>
            <span class="n">dist</span> <span class="o">=</span> <span class="n">best_guess</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">+</span> <span class="n">error_samples</span>
            <span class="n">dist</span> <span class="o">=</span> <span class="n">dist</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">dist</span><span class="p">)]</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">dist</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="n">p_below</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dist</span> <span class="o">&lt;</span> <span class="n">first_tercile</span><span class="p">)</span>
            <span class="n">p_between</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">dist</span> <span class="o">&gt;=</span> <span class="n">first_tercile</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">dist</span> <span class="o">&lt;</span> <span class="n">second_tercile</span><span class="p">))</span>
            <span class="n">p_above</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="p">(</span><span class="n">p_below</span> <span class="o">+</span> <span class="n">p_between</span><span class="p">)</span>
            <span class="n">pred_prob</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">p_below</span>
            <span class="n">pred_prob</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">p_between</span>
            <span class="n">pred_prob</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">p_above</span>
        <span class="k">return</span> <span class="n">pred_prob</span></div>




<div class="viewcode-block" id="WAS_RandomForest_XGBoost_ML_Stacking.compute_prob">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_RandomForest_XGBoost_ML_Stacking.compute_prob">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">compute_prob</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">Predictant</span><span class="p">:</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span><span class="p">,</span>
        <span class="n">clim_year_start</span><span class="p">,</span>
        <span class="n">clim_year_end</span><span class="p">,</span>
        <span class="n">hindcast_det</span><span class="p">:</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span><span class="p">,</span>
        <span class="n">best_code_da</span><span class="p">:</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">best_shape_da</span><span class="p">:</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">best_loc_da</span><span class="p">:</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">best_scale_da</span><span class="p">:</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute tercile probabilities for deterministic hindcasts.</span>

<span class="sd">        If dist_method == &#39;bestfit&#39;:</span>
<span class="sd">            - Use cluster-based best-fit distributions to:</span>
<span class="sd">                * derive terciles analytically from (best_code_da, best_shape_da, best_loc_da, best_scale_da),</span>
<span class="sd">                * compute predictive probabilities using the same family.</span>

<span class="sd">        Otherwise:</span>
<span class="sd">            - Use empirical terciles from Predictant climatology and the selected</span>
<span class="sd">              parametric / nonparametric method.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Predictant : xarray.DataArray</span>
<span class="sd">            Observed data (T, Y, X) or (T, Y, X, M).</span>
<span class="sd">        clim_year_start, clim_year_end : int or str</span>
<span class="sd">            Climatology period (inclusive) for thresholds.</span>
<span class="sd">        hindcast_det : xarray.DataArray</span>
<span class="sd">            Deterministic hindcast (T, Y, X).</span>
<span class="sd">        best_code_da, best_shape_da, best_loc_da, best_scale_da : xarray.DataArray, optional</span>
<span class="sd">            Output from WAS_TransformData.fit_best_distribution_grid, required for &#39;bestfit&#39;.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        hindcast_prob : xarray.DataArray</span>
<span class="sd">            Probabilities with dims (probability=[&#39;PB&#39;,&#39;PN&#39;,&#39;PA&#39;], T, Y, X).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Handle member dimension if present</span>
        <span class="k">if</span> <span class="s2">&quot;M&quot;</span> <span class="ow">in</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">dims</span><span class="p">:</span>
            <span class="n">Predictant</span> <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">M</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">drop_vars</span><span class="p">(</span><span class="s2">&quot;M&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>

        <span class="c1"># Ensure dimension order</span>
        <span class="n">Predictant</span> <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="s2">&quot;Y&quot;</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">)</span>

        <span class="c1"># Spatial mask</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="o">~</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">Predictant</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="mi">0</span><span class="p">)),</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>

        <span class="c1"># Climatology subset</span>
        <span class="n">clim</span> <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">sel</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="nb">slice</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">clim_year_start</span><span class="p">),</span> <span class="nb">str</span><span class="p">(</span><span class="n">clim_year_end</span><span class="p">)))</span>
        <span class="k">if</span> <span class="n">clim</span><span class="o">.</span><span class="n">sizes</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">3</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Not enough years in climatology period for terciles.&quot;</span><span class="p">)</span>

        <span class="c1"># Error variance for predictive distributions</span>
        <span class="n">error_variance</span> <span class="o">=</span> <span class="p">(</span><span class="n">Predictant</span> <span class="o">-</span> <span class="n">hindcast_det</span><span class="p">)</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="s2">&quot;T&quot;</span><span class="p">)</span>
        <span class="n">dof</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">clim</span><span class="o">.</span><span class="n">sizes</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">])</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

        <span class="c1"># Empirical terciles (used by non-bestfit methods)</span>
        <span class="n">terciles_emp</span> <span class="o">=</span> <span class="n">clim</span><span class="o">.</span><span class="n">quantile</span><span class="p">([</span><span class="mf">0.32</span><span class="p">,</span> <span class="mf">0.67</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="s2">&quot;T&quot;</span><span class="p">)</span>
        <span class="n">T1_emp</span> <span class="o">=</span> <span class="n">terciles_emp</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">quantile</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">drop_vars</span><span class="p">(</span><span class="s2">&quot;quantile&quot;</span><span class="p">)</span>
        <span class="n">T2_emp</span> <span class="o">=</span> <span class="n">terciles_emp</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">quantile</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">drop_vars</span><span class="p">(</span><span class="s2">&quot;quantile&quot;</span><span class="p">)</span>
        

        <span class="n">dm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dist_method</span>

        <span class="c1"># ---------- BESTFIT: zone-wise optimal distributions ----------</span>
        <span class="k">if</span> <span class="n">dm</span> <span class="o">==</span> <span class="s2">&quot;bestfit&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">v</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="p">(</span><span class="n">best_code_da</span><span class="p">,</span> <span class="n">best_shape_da</span><span class="p">,</span> <span class="n">best_loc_da</span><span class="p">,</span> <span class="n">best_scale_da</span><span class="p">)):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;dist_method=&#39;bestfit&#39; requires best_code_da, best_shape_da_da, best_loc_da, best_scale_da.&quot;</span>
                <span class="p">)</span>

            <span class="c1"># T1, T2 from best-fit distributions (per grid)</span>
            <span class="n">T1</span><span class="p">,</span> <span class="n">T2</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_ppf_terciles_from_code</span><span class="p">,</span>
                <span class="n">best_code_da</span><span class="p">,</span>
                <span class="n">best_shape_da</span><span class="p">,</span>
                <span class="n">best_loc_da</span><span class="p">,</span>
                <span class="n">best_scale_da</span><span class="p">,</span>
                <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[(),</span> <span class="p">(),</span> <span class="p">(),</span> <span class="p">()],</span>
                <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(),</span> <span class="p">()],</span>
                <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">dask</span><span class="o">=</span><span class="s2">&quot;parallelized&quot;</span><span class="p">,</span>
                <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span>
            <span class="p">)</span>

            <span class="c1"># Predictive probabilities using same family</span>
            <span class="n">hindcast_prob</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">calculate_tercile_probabilities_bestfit</span><span class="p">,</span>
                <span class="n">hindcast_det</span><span class="p">,</span>
                <span class="n">error_variance</span><span class="p">,</span>
                <span class="n">T1</span><span class="p">,</span>
                <span class="n">T2</span><span class="p">,</span>
                <span class="n">best_code_da</span><span class="p">,</span>
                <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;T&quot;</span><span class="p">,),</span> <span class="p">(),</span> <span class="p">(),</span> <span class="p">(),</span> <span class="p">()],</span>
                <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;probability&quot;</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">)],</span>
                <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;dof&#39;</span><span class="p">:</span> <span class="n">dof</span><span class="p">},</span>
                <span class="n">dask</span><span class="o">=</span><span class="s2">&quot;parallelized&quot;</span><span class="p">,</span>
                <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>
                <span class="n">dask_gufunc_kwargs</span><span class="o">=</span><span class="p">{</span>
                    <span class="s2">&quot;output_sizes&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;probability&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">},</span>
                    <span class="s2">&quot;allow_rechunk&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                <span class="p">},</span>
            <span class="p">)</span>

        <span class="c1"># ---------- Nonparametric ----------</span>
        <span class="k">elif</span> <span class="n">dm</span> <span class="o">==</span> <span class="s2">&quot;nonparam&quot;</span><span class="p">:</span>
            <span class="n">error_samples</span> <span class="o">=</span> <span class="n">Predictant</span> <span class="o">-</span> <span class="n">hindcast_det</span>
            <span class="n">hindcast_prob</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">calculate_tercile_probabilities_nonparametric</span><span class="p">,</span>
                <span class="n">hindcast_det</span><span class="p">,</span>
                <span class="n">error_samples</span><span class="p">,</span>
                <span class="n">T1_emp</span><span class="p">,</span>
                <span class="n">T2_emp</span><span class="p">,</span>
                <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;T&quot;</span><span class="p">,),</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,),</span> <span class="p">(),</span> <span class="p">()],</span>
                <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;probability&quot;</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">)],</span>
                <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">dask</span><span class="o">=</span><span class="s2">&quot;parallelized&quot;</span><span class="p">,</span>
                <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>
                <span class="n">dask_gufunc_kwargs</span><span class="o">=</span><span class="p">{</span>
                    <span class="s2">&quot;output_sizes&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;probability&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">},</span>
                    <span class="s2">&quot;allow_rechunk&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                <span class="p">},</span>
            <span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid dist_method: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">dist_method</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">hindcast_prob</span> <span class="o">=</span> <span class="n">hindcast_prob</span><span class="o">.</span><span class="n">assign_coords</span><span class="p">(</span>
            <span class="n">probability</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;probability&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;PB&quot;</span><span class="p">,</span> <span class="s2">&quot;PN&quot;</span><span class="p">,</span> <span class="s2">&quot;PA&quot;</span><span class="p">])</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">hindcast_prob</span> <span class="o">*</span> <span class="n">mask</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="s2">&quot;probability&quot;</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="s2">&quot;Y&quot;</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">)</span></div>


    <span class="c1"># ----------------------------------------------------------------------</span>
    <span class="c1"># 6) FORECAST METHOD</span>
    <span class="c1"># ----------------------------------------------------------------------</span>
<div class="viewcode-block" id="WAS_RandomForest_XGBoost_ML_Stacking.forecast">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_RandomForest_XGBoost_ML_Stacking.forecast">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">forecast</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> 
        <span class="n">Predictant</span><span class="p">,</span> 
        <span class="n">clim_year_start</span><span class="p">,</span> 
        <span class="n">clim_year_end</span><span class="p">,</span> 
        <span class="n">Predictor</span><span class="p">,</span> 
        <span class="n">hindcast_det</span><span class="p">,</span> 
        <span class="n">Predictor_for_year</span><span class="p">,</span> 
        <span class="n">best_param_da</span><span class="p">,</span> <span class="n">best_code_da</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">best_shape_da</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">best_loc_da</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">best_scale_da</span><span class="o">=</span><span class="kc">None</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generate a forecast for a single time (e.g., future year), then compute </span>
<span class="sd">        tercile probabilities from the chosen distribution method.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Predictant : xarray.DataArray</span>
<span class="sd">            Observed data with dims (T, Y, X), used for climatological terciles.</span>
<span class="sd">        clim_year_start : int</span>
<span class="sd">            Start year of the climatology.</span>
<span class="sd">        clim_year_end : int</span>
<span class="sd">            End year of the climatology.</span>
<span class="sd">        Predictor : xarray.DataArray</span>
<span class="sd">            Historical predictor data, dims (T, features).</span>
<span class="sd">        hindcast_det : xarray.DataArray</span>
<span class="sd">            Historical deterministic forecast, dims (output=[error,prediction], T, Y, X).</span>
<span class="sd">            Used to compute error variance or error samples.</span>
<span class="sd">        Predictor_for_year : xarray.DataArray</span>
<span class="sd">            Predictor data for the forecast year, shape (features,) or (1, features).</span>
<span class="sd">        best_param_da : xarray.DataArray</span>
<span class="sd">            Grid-based hyperparameters from compute_hyperparameters.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        result_ : xarray.DataArray</span>
<span class="sd">            dims (&#39;output&#39;,&#39;Y&#39;,&#39;X&#39;) =&gt; [error, prediction].</span>
<span class="sd">            For a forecast, the &#39;error&#39; will generally be NaN.</span>
<span class="sd">        hindcast_prob : xarray.DataArray</span>
<span class="sd">            dims (probability=3, Y, X) =&gt; tercile probabilities PB, PN, PA.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># We need a dummy y_test array, because fit_predict expects y_test</span>
        <span class="c1"># but we don&#39;t have actual future obs.</span>
        <span class="n">y_test_dummy</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">Predictant</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>  <span class="c1"># shape (Y, X)</span>

        <span class="c1"># Prepare chunk sizes for parallel</span>
        <span class="n">chunksize_x</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">Predictant</span><span class="o">.</span><span class="n">get_index</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">))</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span><span class="p">))</span>
        <span class="n">chunksize_y</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">Predictant</span><span class="o">.</span><span class="n">get_index</span><span class="p">(</span><span class="s2">&quot;Y&quot;</span><span class="p">))</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span><span class="p">))</span>

        <span class="c1"># Align times, typically we set Predictor[&#39;T&#39;] = Predictant[&#39;T&#39;]</span>
        <span class="n">Predictor</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">Predictant</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span>
        <span class="n">Predictant</span> <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="s1">&#39;T&#39;</span><span class="p">,</span> <span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">)</span>
        <span class="n">Predictant_st</span> <span class="o">=</span> <span class="n">standardize_timeseries</span><span class="p">(</span><span class="n">Predictant</span><span class="p">,</span> <span class="n">clim_year_start</span><span class="p">,</span> <span class="n">clim_year_end</span><span class="p">)</span>
        
        <span class="c1"># Squeeze the forecast predictor</span>
        <span class="n">Predictor_for_year_</span> <span class="o">=</span> <span class="n">Predictor_for_year</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>

        <span class="c1"># 1) Fit+predict with the stacked model in parallel, returning [error, pred]</span>
        <span class="n">client</span> <span class="o">=</span> <span class="n">Client</span><span class="p">(</span><span class="n">n_workers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span><span class="p">,</span> <span class="n">threads_per_worker</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">result_da</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">,</span>
            <span class="n">Predictor</span><span class="p">,</span>                          <span class="c1"># X_train</span>
            <span class="n">Predictant_st</span><span class="o">.</span><span class="n">chunk</span><span class="p">({</span><span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">chunksize_y</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">chunksize_x</span><span class="p">}),</span>  <span class="c1"># y_train</span>
            <span class="n">Predictor_for_year_</span><span class="p">,</span>               <span class="c1"># X_test</span>
            <span class="n">y_test_dummy</span><span class="o">.</span><span class="n">chunk</span><span class="p">({</span><span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">chunksize_y</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">chunksize_x</span><span class="p">}),</span> <span class="c1"># y_test (dummy)</span>
            <span class="n">best_param_da</span><span class="o">.</span><span class="n">chunk</span><span class="p">({</span><span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">chunksize_y</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">chunksize_x</span><span class="p">}),</span>
            <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[</span>
                <span class="p">(</span><span class="s1">&#39;T&#39;</span><span class="p">,</span><span class="s1">&#39;features&#39;</span><span class="p">),</span>  <span class="c1"># X_train</span>
                <span class="p">(</span><span class="s1">&#39;T&#39;</span><span class="p">,),</span>           <span class="c1"># y_train</span>
                <span class="p">(</span><span class="s1">&#39;features&#39;</span><span class="p">,),</span>    <span class="c1"># X_test</span>
                <span class="p">(),</span>               <span class="c1"># y_test</span>
                <span class="p">()</span>                <span class="c1"># best_params_str</span>
            <span class="p">],</span>
            <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">dask</span><span class="o">=</span><span class="s1">&#39;parallelized&#39;</span><span class="p">,</span>
            <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s1">&#39;output&#39;</span><span class="p">,)],</span>  <span class="c1"># We&#39;ll get shape (2,) =&gt; [err, pred]</span>
            <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>
            <span class="n">dask_gufunc_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;output_sizes&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;output&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">}},</span>
        <span class="p">)</span>
        <span class="n">result_</span> <span class="o">=</span> <span class="n">result_da</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
        <span class="n">client</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
        <span class="n">result_</span> <span class="o">=</span> <span class="n">result_</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">output</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="n">result_</span> <span class="o">=</span> <span class="n">reverse_standardize</span><span class="p">(</span><span class="n">result_</span><span class="p">,</span> <span class="n">Predictant</span><span class="p">,</span>
                                        <span class="n">clim_year_start</span><span class="p">,</span> <span class="n">clim_year_end</span><span class="p">)</span>
        <span class="c1"># result_ =&gt; dims (output=2, Y, X). </span>
        <span class="c1"># For a real future forecast, &quot;error&quot; is NaN, &quot;prediction&quot; is the forecast.</span>

        <span class="c1"># 2) Compute thresholds T1, T2 from climatology</span>
        <span class="n">index_start</span> <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">get_index</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">get_loc</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">clim_year_start</span><span class="p">))</span><span class="o">.</span><span class="n">start</span>
        <span class="n">index_end</span>   <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">get_index</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">get_loc</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">clim_year_end</span><span class="p">))</span><span class="o">.</span><span class="n">stop</span>
        <span class="n">rainfall_for_tercile</span> <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="nb">slice</span><span class="p">(</span><span class="n">index_start</span><span class="p">,</span> <span class="n">index_end</span><span class="p">))</span>
        <span class="n">terciles</span> <span class="o">=</span> <span class="n">rainfall_for_tercile</span><span class="o">.</span><span class="n">quantile</span><span class="p">([</span><span class="mf">0.32</span><span class="p">,</span> <span class="mf">0.67</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="s1">&#39;T&#39;</span><span class="p">)</span>
        <span class="n">T1_emp</span> <span class="o">=</span> <span class="n">terciles</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">quantile</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">drop_vars</span><span class="p">(</span><span class="s1">&#39;quantile&#39;</span><span class="p">)</span>
        <span class="n">T2_emp</span> <span class="o">=</span> <span class="n">terciles</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">quantile</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">drop_vars</span><span class="p">(</span><span class="s1">&#39;quantile&#39;</span><span class="p">)</span>
        <span class="n">error_variance</span> <span class="o">=</span> <span class="p">(</span><span class="n">Predictant</span> <span class="o">-</span> <span class="n">hindcast_det</span><span class="p">)</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="s1">&#39;T&#39;</span><span class="p">)</span>
        
        <span class="c1"># Expand single prediction to T=1 so probability methods can handle it</span>
        <span class="n">forecast_expanded</span> <span class="o">=</span> <span class="n">result_</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span>
            <span class="n">T</span><span class="o">=</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">Timestamp</span><span class="p">(</span><span class="n">Predictor_for_year</span><span class="o">.</span><span class="n">coords</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">to_pydatetime</span><span class="p">()]</span>
        <span class="p">)</span>
        <span class="n">year</span> <span class="o">=</span> <span class="n">Predictor_for_year</span><span class="o">.</span><span class="n">coords</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;datetime64[Y]&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1970</span>
        <span class="c1"># year = Predictor_for_year.coords[&#39;T&#39;].values.astype(&#39;datetime64[Y]&#39;).astype(int)[0] + 1970  </span>
        <span class="n">T_value_1</span> <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">coords</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>  <span class="c1"># Get the datetime64 value from da1</span>
        <span class="n">month_1</span> <span class="o">=</span> <span class="n">T_value_1</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;datetime64[M]&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span> <span class="o">%</span> <span class="mi">12</span> <span class="o">+</span> <span class="mi">1</span>  <span class="c1"># Extract month</span>
        <span class="n">new_T_value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">datetime64</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">year</span><span class="si">}</span><span class="s2">-</span><span class="si">{</span><span class="n">month_1</span><span class="si">:</span><span class="s2">02d</span><span class="si">}</span><span class="s2">-</span><span class="si">{</span><span class="mi">1</span><span class="si">:</span><span class="s2">02d</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        
        <span class="n">forecast_expanded</span> <span class="o">=</span> <span class="n">forecast_expanded</span><span class="o">.</span><span class="n">assign_coords</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span><span class="p">([</span><span class="n">new_T_value</span><span class="p">],</span> <span class="n">dims</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">]))</span>
        <span class="n">forecast_expanded</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">forecast_expanded</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;datetime64[ns]&#39;</span><span class="p">)</span>

        <span class="n">dof</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">rainfall_for_tercile</span><span class="o">.</span><span class="n">sizes</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">])</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

        <span class="n">dm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dist_method</span>

        <span class="c1"># ---------- BESTFIT ----------</span>
        <span class="k">if</span> <span class="n">dm</span> <span class="o">==</span> <span class="s2">&quot;bestfit&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">v</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="p">(</span><span class="n">best_code_da</span><span class="p">,</span> <span class="n">best_shape_da</span><span class="p">,</span> <span class="n">best_loc_da</span><span class="p">,</span> <span class="n">best_scale_da</span><span class="p">)):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;dist_method=&#39;bestfit&#39; requires best_code_da, best_shape_da, best_loc_da, best_scale_da.&quot;</span>
                <span class="p">)</span>
            
            <span class="n">T1</span><span class="p">,</span> <span class="n">T2</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_ppf_terciles_from_code</span><span class="p">,</span>
                <span class="n">best_code_da</span><span class="p">,</span>
                <span class="n">best_shape_da</span><span class="p">,</span>
                <span class="n">best_loc_da</span><span class="p">,</span>
                <span class="n">best_scale_da</span><span class="p">,</span>
                <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[(),</span> <span class="p">(),</span> <span class="p">(),</span> <span class="p">()],</span>
                <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(),</span> <span class="p">()],</span>
                <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">dask</span><span class="o">=</span><span class="s2">&quot;parallelized&quot;</span><span class="p">,</span>
                <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span>
            <span class="p">)</span>

            <span class="n">forecast_prob</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">calculate_tercile_probabilities_bestfit</span><span class="p">,</span>
                <span class="n">forecast_expanded</span><span class="p">,</span>
                <span class="n">error_variance</span><span class="p">,</span>
                <span class="n">T1</span><span class="p">,</span>
                <span class="n">T2</span><span class="p">,</span>
                <span class="n">best_code_da</span><span class="p">,</span>
                <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;T&quot;</span><span class="p">,),</span> <span class="p">(),</span> <span class="p">(),</span> <span class="p">(),</span> <span class="p">()],</span>
                <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;probability&quot;</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">)],</span>
                <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">dask</span><span class="o">=</span><span class="s2">&quot;parallelized&quot;</span><span class="p">,</span>
                <span class="n">kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;dof&quot;</span><span class="p">:</span> <span class="n">dof</span><span class="p">},</span>
                <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>
                <span class="n">dask_gufunc_kwargs</span><span class="o">=</span><span class="p">{</span>
                    <span class="s2">&quot;output_sizes&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;probability&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">},</span>
                    <span class="s2">&quot;allow_rechunk&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                <span class="p">},</span>
            <span class="p">)</span>

        <span class="c1"># ---------- Nonparametric ----------</span>
        <span class="k">elif</span> <span class="n">dm</span> <span class="o">==</span> <span class="s2">&quot;nonparam&quot;</span><span class="p">:</span>
            <span class="n">error_samples</span> <span class="o">=</span> <span class="n">Predictant</span> <span class="o">-</span> <span class="n">hindcast_det</span>
            <span class="n">forecast_prob</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">calculate_tercile_probabilities_nonparametric</span><span class="p">,</span>
                <span class="n">forecast_expanded</span><span class="p">,</span>
                <span class="n">error_samples</span><span class="p">,</span>
                <span class="n">T1_emp</span><span class="p">,</span>
                <span class="n">T2_emp</span><span class="p">,</span>
                <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;T&quot;</span><span class="p">,),</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,),</span> <span class="p">(),</span> <span class="p">()],</span>
                <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;probability&quot;</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">)],</span>
                <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">dask</span><span class="o">=</span><span class="s2">&quot;parallelized&quot;</span><span class="p">,</span>
                <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>
                <span class="n">dask_gufunc_kwargs</span><span class="o">=</span><span class="p">{</span>
                    <span class="s2">&quot;output_sizes&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;probability&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">},</span>
                    <span class="s2">&quot;allow_rechunk&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                <span class="p">},</span>
            <span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid dist_method: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">dist_method</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">forecast_prob</span> <span class="o">=</span> <span class="n">forecast_prob</span><span class="o">.</span><span class="n">assign_coords</span><span class="p">(</span><span class="n">probability</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;probability&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;PB&#39;</span><span class="p">,</span> <span class="s1">&#39;PN&#39;</span><span class="p">,</span> <span class="s1">&#39;PA&#39;</span><span class="p">]))</span>
        <span class="k">return</span> <span class="n">forecast_expanded</span><span class="p">,</span> <span class="n">forecast_prob</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="s1">&#39;probability&#39;</span><span class="p">,</span> <span class="s1">&#39;T&#39;</span><span class="p">,</span> <span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">)</span></div>
</div>



<div class="viewcode-block" id="WAS_RandomForest_XGBoost_Stacking_MLP">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_RandomForest_XGBoost_Stacking_MLP">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">WAS_RandomForest_XGBoost_Stacking_MLP</span><span class="p">:</span>
<div class="viewcode-block" id="WAS_RandomForest_XGBoost_Stacking_MLP.__init__">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_RandomForest_XGBoost_Stacking_MLP.__init__">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">nb_cores</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">dist_method</span><span class="o">=</span><span class="s2">&quot;nonparam&quot;</span><span class="p">,</span>
        <span class="n">n_clusters</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
        <span class="n">param_grid</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">optimization_method</span><span class="o">=</span><span class="s2">&quot;grid&quot;</span><span class="p">,</span>  <span class="c1"># New parameter</span>
        <span class="n">n_trials</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>  <span class="c1"># New parameter</span>
        <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>  <span class="c1"># New parameter</span>
        <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>  <span class="c1"># New parameter</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span> <span class="o">=</span> <span class="n">nb_cores</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dist_method</span> <span class="o">=</span> <span class="n">dist_method</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span> <span class="o">=</span> <span class="n">n_clusters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimization_method</span> <span class="o">=</span> <span class="n">optimization_method</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_trials</span> <span class="o">=</span> <span class="n">n_trials</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cv</span> <span class="o">=</span> <span class="n">cv</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span>

        <span class="c1"># Define minimal param_grid if none is provided</span>
        <span class="k">if</span> <span class="n">param_grid</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s2">&quot;rf__n_estimators&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span>
                <span class="s2">&quot;xgb__max_depth&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span>
                <span class="s2">&quot;xgb__learning_rate&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span>
                <span class="s2">&quot;final_estimator__hidden_layer_sizes&quot;</span><span class="p">:</span> <span class="p">[(</span><span class="mi">50</span><span class="p">,),</span> <span class="p">(</span><span class="mi">30</span><span class="p">,</span><span class="mi">10</span><span class="p">)],</span>
                <span class="s2">&quot;final_estimator__activation&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="s2">&quot;tanh&quot;</span><span class="p">],</span>
                <span class="s2">&quot;final_estimator__alpha&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.0001</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">],</span>
                <span class="s2">&quot;final_estimator__learning_rate_init&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">]</span>
            <span class="p">}</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">param_grid</span> <span class="o">=</span> <span class="n">param_grid</span>
            
        <span class="c1"># Initialize optimizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">BaseOptimizer</span><span class="p">(</span>
            <span class="n">optimization_method</span><span class="o">=</span><span class="n">optimization_method</span><span class="p">,</span>
            <span class="n">n_trials</span><span class="o">=</span><span class="n">n_trials</span><span class="p">,</span>
            <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span>
            <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="WAS_RandomForest_XGBoost_Stacking_MLP.compute_hyperparameters">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_RandomForest_XGBoost_Stacking_MLP.compute_hyperparameters">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">compute_hyperparameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">predictand</span><span class="p">,</span> <span class="n">predictor</span><span class="p">,</span> <span class="n">clim_year_start</span><span class="p">,</span> <span class="n">clim_year_end</span><span class="p">):</span>
        <span class="n">predictor</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">predictand</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Optimized version with Bayesian optimization.&quot;&quot;&quot;</span>
        <span class="n">df</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">predictand</span><span class="o">.</span><span class="n">to_dataframe</span><span class="p">()</span>
                      <span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
                      <span class="o">.</span><span class="n">dropna</span><span class="p">()</span>
                      <span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">])</span>
        <span class="p">)</span>
        <span class="n">col_name</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
        <span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
        <span class="n">df</span><span class="p">[</span><span class="s2">&quot;cluster&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">df</span><span class="p">[[</span><span class="n">col_name</span><span class="p">]])</span>
    
        <span class="n">df_unique</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop_duplicates</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Y&quot;</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">])</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">df_unique</span><span class="o">.</span><span class="n">set_index</span><span class="p">([</span><span class="s2">&quot;Y&quot;</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">to_xarray</span><span class="p">()</span>
        
        <span class="n">cluster_da</span> <span class="o">=</span> <span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;cluster&quot;</span><span class="p">]</span> <span class="o">*</span>
                      <span class="n">xr</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="o">~</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">predictand</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="mi">0</span><span class="p">)),</span> <span class="mi">1</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
                     <span class="p">)</span><span class="o">.</span><span class="n">drop_vars</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">cluster_da</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">align</span><span class="p">(</span><span class="n">predictand</span><span class="p">,</span> <span class="n">cluster_da</span><span class="p">,</span> <span class="n">join</span><span class="o">=</span><span class="s2">&quot;outer&quot;</span><span class="p">)</span>
    
        <span class="c1"># Build stacking model</span>
        <span class="n">base_rf</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
        <span class="n">base_xgb</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">XGBRegressor</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
        
        <span class="c1"># Wrap MLP (meta) in a pipeline with scaling</span>
        <span class="n">meta_pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
            <span class="p">(</span><span class="s1">&#39;scaler&#39;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>  
            <span class="p">(</span><span class="s1">&#39;meta_mlp&#39;</span><span class="p">,</span> <span class="n">MLPRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">))</span>
        <span class="p">])</span>
        
        <span class="n">stacking</span> <span class="o">=</span> <span class="n">StackingRegressor</span><span class="p">(</span>
            <span class="n">estimators</span><span class="o">=</span><span class="p">[(</span><span class="s1">&#39;rf&#39;</span><span class="p">,</span> <span class="n">base_rf</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;xgb&#39;</span><span class="p">,</span> <span class="n">base_xgb</span><span class="p">)],</span>
            <span class="n">final_estimator</span><span class="o">=</span><span class="n">meta_pipeline</span><span class="p">,</span>  
            <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span>
        <span class="p">)</span>
        <span class="c1"># Scale ONLY y, and automatically inverse-transform predictions back to original y units</span>
        <span class="n">stacking_model</span> <span class="o">=</span> <span class="n">TransformedTargetRegressor</span><span class="p">(</span>
            <span class="n">regressor</span><span class="o">=</span><span class="n">stacking</span><span class="p">,</span>
            <span class="n">transformer</span><span class="o">=</span><span class="n">StandardScaler</span><span class="p">()</span>   
        <span class="p">)</span>    
        <span class="n">unique_clusters</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">cluster_da</span><span class="p">)</span>
        <span class="n">unique_clusters</span> <span class="o">=</span> <span class="n">unique_clusters</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">unique_clusters</span><span class="p">)]</span>
        <span class="n">best_params_for_cluster</span> <span class="o">=</span> <span class="p">{}</span>
    
        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">unique_clusters</span><span class="p">:</span>
            <span class="n">mask_c</span> <span class="o">=</span> <span class="p">(</span><span class="n">cluster_da</span> <span class="o">==</span> <span class="n">c</span><span class="p">)</span>
            <span class="n">y_cluster</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">predictand</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">mask_c</span><span class="p">)</span>
                          <span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Y&quot;</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">],</span> <span class="n">skipna</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                          <span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="s2">&quot;T&quot;</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_cluster</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">])</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">continue</span>
    
            <span class="n">predictor_cluster</span> <span class="o">=</span> <span class="n">predictor</span><span class="o">.</span><span class="n">sel</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="n">y_cluster</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">])</span>
            <span class="n">X_mat</span> <span class="o">=</span> <span class="n">predictor_cluster</span><span class="o">.</span><span class="n">values</span>
            <span class="n">y_vec</span> <span class="o">=</span> <span class="n">y_cluster</span><span class="o">.</span><span class="n">values</span>
    
            <span class="c1"># Use optimizer to find best parameters</span>
            <span class="n">best_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span>
                <span class="n">stacking_model</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">param_grid</span><span class="p">,</span>
                <span class="n">X_mat</span><span class="p">,</span>
                <span class="n">y_vec</span><span class="p">,</span>
                <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;neg_mean_squared_error&#39;</span>
            <span class="p">)</span>
            <span class="n">best_params_for_cluster</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">c</span><span class="p">)]</span> <span class="o">=</span> <span class="n">best_params</span>
    
        <span class="c1"># Broadcast best hyperparameters</span>
        <span class="n">best_param_da</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">cluster_da</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">object</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">c</span><span class="p">,</span> <span class="n">bp</span> <span class="ow">in</span> <span class="n">best_params_for_cluster</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">c_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">cluster_da</span> <span class="o">==</span> <span class="n">c</span><span class="p">)</span>
            <span class="n">best_param_da</span> <span class="o">=</span> <span class="n">best_param_da</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="o">~</span><span class="n">c_mask</span><span class="p">,</span> <span class="n">other</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">bp</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">best_param_da</span><span class="p">,</span> <span class="n">cluster_da</span></div>


    <span class="c1"># -----------------------------------------------------------------</span>
    <span class="c1"># 2) FIT + PREDICT FOR A SINGLE GRID CELL</span>
    <span class="c1"># -----------------------------------------------------------------</span>
<div class="viewcode-block" id="WAS_RandomForest_XGBoost_Stacking_MLP.fit_predict">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_RandomForest_XGBoost_Stacking_MLP.fit_predict">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">fit_predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">best_params_str</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        For a single grid cell, parse the local best_params dict, set them on the </span>
<span class="sd">        StackingRegressor (with RF + XGB base, MLP meta), train and predict.</span>
<span class="sd">        </span>
<span class="sd">        Returns [error, prediction].</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X_train : np.ndarray, shape (n_samples, n_features)</span>
<span class="sd">        y_train : np.ndarray, shape (n_samples,)</span>
<span class="sd">        X_test :  np.ndarray, shape (n_features,) or (1, n_features)</span>
<span class="sd">        y_test :  float or np.nan</span>
<span class="sd">        best_params_str : str</span>
<span class="sd">            Local best hyperparams as a stringified dict.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        np.ndarray of shape (2,)</span>
<span class="sd">            [error, prediction]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span> <span class="o">&amp;</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">X_train</span><span class="p">),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># If there&#39;s no valid best_params or no data, return NaNs</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">best_params_str</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">best_params_str</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">])</span>

        <span class="c1"># Parse the params</span>
        <span class="n">best_params</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="n">best_params_str</span><span class="p">)</span>  
        
        <span class="c1"># Build stacking model</span>
        <span class="n">base_rf</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
        <span class="n">base_xgb</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">XGBRegressor</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
        
        <span class="c1"># Wrap MLP (meta) in a pipeline with scaling</span>
        <span class="n">meta_pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
            <span class="p">(</span><span class="s1">&#39;scaler&#39;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>  
            <span class="p">(</span><span class="s1">&#39;meta_mlp&#39;</span><span class="p">,</span> <span class="n">MLPRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">))</span>
        <span class="p">])</span>
        
        <span class="n">stacking</span> <span class="o">=</span> <span class="n">StackingRegressor</span><span class="p">(</span>
            <span class="n">estimators</span><span class="o">=</span><span class="p">[(</span><span class="s1">&#39;rf&#39;</span><span class="p">,</span> <span class="n">base_rf</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;xgb&#39;</span><span class="p">,</span> <span class="n">base_xgb</span><span class="p">)],</span>
            <span class="n">final_estimator</span><span class="o">=</span><span class="n">meta_pipeline</span><span class="p">,</span>  
            <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span>
        <span class="p">)</span>
        <span class="c1"># Scale ONLY y, and automatically inverse-transform predictions back to original y units</span>
        <span class="n">stacking_model</span> <span class="o">=</span> <span class="n">TransformedTargetRegressor</span><span class="p">(</span>
            <span class="n">regressor</span><span class="o">=</span><span class="n">stacking</span><span class="p">,</span>
            <span class="n">transformer</span><span class="o">=</span><span class="n">StandardScaler</span><span class="p">()</span>   
        <span class="p">)</span> 
        <span class="c1"># Apply local best params</span>
        <span class="n">stacking_model</span><span class="o">.</span><span class="n">regressor</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="o">**</span><span class="n">best_params</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">mask</span><span class="p">):</span>
            <span class="n">X_c</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="n">mask</span><span class="p">,</span> <span class="p">:]</span>
            <span class="n">y_c</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>

            <span class="n">stacking_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_c</span><span class="p">,</span> <span class="n">y_c</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">X_test</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

            <span class="n">preds</span> <span class="o">=</span> <span class="n">stacking_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
            <span class="n">preds</span><span class="p">[</span><span class="n">preds</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># clip negatives if it&#39;s precipitation</span>
            <span class="n">err</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span> <span class="k">if</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">y_test</span><span class="p">))</span> <span class="k">else</span> <span class="p">(</span><span class="n">y_test</span> <span class="o">-</span> <span class="n">preds</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">err</span><span class="p">,</span> <span class="n">preds</span><span class="p">])</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">])</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span></div>


    <span class="c1"># -----------------------------------------------------------------</span>
    <span class="c1"># 3) PARALLELIZED COMPUTE_MODEL</span>
    <span class="c1"># -----------------------------------------------------------------</span>
<div class="viewcode-block" id="WAS_RandomForest_XGBoost_Stacking_MLP.compute_model">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_RandomForest_XGBoost_Stacking_MLP.compute_model">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">compute_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">best_param_da</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Parallel training + prediction across the entire spatial domain,</span>
<span class="sd">        referencing local best_params for each grid cell.</span>

<span class="sd">        Returns an xarray.DataArray with dim &#39;output&#39; = [error, prediction].</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># chunk sizes for parallel</span>
        <span class="n">chunksize_x</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="o">.</span><span class="n">get_index</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">))</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span><span class="p">))</span>
        <span class="n">chunksize_y</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="o">.</span><span class="n">get_index</span><span class="p">(</span><span class="s2">&quot;Y&quot;</span><span class="p">))</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span><span class="p">))</span>

        <span class="c1"># Align time</span>
        <span class="n">X_train</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span>
        <span class="n">y_train</span> <span class="o">=</span> <span class="n">y_train</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="s1">&#39;T&#39;</span><span class="p">,</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span><span class="s1">&#39;X&#39;</span><span class="p">)</span>

        <span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
        <span class="n">y_test</span> <span class="o">=</span> <span class="n">y_test</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span><span class="s1">&#39;X&#39;</span><span class="p">)</span>

        <span class="c1"># Parallel execution with Dask</span>
        <span class="n">client</span> <span class="o">=</span> <span class="n">Client</span><span class="p">(</span><span class="n">n_workers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span><span class="p">,</span> <span class="n">threads_per_worker</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">result_da</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">,</span>
            <span class="n">X_train</span><span class="p">,</span>
            <span class="n">y_train</span><span class="o">.</span><span class="n">chunk</span><span class="p">({</span><span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">chunksize_y</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">chunksize_x</span><span class="p">}),</span>
            <span class="n">X_test</span><span class="p">,</span>
            <span class="n">y_test</span><span class="o">.</span><span class="n">chunk</span><span class="p">({</span><span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">chunksize_y</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">chunksize_x</span><span class="p">}),</span>
            <span class="n">best_param_da</span><span class="o">.</span><span class="n">chunk</span><span class="p">({</span><span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">chunksize_y</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">chunksize_x</span><span class="p">}),</span>
            <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[</span>
                <span class="p">(</span><span class="s1">&#39;T&#39;</span><span class="p">,</span><span class="s1">&#39;features&#39;</span><span class="p">),</span>
                <span class="p">(</span><span class="s1">&#39;T&#39;</span><span class="p">,),</span>
                <span class="p">(</span><span class="s1">&#39;features&#39;</span><span class="p">,),</span>
                <span class="p">(),</span>
                <span class="p">()</span>
            <span class="p">],</span>
            <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">dask</span><span class="o">=</span><span class="s1">&#39;parallelized&#39;</span><span class="p">,</span>
            <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s1">&#39;output&#39;</span><span class="p">,)],</span>
            <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>
            <span class="n">dask_gufunc_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;output_sizes&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;output&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">}},</span>
        <span class="p">)</span>
        <span class="n">result_</span> <span class="o">=</span> <span class="n">result_da</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
        <span class="n">client</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">result_</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">output</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></div>


    <span class="c1"># ------------------ Probability Calculation Methods ------------------</span>

<div class="viewcode-block" id="WAS_RandomForest_XGBoost_Stacking_MLP._ppf_terciles_from_code">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_RandomForest_XGBoost_Stacking_MLP._ppf_terciles_from_code">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_ppf_terciles_from_code</span><span class="p">(</span><span class="n">dist_code</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return tercile thresholds (T1, T2) from best-fit distribution parameters.</span>
<span class="sd">    </span>
<span class="sd">        dist_code:</span>
<span class="sd">            1: norm</span>
<span class="sd">            2: lognorm</span>
<span class="sd">            3: expon</span>
<span class="sd">            4: gamma</span>
<span class="sd">            5: weibull_min</span>
<span class="sd">            6: t</span>
<span class="sd">            7: poisson</span>
<span class="sd">            8: nbinom</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">dist_code</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
    
        <span class="n">code</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">dist_code</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                    <span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">lognorm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                    <span class="n">lognorm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">expon</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                    <span class="n">expon</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">gamma</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                    <span class="n">gamma</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">5</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">weibull_min</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                    <span class="n">weibull_min</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">6</span><span class="p">:</span>
                <span class="c1"># Note: Renamed &#39;t_dist&#39; to &#39;t&#39; for standard scipy.stats</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">t</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                    <span class="n">t</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">7</span><span class="p">:</span>
                <span class="c1"># Poisson: poisson.ppf(q, mu, loc=0)</span>
                <span class="c1"># ASSUMPTION: &#39;mu&#39; (mean) is passed as &#39;shape&#39;</span>
                <span class="c1">#             &#39;loc&#39; is passed as &#39;loc&#39;</span>
                <span class="c1">#             &#39;scale&#39; is unused</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">poisson</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">),</span>
                    <span class="n">poisson</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">8</span><span class="p">:</span>
                <span class="c1"># Negative Binomial: nbinom.ppf(q, n, p, loc=0)</span>
                <span class="c1"># ASSUMPTION: &#39;n&#39; (successes) is passed as &#39;shape&#39;</span>
                <span class="c1">#             &#39;p&#39; (probability) is passed as &#39;scale&#39;</span>
                <span class="c1">#             &#39;loc&#39; is passed as &#39;loc&#39;</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">nbinom</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">scale</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">),</span>
                    <span class="n">nbinom</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">scale</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">),</span>
                <span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
    
        <span class="c1"># Fallback if code is not 1-8</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span></div>

        
<div class="viewcode-block" id="WAS_RandomForest_XGBoost_Stacking_MLP.weibull_shape_solver">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_RandomForest_XGBoost_Stacking_MLP.weibull_shape_solver">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">weibull_shape_solver</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">V</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Function to find the root of the Weibull shape parameter &#39;k&#39;.</span>
<span class="sd">        We find &#39;k&#39; such that the theoretical variance/mean^2 ratio</span>
<span class="sd">        matches the observed V/M^2 ratio.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Guard against invalid &#39;k&#39; values during solving</span>
        <span class="k">if</span> <span class="n">k</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">g1</span> <span class="o">=</span> <span class="n">gamma_function</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="mi">1</span><span class="o">/</span><span class="n">k</span><span class="p">)</span>
            <span class="n">g2</span> <span class="o">=</span> <span class="n">gamma_function</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="mi">2</span><span class="o">/</span><span class="n">k</span><span class="p">)</span>
            
            <span class="c1"># This is the V/M^2 ratio *implied by k*</span>
            <span class="n">implied_v_over_m_sq</span> <span class="o">=</span> <span class="p">(</span><span class="n">g2</span> <span class="o">/</span> <span class="p">(</span><span class="n">g1</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span> <span class="o">-</span> <span class="mi">1</span>
            
            <span class="c1"># This is the *observed* ratio</span>
            <span class="n">observed_v_over_m_sq</span> <span class="o">=</span> <span class="n">V</span> <span class="o">/</span> <span class="p">(</span><span class="n">M</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
            
            <span class="c1"># Return the difference (we want this to be 0)</span>
            <span class="k">return</span> <span class="n">observed_v_over_m_sq</span> <span class="o">-</span> <span class="n">implied_v_over_m_sq</span>
        <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
            <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span> <span class="c1"># Handle math errors</span></div>


<div class="viewcode-block" id="WAS_RandomForest_XGBoost_Stacking_MLP.calculate_tercile_probabilities_bestfit">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_RandomForest_XGBoost_Stacking_MLP.calculate_tercile_probabilities_bestfit">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">calculate_tercile_probabilities_bestfit</span><span class="p">(</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">error_variance</span><span class="p">,</span> <span class="n">T1</span><span class="p">,</span> <span class="n">T2</span><span class="p">,</span> <span class="n">dist_code</span><span class="p">,</span> <span class="n">dof</span> 
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generic tercile probabilities using best-fit family per grid cell.</span>

<span class="sd">        Inputs (per grid cell):</span>
<span class="sd">        - best_guess : 1D array over T (hindcast_det or forecast_det)</span>
<span class="sd">        - T1, T2     : scalar terciles from climatological best-fit distribution</span>
<span class="sd">        - dist_code  : int, as in _ppf_terciles_from_code</span>
<span class="sd">        - shape, loc, scale : scalars from climatology fit</span>

<span class="sd">        Strategy:</span>
<span class="sd">        - For each time step, build a predictive distribution of the same family:</span>
<span class="sd">            * Use best_guess[t] to adjust mean / location;</span>
<span class="sd">            * Keep shape parameters from climatology.</span>
<span class="sd">        - Then compute probabilities:</span>
<span class="sd">            P(B) = F(T1), P(N) = F(T2) - F(T1), P(A) = 1 - F(T2).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        
        <span class="n">best_guess</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">best_guess</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span>
        <span class="n">error_variance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">error_variance</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
        <span class="c1"># T1 = np.asarray(T1, dtype=float)</span>
        <span class="c1"># T2 = np.asarray(T2, dtype=float)</span>
        <span class="n">n_time</span> <span class="o">=</span> <span class="n">best_guess</span><span class="o">.</span><span class="n">size</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="n">n_time</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">best_guess</span><span class="p">))</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">dist_code</span><span class="p">)</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">T1</span><span class="p">)</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">T2</span><span class="p">)</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">error_variance</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">out</span>

        <span class="n">code</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">dist_code</span><span class="p">)</span>

        <span class="c1"># Normal: loc = forecast; scale from clim</span>
        <span class="k">if</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">error_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">error_variance</span><span class="p">)</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">error_std</span><span class="p">)</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">error_std</span><span class="p">)</span> <span class="o">-</span> <span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">error_std</span><span class="p">)</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">error_std</span><span class="p">)</span>

        <span class="c1"># Lognormal: shape = sigma from clim; enforce mean = best_guess</span>
        <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">sigma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">error_variance</span> <span class="o">/</span> <span class="p">(</span><span class="n">best_guess</span><span class="o">**</span><span class="mi">2</span><span class="p">)))</span>
            <span class="n">mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">best_guess</span><span class="p">)</span> <span class="o">-</span> <span class="n">sigma</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="mi">2</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">lognorm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">mu</span><span class="p">))</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">lognorm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">mu</span><span class="p">))</span> <span class="o">-</span> <span class="n">lognorm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">mu</span><span class="p">))</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">lognorm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">mu</span><span class="p">))</span>      


        <span class="c1"># Exponential: keep scale from clim; shift loc so mean = best_guess</span>
        <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
            <span class="n">c1</span> <span class="o">=</span> <span class="n">expon</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">error_variance</span><span class="p">))</span>
            <span class="n">c2</span> <span class="o">=</span> <span class="n">expon</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc_t</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">error_variance</span><span class="p">))</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c2</span> <span class="o">-</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">c2</span>

        <span class="c1"># Gamma: use shape from clim; set scale so mean = best_guess</span>
        <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
            <span class="n">alpha</span> <span class="o">=</span> <span class="p">(</span><span class="n">best_guess</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="n">error_variance</span>
            <span class="n">theta</span> <span class="o">=</span> <span class="n">error_variance</span> <span class="o">/</span> <span class="n">best_guess</span>
            <span class="n">c1</span> <span class="o">=</span> <span class="n">gamma</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">theta</span><span class="p">)</span>
            <span class="n">c2</span> <span class="o">=</span> <span class="n">gamma</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">theta</span><span class="p">)</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c2</span> <span class="o">-</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">c2</span>

        <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">5</span><span class="p">:</span> <span class="c1"># Assuming 5 is for Weibull   </span>
        
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_time</span><span class="p">):</span>
                <span class="c1"># Get the scalar values for this specific element (e.g., grid cell)</span>
                <span class="n">M</span> <span class="o">=</span> <span class="n">best_guess</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">M</span><span class="p">)</span>
                <span class="n">V</span> <span class="o">=</span> <span class="n">error_variance</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">V</span><span class="p">)</span>
                
                <span class="c1"># Handle cases with no variance to avoid division by zero</span>
                <span class="k">if</span> <span class="n">V</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">M</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                    <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                    <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                    <span class="k">continue</span> <span class="c1"># Skip to the next element</span>
        
                <span class="c1"># --- 1. Numerically solve for shape &#39;k&#39; ---</span>
                <span class="c1"># We need a reasonable starting guess. 2.0 is common (Rayleigh dist.)</span>
                <span class="n">initial_guess</span> <span class="o">=</span> <span class="mf">2.0</span>
                
                <span class="c1"># fsolve finds the root of our helper function</span>
                <span class="n">k</span> <span class="o">=</span> <span class="n">fsolve</span><span class="p">(</span><span class="n">weibull_shape_solver</span><span class="p">,</span> <span class="n">initial_guess</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">V</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>
        
                <span class="c1"># --- 2. Check for bad solution and calculate scale &#39;lambda&#39; ---</span>
                <span class="k">if</span> <span class="n">k</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="c1"># Solver failed</span>
                    <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                    <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                    <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                    <span class="k">continue</span>
                
                <span class="c1"># With &#39;k&#39; found, we can now algebraically find scale &#39;lambda&#39;</span>
                <span class="c1"># In scipy.stats, scale is &#39;scale&#39;</span>
                <span class="n">lambda_scale</span> <span class="o">=</span> <span class="n">M</span> <span class="o">/</span> <span class="n">gamma_function</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="mi">1</span><span class="o">/</span><span class="n">k</span><span class="p">)</span>
        
                <span class="c1"># --- 3. Calculate Probabilities ---</span>
                <span class="c1"># In scipy.stats, shape &#39;k&#39; is &#39;c&#39;</span>
                <span class="c1"># Use the T1 and T2 values for this specific element</span>
                
                <span class="n">c1</span> <span class="o">=</span> <span class="n">weibull_min</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">lambda_scale</span><span class="p">)</span>
                <span class="n">c2</span> <span class="o">=</span> <span class="n">weibull_min</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">lambda_scale</span><span class="p">)</span>
        
                <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">c1</span>
                <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">c2</span> <span class="o">-</span> <span class="n">c1</span>
                <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">c2</span>

        <span class="c1"># Student-t: df from clim; scale from clim; loc = best_guess</span>
        <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">6</span><span class="p">:</span>       
            <span class="c1"># Check if df is valid for variance calculation</span>
            <span class="k">if</span> <span class="n">dof</span> <span class="o">&lt;=</span> <span class="mi">2</span><span class="p">:</span>
                <span class="c1"># Cannot calculate scale, fill with NaNs</span>
                <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># 1. Calculate t-distribution parameters</span>
                <span class="c1"># &#39;loc&#39; (mean) is just the best_guess</span>
                <span class="n">loc</span> <span class="o">=</span> <span class="n">best_guess</span>
                <span class="c1"># &#39;scale&#39; is calculated from the variance and df</span>
                <span class="c1"># Variance = scale**2 * (df / (df - 2))</span>
                <span class="n">scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">error_variance</span> <span class="o">*</span> <span class="p">(</span><span class="n">dof</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="n">dof</span><span class="p">)</span>
                
                <span class="c1"># 2. Calculate probabilities</span>
                <span class="n">c1</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">dof</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">)</span>
                <span class="n">c2</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">dof</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">)</span>

                <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c1</span>
                <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c2</span> <span class="o">-</span> <span class="n">c1</span>
                <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">c2</span>

        <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">7</span><span class="p">:</span> <span class="c1"># Assuming 7 is for Poisson</span>
            
            <span class="c1"># --- 1. Set the Poisson parameter &#39;mu&#39; ---</span>
            <span class="c1"># The &#39;mu&#39; parameter is the mean.</span>
            
            <span class="c1"># A warning is strongly recommended if error_variance is different from best_guess</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">error_variance</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Warning: &#39;error_variance&#39; is not equal to &#39;best_guess&#39;.&quot;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Poisson model assumes mean=variance and is likely inappropriate.&quot;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Consider using Negative Binomial.&quot;</span><span class="p">)</span>
            
            <span class="n">mu</span> <span class="o">=</span> <span class="n">best_guess</span>
        
            <span class="c1"># --- 2. Calculate Probabilities ---</span>
            <span class="c1"># poisson.cdf(k, mu) calculates P(X &lt;= k)</span>
            
            <span class="n">c1</span> <span class="o">=</span> <span class="n">poisson</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">mu</span><span class="p">)</span>
            <span class="n">c2</span> <span class="o">=</span> <span class="n">poisson</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">mu</span><span class="p">)</span>
            
            <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c2</span> <span class="o">-</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">c2</span>

        <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">8</span><span class="p">:</span> <span class="c1"># Assuming 8 is for Negative Binomial</span>
            
            <span class="c1"># --- 1. Calculate Negative Binomial Parameters ---</span>
            <span class="c1"># This model is ONLY valid for overdispersion (Variance &gt; Mean).</span>
            <span class="c1"># We will use np.where to set parameters to NaN if V &lt;= M.</span>
            
            <span class="c1"># p = Mean / Variance</span>
            <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">error_variance</span> <span class="o">&gt;</span> <span class="n">best_guess</span><span class="p">,</span> 
                         <span class="n">best_guess</span> <span class="o">/</span> <span class="n">error_variance</span><span class="p">,</span> 
                         <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
            
            <span class="c1"># n = Mean^2 / (Variance - Mean)</span>
            <span class="n">n</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">error_variance</span> <span class="o">&gt;</span> <span class="n">best_guess</span><span class="p">,</span> 
                         <span class="p">(</span><span class="n">best_guess</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">error_variance</span> <span class="o">-</span> <span class="n">best_guess</span><span class="p">),</span> 
                         <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
            
            <span class="c1"># --- 2. Calculate Probabilities ---</span>
            <span class="c1"># The nbinom.cdf function will propagate NaNs, correctly</span>
            <span class="c1"># handling the cases where the model was invalid.</span>
            
            <span class="n">c1</span> <span class="o">=</span> <span class="n">nbinom</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">)</span>
            <span class="n">c2</span> <span class="o">=</span> <span class="n">nbinom</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">)</span>
            
            <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c2</span> <span class="o">-</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">c2</span>
            
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid distribution&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">out</span></div>


<div class="viewcode-block" id="WAS_RandomForest_XGBoost_Stacking_MLP.calculate_tercile_probabilities_nonparametric">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_RandomForest_XGBoost_Stacking_MLP.calculate_tercile_probabilities_nonparametric">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">calculate_tercile_probabilities_nonparametric</span><span class="p">(</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">error_samples</span><span class="p">,</span> <span class="n">first_tercile</span><span class="p">,</span> <span class="n">second_tercile</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Non-parametric method using historical error samples.&quot;&quot;&quot;</span>
        <span class="n">n_time</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">best_guess</span><span class="p">)</span>
        <span class="n">pred_prob</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="n">n_time</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_time</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">best_guess</span><span class="p">[</span><span class="n">t</span><span class="p">]):</span>
                <span class="k">continue</span>
            <span class="n">dist</span> <span class="o">=</span> <span class="n">best_guess</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">+</span> <span class="n">error_samples</span>
            <span class="n">dist</span> <span class="o">=</span> <span class="n">dist</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">dist</span><span class="p">)]</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">dist</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="n">p_below</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dist</span> <span class="o">&lt;</span> <span class="n">first_tercile</span><span class="p">)</span>
            <span class="n">p_between</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">dist</span> <span class="o">&gt;=</span> <span class="n">first_tercile</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">dist</span> <span class="o">&lt;</span> <span class="n">second_tercile</span><span class="p">))</span>
            <span class="n">p_above</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="p">(</span><span class="n">p_below</span> <span class="o">+</span> <span class="n">p_between</span><span class="p">)</span>
            <span class="n">pred_prob</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">p_below</span>
            <span class="n">pred_prob</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">p_between</span>
            <span class="n">pred_prob</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">p_above</span>
        <span class="k">return</span> <span class="n">pred_prob</span></div>




<div class="viewcode-block" id="WAS_RandomForest_XGBoost_Stacking_MLP.compute_prob">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_RandomForest_XGBoost_Stacking_MLP.compute_prob">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">compute_prob</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">Predictant</span><span class="p">:</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span><span class="p">,</span>
        <span class="n">clim_year_start</span><span class="p">,</span>
        <span class="n">clim_year_end</span><span class="p">,</span>
        <span class="n">hindcast_det</span><span class="p">:</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span><span class="p">,</span>
        <span class="n">best_code_da</span><span class="p">:</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">best_shape_da</span><span class="p">:</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">best_loc_da</span><span class="p">:</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">best_scale_da</span><span class="p">:</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute tercile probabilities for deterministic hindcasts.</span>

<span class="sd">        If dist_method == &#39;bestfit&#39;:</span>
<span class="sd">            - Use cluster-based best-fit distributions to:</span>
<span class="sd">                * derive terciles analytically from (best_code_da, best_shape_da, best_loc_da, best_scale_da),</span>
<span class="sd">                * compute predictive probabilities using the same family.</span>

<span class="sd">        Otherwise:</span>
<span class="sd">            - Use empirical terciles from Predictant climatology and the selected</span>
<span class="sd">              parametric / nonparametric method.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Predictant : xarray.DataArray</span>
<span class="sd">            Observed data (T, Y, X) or (T, Y, X, M).</span>
<span class="sd">        clim_year_start, clim_year_end : int or str</span>
<span class="sd">            Climatology period (inclusive) for thresholds.</span>
<span class="sd">        hindcast_det : xarray.DataArray</span>
<span class="sd">            Deterministic hindcast (T, Y, X).</span>
<span class="sd">        best_code_da, best_shape_da, best_loc_da, best_scale_da : xarray.DataArray, optional</span>
<span class="sd">            Output from WAS_TransformData.fit_best_distribution_grid, required for &#39;bestfit&#39;.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        hindcast_prob : xarray.DataArray</span>
<span class="sd">            Probabilities with dims (probability=[&#39;PB&#39;,&#39;PN&#39;,&#39;PA&#39;], T, Y, X).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Handle member dimension if present</span>
        <span class="k">if</span> <span class="s2">&quot;M&quot;</span> <span class="ow">in</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">dims</span><span class="p">:</span>
            <span class="n">Predictant</span> <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">M</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">drop_vars</span><span class="p">(</span><span class="s2">&quot;M&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>

        <span class="c1"># Ensure dimension order</span>
        <span class="n">Predictant</span> <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="s2">&quot;Y&quot;</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">)</span>

        <span class="c1"># Spatial mask</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="o">~</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">Predictant</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="mi">0</span><span class="p">)),</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>

        <span class="c1"># Climatology subset</span>
        <span class="n">clim</span> <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">sel</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="nb">slice</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">clim_year_start</span><span class="p">),</span> <span class="nb">str</span><span class="p">(</span><span class="n">clim_year_end</span><span class="p">)))</span>
        <span class="k">if</span> <span class="n">clim</span><span class="o">.</span><span class="n">sizes</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">3</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Not enough years in climatology period for terciles.&quot;</span><span class="p">)</span>

        <span class="c1"># Error variance for predictive distributions</span>
        <span class="n">error_variance</span> <span class="o">=</span> <span class="p">(</span><span class="n">Predictant</span> <span class="o">-</span> <span class="n">hindcast_det</span><span class="p">)</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="s2">&quot;T&quot;</span><span class="p">)</span>
        <span class="n">dof</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">clim</span><span class="o">.</span><span class="n">sizes</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">])</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

        <span class="c1"># Empirical terciles (used by non-bestfit methods)</span>
        <span class="n">terciles_emp</span> <span class="o">=</span> <span class="n">clim</span><span class="o">.</span><span class="n">quantile</span><span class="p">([</span><span class="mf">0.32</span><span class="p">,</span> <span class="mf">0.67</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="s2">&quot;T&quot;</span><span class="p">)</span>
        <span class="n">T1_emp</span> <span class="o">=</span> <span class="n">terciles_emp</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">quantile</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">drop_vars</span><span class="p">(</span><span class="s2">&quot;quantile&quot;</span><span class="p">)</span>
        <span class="n">T2_emp</span> <span class="o">=</span> <span class="n">terciles_emp</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">quantile</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">drop_vars</span><span class="p">(</span><span class="s2">&quot;quantile&quot;</span><span class="p">)</span>
        

        <span class="n">dm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dist_method</span>

        <span class="c1"># ---------- BESTFIT: zone-wise optimal distributions ----------</span>
        <span class="k">if</span> <span class="n">dm</span> <span class="o">==</span> <span class="s2">&quot;bestfit&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">v</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="p">(</span><span class="n">best_code_da</span><span class="p">,</span> <span class="n">best_shape_da</span><span class="p">,</span> <span class="n">best_loc_da</span><span class="p">,</span> <span class="n">best_scale_da</span><span class="p">)):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;dist_method=&#39;bestfit&#39; requires best_code_da, best_shape_da_da, best_loc_da, best_scale_da.&quot;</span>
                <span class="p">)</span>

            <span class="c1"># T1, T2 from best-fit distributions (per grid)</span>
            <span class="n">T1</span><span class="p">,</span> <span class="n">T2</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_ppf_terciles_from_code</span><span class="p">,</span>
                <span class="n">best_code_da</span><span class="p">,</span>
                <span class="n">best_shape_da</span><span class="p">,</span>
                <span class="n">best_loc_da</span><span class="p">,</span>
                <span class="n">best_scale_da</span><span class="p">,</span>
                <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[(),</span> <span class="p">(),</span> <span class="p">(),</span> <span class="p">()],</span>
                <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(),</span> <span class="p">()],</span>
                <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">dask</span><span class="o">=</span><span class="s2">&quot;parallelized&quot;</span><span class="p">,</span>
                <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span>
            <span class="p">)</span>

            <span class="c1"># Predictive probabilities using same family</span>
            <span class="n">hindcast_prob</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">calculate_tercile_probabilities_bestfit</span><span class="p">,</span>
                <span class="n">hindcast_det</span><span class="p">,</span>
                <span class="n">error_variance</span><span class="p">,</span>
                <span class="n">T1</span><span class="p">,</span>
                <span class="n">T2</span><span class="p">,</span>
                <span class="n">best_code_da</span><span class="p">,</span>
                <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;T&quot;</span><span class="p">,),</span> <span class="p">(),</span> <span class="p">(),</span> <span class="p">(),</span> <span class="p">()],</span>
                <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;probability&quot;</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">)],</span>
                <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;dof&#39;</span><span class="p">:</span> <span class="n">dof</span><span class="p">},</span>
                <span class="n">dask</span><span class="o">=</span><span class="s2">&quot;parallelized&quot;</span><span class="p">,</span>
                <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>
                <span class="n">dask_gufunc_kwargs</span><span class="o">=</span><span class="p">{</span>
                    <span class="s2">&quot;output_sizes&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;probability&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">},</span>
                    <span class="s2">&quot;allow_rechunk&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                <span class="p">},</span>
            <span class="p">)</span>

        <span class="c1"># ---------- Nonparametric ----------</span>
        <span class="k">elif</span> <span class="n">dm</span> <span class="o">==</span> <span class="s2">&quot;nonparam&quot;</span><span class="p">:</span>
            <span class="n">error_samples</span> <span class="o">=</span> <span class="n">Predictant</span> <span class="o">-</span> <span class="n">hindcast_det</span>
            <span class="n">hindcast_prob</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">calculate_tercile_probabilities_nonparametric</span><span class="p">,</span>
                <span class="n">hindcast_det</span><span class="p">,</span>
                <span class="n">error_samples</span><span class="p">,</span>
                <span class="n">T1_emp</span><span class="p">,</span>
                <span class="n">T2_emp</span><span class="p">,</span>
                <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;T&quot;</span><span class="p">,),</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,),</span> <span class="p">(),</span> <span class="p">()],</span>
                <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;probability&quot;</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">)],</span>
                <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">dask</span><span class="o">=</span><span class="s2">&quot;parallelized&quot;</span><span class="p">,</span>
                <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>
                <span class="n">dask_gufunc_kwargs</span><span class="o">=</span><span class="p">{</span>
                    <span class="s2">&quot;output_sizes&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;probability&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">},</span>
                    <span class="s2">&quot;allow_rechunk&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                <span class="p">},</span>
            <span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid dist_method: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">dist_method</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">hindcast_prob</span> <span class="o">=</span> <span class="n">hindcast_prob</span><span class="o">.</span><span class="n">assign_coords</span><span class="p">(</span>
            <span class="n">probability</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;probability&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;PB&quot;</span><span class="p">,</span> <span class="s2">&quot;PN&quot;</span><span class="p">,</span> <span class="s2">&quot;PA&quot;</span><span class="p">])</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">hindcast_prob</span> <span class="o">*</span> <span class="n">mask</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="s2">&quot;probability&quot;</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="s2">&quot;Y&quot;</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">)</span></div>



    <span class="c1"># -----------------------------------------------------------------</span>
    <span class="c1"># 6) FORECAST METHOD</span>
    <span class="c1"># -----------------------------------------------------------------</span>
<div class="viewcode-block" id="WAS_RandomForest_XGBoost_Stacking_MLP.forecast">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_RandomForest_XGBoost_Stacking_MLP.forecast">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">forecast</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> 
        <span class="n">Predictant</span><span class="p">,</span> 
        <span class="n">clim_year_start</span><span class="p">,</span> 
        <span class="n">clim_year_end</span><span class="p">,</span> 
        <span class="n">Predictor</span><span class="p">,</span> 
        <span class="n">hindcast_det</span><span class="p">,</span> 
        <span class="n">Predictor_for_year</span><span class="p">,</span> 
        <span class="n">best_param_da</span><span class="p">,</span> <span class="n">best_code_da</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">best_shape_da</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">best_loc_da</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">best_scale_da</span><span class="o">=</span><span class="kc">None</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generate a forecast for a single future time (e.g., future year),</span>
<span class="sd">        then compute tercile probabilities from the chosen distribution method.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Predictant : xarray.DataArray</span>
<span class="sd">            Observed data with dims (T, Y, X) used for computing climatological terciles.</span>
<span class="sd">        clim_year_start : int</span>
<span class="sd">            Start year of the climatology period.</span>
<span class="sd">        clim_year_end : int</span>
<span class="sd">            End year of the climatology period.</span>
<span class="sd">        Predictor : xarray.DataArray</span>
<span class="sd">            Historical predictor data, shape (T, features).</span>
<span class="sd">        hindcast_det : xarray.DataArray</span>
<span class="sd">            Historical deterministic forecast with dims (output=[error,prediction], T, Y, X).</span>
<span class="sd">            Used to estimate error variance or error samples.</span>
<span class="sd">        Predictor_for_year : xarray.DataArray</span>
<span class="sd">            Predictor data for the forecast year, shape (features,) or (1, features).</span>
<span class="sd">        best_param_da : xarray.DataArray</span>
<span class="sd">            Grid-based best hyperparams from `compute_hyperparameters`.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        result_ : xarray.DataArray</span>
<span class="sd">            dims (&#39;output&#39;,&#39;Y&#39;,&#39;X&#39;) =&gt; [error, prediction].</span>
<span class="sd">            For a true forecast, the &#39;error&#39; is typically NaN.</span>
<span class="sd">        hindcast_prob : xarray.DataArray</span>
<span class="sd">            dims (probability=3, Y, X) =&gt; PB, PN, PA tercile probabilities.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># 1) Provide a dummy y_test =&gt; shape (Y, X), all NaN</span>
        <span class="n">y_test_dummy</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">Predictant</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>

        <span class="c1"># Prepare chunk sizes</span>
        <span class="n">chunksize_x</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">Predictant</span><span class="o">.</span><span class="n">get_index</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">))</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span><span class="p">))</span>
        <span class="n">chunksize_y</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">Predictant</span><span class="o">.</span><span class="n">get_index</span><span class="p">(</span><span class="s2">&quot;Y&quot;</span><span class="p">))</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span><span class="p">))</span>

        <span class="c1"># Align time</span>
        <span class="n">Predictor</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">Predictant</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span>
        <span class="n">Predictant</span> <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="s1">&#39;T&#39;</span><span class="p">,</span> <span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">)</span>
        <span class="n">Predictor_for_year_</span> <span class="o">=</span> <span class="n">Predictor_for_year</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
        <span class="c1"># Predictant_st = standardize_timeseries(Predictant, clim_year_start, clim_year_end)</span>
        
        <span class="c1"># 2) Fit+predict in parallel =&gt; produce shape (2, Y, X) =&gt; [error, prediction]</span>
        <span class="n">client</span> <span class="o">=</span> <span class="n">Client</span><span class="p">(</span><span class="n">n_workers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span><span class="p">,</span> <span class="n">threads_per_worker</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">result_da</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">,</span>
            <span class="n">Predictor</span><span class="p">,</span>
            <span class="n">Predictant</span><span class="o">.</span><span class="n">chunk</span><span class="p">({</span><span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">chunksize_y</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">chunksize_x</span><span class="p">}),</span>
            <span class="n">Predictor_for_year_</span><span class="p">,</span>
            <span class="n">y_test_dummy</span><span class="o">.</span><span class="n">chunk</span><span class="p">({</span><span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">chunksize_y</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">chunksize_x</span><span class="p">}),</span>
            <span class="n">best_param_da</span><span class="o">.</span><span class="n">chunk</span><span class="p">({</span><span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">chunksize_y</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">chunksize_x</span><span class="p">}),</span>
            <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[</span>
                <span class="p">(</span><span class="s1">&#39;T&#39;</span><span class="p">,</span><span class="s1">&#39;features&#39;</span><span class="p">),</span>  <span class="c1"># X_train</span>
                <span class="p">(</span><span class="s1">&#39;T&#39;</span><span class="p">,),</span>           <span class="c1"># y_train</span>
                <span class="p">(</span><span class="s1">&#39;features&#39;</span><span class="p">,),</span>    <span class="c1"># X_test</span>
                <span class="p">(),</span>               <span class="c1"># y_test (dummy)</span>
                <span class="p">()</span>                <span class="c1"># best_params_str</span>
            <span class="p">],</span>
            <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">dask</span><span class="o">=</span><span class="s1">&#39;parallelized&#39;</span><span class="p">,</span>
            <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s1">&#39;output&#39;</span><span class="p">,)],</span>
            <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>
            <span class="n">dask_gufunc_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;output_sizes&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;output&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">}},</span>
        <span class="p">)</span>
        <span class="n">result_</span> <span class="o">=</span> <span class="n">result_da</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
        <span class="n">client</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
        <span class="n">result_</span> <span class="o">=</span> <span class="n">result_</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">output</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># result_ = reverse_standardize(result_, Predictant, clim_year_start, clim_year_end)</span>
        <span class="c1"># result_ =&gt; dims (output=2, Y, X). </span>
        <span class="c1"># For a real future forecast, &quot;error&quot; is NaN, &quot;prediction&quot; is the forecast.</span>

        <span class="c1"># 2) Compute thresholds T1, T2 from climatology</span>
        <span class="n">index_start</span> <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">get_index</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">get_loc</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">clim_year_start</span><span class="p">))</span><span class="o">.</span><span class="n">start</span>
        <span class="n">index_end</span>   <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">get_index</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">get_loc</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">clim_year_end</span><span class="p">))</span><span class="o">.</span><span class="n">stop</span>
        <span class="n">rainfall_for_tercile</span> <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="nb">slice</span><span class="p">(</span><span class="n">index_start</span><span class="p">,</span> <span class="n">index_end</span><span class="p">))</span>
        <span class="n">terciles</span> <span class="o">=</span> <span class="n">rainfall_for_tercile</span><span class="o">.</span><span class="n">quantile</span><span class="p">([</span><span class="mf">0.32</span><span class="p">,</span> <span class="mf">0.67</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="s1">&#39;T&#39;</span><span class="p">)</span>
        <span class="n">T1_emp</span> <span class="o">=</span> <span class="n">terciles</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">quantile</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">drop_vars</span><span class="p">(</span><span class="s1">&#39;quantile&#39;</span><span class="p">)</span>
        <span class="n">T2_emp</span> <span class="o">=</span> <span class="n">terciles</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">quantile</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">drop_vars</span><span class="p">(</span><span class="s1">&#39;quantile&#39;</span><span class="p">)</span>
        <span class="n">error_variance</span> <span class="o">=</span> <span class="p">(</span><span class="n">Predictant</span> <span class="o">-</span> <span class="n">hindcast_det</span><span class="p">)</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="s1">&#39;T&#39;</span><span class="p">)</span>
        
        <span class="c1"># Expand single prediction to T=1 so probability methods can handle it</span>
        <span class="n">forecast_expanded</span> <span class="o">=</span> <span class="n">result_</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span>
            <span class="n">T</span><span class="o">=</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">Timestamp</span><span class="p">(</span><span class="n">Predictor_for_year</span><span class="o">.</span><span class="n">coords</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">to_pydatetime</span><span class="p">()]</span>
        <span class="p">)</span>
        <span class="n">year</span> <span class="o">=</span> <span class="n">Predictor_for_year</span><span class="o">.</span><span class="n">coords</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;datetime64[Y]&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1970</span>
        <span class="c1"># year = Predictor_for_year.coords[&#39;T&#39;].values.astype(&#39;datetime64[Y]&#39;).astype(int)[0] + 1970  </span>
        <span class="n">T_value_1</span> <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">coords</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>  <span class="c1"># Get the datetime64 value from da1</span>
        <span class="n">month_1</span> <span class="o">=</span> <span class="n">T_value_1</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;datetime64[M]&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span> <span class="o">%</span> <span class="mi">12</span> <span class="o">+</span> <span class="mi">1</span>  <span class="c1"># Extract month</span>
        <span class="n">new_T_value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">datetime64</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">year</span><span class="si">}</span><span class="s2">-</span><span class="si">{</span><span class="n">month_1</span><span class="si">:</span><span class="s2">02d</span><span class="si">}</span><span class="s2">-</span><span class="si">{</span><span class="mi">1</span><span class="si">:</span><span class="s2">02d</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        
        <span class="n">forecast_expanded</span> <span class="o">=</span> <span class="n">forecast_expanded</span><span class="o">.</span><span class="n">assign_coords</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span><span class="p">([</span><span class="n">new_T_value</span><span class="p">],</span> <span class="n">dims</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">]))</span>
        <span class="n">forecast_expanded</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">forecast_expanded</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;datetime64[ns]&#39;</span><span class="p">)</span>

        <span class="n">dof</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">rainfall_for_tercile</span><span class="o">.</span><span class="n">sizes</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">])</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

        <span class="n">dm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dist_method</span>

        <span class="c1"># ---------- BESTFIT ----------</span>
        <span class="k">if</span> <span class="n">dm</span> <span class="o">==</span> <span class="s2">&quot;bestfit&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">v</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="p">(</span><span class="n">best_code_da</span><span class="p">,</span> <span class="n">best_shape_da</span><span class="p">,</span> <span class="n">best_loc_da</span><span class="p">,</span> <span class="n">best_scale_da</span><span class="p">)):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;dist_method=&#39;bestfit&#39; requires best_code_da, best_shape_da, best_loc_da, best_scale_da.&quot;</span>
                <span class="p">)</span>
            
            <span class="n">T1</span><span class="p">,</span> <span class="n">T2</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_ppf_terciles_from_code</span><span class="p">,</span>
                <span class="n">best_code_da</span><span class="p">,</span>
                <span class="n">best_shape_da</span><span class="p">,</span>
                <span class="n">best_loc_da</span><span class="p">,</span>
                <span class="n">best_scale_da</span><span class="p">,</span>
                <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[(),</span> <span class="p">(),</span> <span class="p">(),</span> <span class="p">()],</span>
                <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(),</span> <span class="p">()],</span>
                <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">dask</span><span class="o">=</span><span class="s2">&quot;parallelized&quot;</span><span class="p">,</span>
                <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span>
            <span class="p">)</span>

            <span class="n">forecast_prob</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">calculate_tercile_probabilities_bestfit</span><span class="p">,</span>
                <span class="n">forecast_expanded</span><span class="p">,</span>
                <span class="n">error_variance</span><span class="p">,</span>
                <span class="n">T1</span><span class="p">,</span>
                <span class="n">T2</span><span class="p">,</span>
                <span class="n">best_code_da</span><span class="p">,</span>
                <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;T&quot;</span><span class="p">,),</span> <span class="p">(),</span> <span class="p">(),</span> <span class="p">(),</span> <span class="p">()],</span>
                <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;probability&quot;</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">)],</span>
                <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">dask</span><span class="o">=</span><span class="s2">&quot;parallelized&quot;</span><span class="p">,</span>
                <span class="n">kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;dof&quot;</span><span class="p">:</span> <span class="n">dof</span><span class="p">},</span>
                <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>
                <span class="n">dask_gufunc_kwargs</span><span class="o">=</span><span class="p">{</span>
                    <span class="s2">&quot;output_sizes&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;probability&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">},</span>
                    <span class="s2">&quot;allow_rechunk&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                <span class="p">},</span>
            <span class="p">)</span>

        <span class="c1"># ---------- Nonparametric ----------</span>
        <span class="k">elif</span> <span class="n">dm</span> <span class="o">==</span> <span class="s2">&quot;nonparam&quot;</span><span class="p">:</span>
            <span class="n">error_samples</span> <span class="o">=</span> <span class="n">Predictant</span> <span class="o">-</span> <span class="n">hindcast_det</span>
            <span class="n">forecast_prob</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">calculate_tercile_probabilities_nonparametric</span><span class="p">,</span>
                <span class="n">forecast_expanded</span><span class="p">,</span>
                <span class="n">error_samples</span><span class="p">,</span>
                <span class="n">T1_emp</span><span class="p">,</span>
                <span class="n">T2_emp</span><span class="p">,</span>
                <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;T&quot;</span><span class="p">,),</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,),</span> <span class="p">(),</span> <span class="p">()],</span>
                <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;probability&quot;</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">)],</span>
                <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">dask</span><span class="o">=</span><span class="s2">&quot;parallelized&quot;</span><span class="p">,</span>
                <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>
                <span class="n">dask_gufunc_kwargs</span><span class="o">=</span><span class="p">{</span>
                    <span class="s2">&quot;output_sizes&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;probability&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">},</span>
                    <span class="s2">&quot;allow_rechunk&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                <span class="p">},</span>
            <span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid dist_method: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">dist_method</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">forecast_prob</span> <span class="o">=</span> <span class="n">forecast_prob</span><span class="o">.</span><span class="n">assign_coords</span><span class="p">(</span><span class="n">probability</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;probability&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;PB&#39;</span><span class="p">,</span> <span class="s1">&#39;PN&#39;</span><span class="p">,</span> <span class="s1">&#39;PA&#39;</span><span class="p">]))</span>
        <span class="k">return</span> <span class="n">forecast_expanded</span><span class="p">,</span> <span class="n">forecast_prob</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="s1">&#39;probability&#39;</span><span class="p">,</span> <span class="s1">&#39;T&#39;</span><span class="p">,</span> <span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">)</span></div>
</div>




<div class="viewcode-block" id="WAS_Stacking_Ridge">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_Stacking_Ridge">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">WAS_Stacking_Ridge</span><span class="p">:</span>
<div class="viewcode-block" id="WAS_Stacking_Ridge.__init__">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_Stacking_Ridge.__init__">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">nb_cores</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">dist_method</span><span class="o">=</span><span class="s2">&quot;nonparam&quot;</span><span class="p">,</span>
        <span class="n">n_clusters</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
        <span class="n">param_grid</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">optimization_method</span><span class="o">=</span><span class="s2">&quot;grid&quot;</span><span class="p">,</span>  <span class="c1"># New parameter</span>
        <span class="n">n_trials</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>  <span class="c1"># New parameter</span>
        <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>  <span class="c1"># New parameter</span>
        <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>  <span class="c1"># New parameter</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span> <span class="o">=</span> <span class="n">nb_cores</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dist_method</span> <span class="o">=</span> <span class="n">dist_method</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span> <span class="o">=</span> <span class="n">n_clusters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimization_method</span> <span class="o">=</span> <span class="n">optimization_method</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_trials</span> <span class="o">=</span> <span class="n">n_trials</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cv</span> <span class="o">=</span> <span class="n">cv</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span>

        <span class="c1"># Minimal default grid if none is provided</span>
        <span class="k">if</span> <span class="n">param_grid</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s2">&quot;rf__n_estimators&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span>
                <span class="s2">&quot;xgb__max_depth&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span>
                <span class="s2">&quot;mlp_base__hidden_layer_sizes&quot;</span><span class="p">:</span> <span class="p">[(</span><span class="mi">20</span><span class="p">,),</span> <span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">10</span><span class="p">)],</span>
                <span class="s2">&quot;mlp_base__activation&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="s2">&quot;tanh&quot;</span><span class="p">],</span>
                <span class="s2">&quot;mlp_base__alpha&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.0001</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">],</span>
                <span class="s2">&quot;final_estimator__alpha&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">]</span>
            <span class="p">}</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">param_grid</span> <span class="o">=</span> <span class="n">param_grid</span>
            
        <span class="c1"># Initialize optimizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">BaseOptimizer</span><span class="p">(</span>
            <span class="n">optimization_method</span><span class="o">=</span><span class="n">optimization_method</span><span class="p">,</span>
            <span class="n">n_trials</span><span class="o">=</span><span class="n">n_trials</span><span class="p">,</span>
            <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span>
            <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="WAS_Stacking_Ridge.compute_hyperparameters">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_Stacking_Ridge.compute_hyperparameters">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">compute_hyperparameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">predictand</span><span class="p">,</span> <span class="n">predictor</span><span class="p">,</span> <span class="n">clim_year_start</span><span class="p">,</span> <span class="n">clim_year_end</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Optimized version with Bayesian optimization.&quot;&quot;&quot;</span>
        <span class="n">predictor</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">predictand</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span>
        <span class="n">df</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">predictand</span><span class="o">.</span><span class="n">to_dataframe</span><span class="p">()</span>
                      <span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
                      <span class="o">.</span><span class="n">dropna</span><span class="p">()</span>
                      <span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">])</span>
        <span class="p">)</span>
        <span class="n">col_name</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
        <span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
        <span class="n">df</span><span class="p">[</span><span class="s2">&quot;cluster&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">df</span><span class="p">[[</span><span class="n">col_name</span><span class="p">]])</span>
    
        <span class="n">df_unique</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop_duplicates</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Y&quot;</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">])</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">df_unique</span><span class="o">.</span><span class="n">set_index</span><span class="p">([</span><span class="s2">&quot;Y&quot;</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">to_xarray</span><span class="p">()</span>
    
        <span class="n">cluster_da</span> <span class="o">=</span> <span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;cluster&quot;</span><span class="p">]</span> <span class="o">*</span>
                      <span class="n">xr</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="o">~</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">predictand</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="mi">0</span><span class="p">)),</span> <span class="mi">1</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
                     <span class="p">)</span><span class="o">.</span><span class="n">drop_vars</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">cluster_da</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">align</span><span class="p">(</span><span class="n">predictand</span><span class="p">,</span> <span class="n">cluster_da</span><span class="p">,</span> <span class="n">join</span><span class="o">=</span><span class="s2">&quot;outer&quot;</span><span class="p">)</span>
    
        <span class="c1"># Build stacking model</span>
        <span class="n">rf_model</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
        <span class="n">xgb_model</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">XGBRegressor</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
        
        <span class="c1"># # # Wrap MLP (base) in a pipeline with scaling</span>
        <span class="c1"># # mlp_pipeline = Pipeline([</span>
        <span class="c1"># #     (&#39;scaler&#39;, StandardScaler()),  </span>
        <span class="c1"># #     (&#39;mlp_base&#39;, MLPRegressor(random_state=42, max_iter=1000))</span>
        <span class="c1"># # ])</span>
        <span class="c1"># mlp_pipeline = TransformedTargetRegressor(</span>
        <span class="c1">#     regressor=MLPRegressor(random_state=42, max_iter=1000),</span>
        <span class="c1">#     transformer=StandardScaler()</span>
        <span class="c1"># )  </span>
        <span class="c1"># meta_pipeline = Pipeline([</span>
        <span class="c1">#     (&#39;scaler&#39;, StandardScaler()),  </span>
        <span class="c1">#     (&#39;ridge_meta&#39;, Ridge(alpha=0.8))</span>
        <span class="c1"># ])</span>

        <span class="c1"># stacking_ridge = StackingRegressor(</span>
        <span class="c1">#     estimators=[(&quot;rf&quot;, rf_model), (&quot;xgb&quot;, xgb_model), (&quot;mlp&quot;, mlp_pipeline)],</span>
        <span class="c1">#     final_estimator=meta_pipeline,</span>
        <span class="c1">#     n_jobs=-1</span>
        <span class="c1"># )</span>
        
        <span class="n">mlp_base</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
            <span class="p">(</span><span class="s1">&#39;scaler&#39;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span> 
            <span class="p">(</span><span class="s1">&#39;mlp&#39;</span><span class="p">,</span> <span class="n">MLPRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">))</span>
        <span class="p">])</span>
        
        <span class="n">meta_pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
            <span class="p">(</span><span class="s1">&#39;scaler&#39;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>  
            <span class="p">(</span><span class="s1">&#39;ridge_meta&#39;</span><span class="p">,</span> <span class="n">Ridge</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">))</span>
        <span class="p">])</span>
        
        <span class="n">stacking_core</span> <span class="o">=</span> <span class="n">StackingRegressor</span><span class="p">(</span>
            <span class="n">estimators</span><span class="o">=</span><span class="p">[</span>
                <span class="p">(</span><span class="s2">&quot;rf&quot;</span><span class="p">,</span> <span class="n">rf_model</span><span class="p">),</span>   <span class="c1"># RF/XGB are scale-invariant but will target anomalies</span>
                <span class="p">(</span><span class="s2">&quot;xgb&quot;</span><span class="p">,</span> <span class="n">xgb_model</span><span class="p">),</span> 
                <span class="p">(</span><span class="s2">&quot;mlp&quot;</span><span class="p">,</span> <span class="n">mlp_base</span><span class="p">)</span>
            <span class="p">],</span>
            <span class="n">final_estimator</span><span class="o">=</span><span class="n">meta_pipeline</span><span class="p">,</span>
            <span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
            <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span>
        <span class="p">)</span>
        
        <span class="n">stacking_ridge</span> <span class="o">=</span> <span class="n">TransformedTargetRegressor</span><span class="p">(</span>
            <span class="n">regressor</span><span class="o">=</span><span class="n">stacking_core</span><span class="p">,</span>
            <span class="n">transformer</span><span class="o">=</span><span class="n">StandardScaler</span><span class="p">()</span>
        <span class="p">)</span>
        <span class="n">unique_clusters</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">cluster_da</span><span class="p">)</span>
        <span class="n">unique_clusters</span> <span class="o">=</span> <span class="n">unique_clusters</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">unique_clusters</span><span class="p">)]</span>
        <span class="n">best_params_for_cluster</span> <span class="o">=</span> <span class="p">{}</span>
    
        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">unique_clusters</span><span class="p">:</span>
            <span class="n">mask_c</span> <span class="o">=</span> <span class="p">(</span><span class="n">cluster_da</span> <span class="o">==</span> <span class="n">c</span><span class="p">)</span>
            <span class="n">y_cluster</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">predictand</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">mask_c</span><span class="p">)</span>
                          <span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Y&quot;</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">],</span> <span class="n">skipna</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                          <span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="s2">&quot;T&quot;</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_cluster</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">])</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">continue</span>
    
            <span class="n">predictor_cluster</span> <span class="o">=</span> <span class="n">predictor</span><span class="o">.</span><span class="n">sel</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="n">y_cluster</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">])</span>
            <span class="n">X_mat</span> <span class="o">=</span> <span class="n">predictor_cluster</span><span class="o">.</span><span class="n">values</span>
            <span class="n">y_vec</span> <span class="o">=</span> <span class="n">y_cluster</span><span class="o">.</span><span class="n">values</span>
    
            <span class="c1"># Use optimizer to find best parameters</span>
            <span class="n">best_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span>
                <span class="n">stacking_ridge</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">param_grid</span><span class="p">,</span>
                <span class="n">X_mat</span><span class="p">,</span>
                <span class="n">y_vec</span><span class="p">,</span>
                <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;neg_mean_squared_error&#39;</span>
            <span class="p">)</span>
            <span class="n">best_params_for_cluster</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">c</span><span class="p">)]</span> <span class="o">=</span> <span class="n">best_params</span>
    
        <span class="c1"># Broadcast best hyperparameters</span>
        <span class="n">best_param_da</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">cluster_da</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">object</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">c</span><span class="p">,</span> <span class="n">bp</span> <span class="ow">in</span> <span class="n">best_params_for_cluster</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">c_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">cluster_da</span> <span class="o">==</span> <span class="n">c</span><span class="p">)</span>
            <span class="n">best_param_da</span> <span class="o">=</span> <span class="n">best_param_da</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="o">~</span><span class="n">c_mask</span><span class="p">,</span> <span class="n">other</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">bp</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">best_param_da</span><span class="p">,</span> <span class="n">cluster_da</span></div>


    <span class="c1"># ------------------------------------------------------------------</span>
    <span class="c1"># 2) FIT + PREDICT FOR A SINGLE GRID CELL</span>
    <span class="c1"># ------------------------------------------------------------------</span>
<div class="viewcode-block" id="WAS_Stacking_Ridge.fit_predict">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_Stacking_Ridge.fit_predict">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">fit_predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">best_params_str</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        For a single grid cell, parse the best params, instantiate the stacking regressor,</span>
<span class="sd">        fit to local data, and predict.</span>

<span class="sd">        Returns [error, prediction].</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span> <span class="o">&amp;</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">X_train</span><span class="p">),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">best_params_str</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">best_params_str</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># No valid hyperparams =&gt; return NaN</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">])</span>

        <span class="c1"># Parse param dict from string</span>
        <span class="n">best_params</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="n">best_params_str</span><span class="p">)</span>  <span class="c1"># or use a safer parser if you prefer</span>

        <span class="n">mlp_base</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
            <span class="p">(</span><span class="s1">&#39;scaler&#39;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span> 
            <span class="p">(</span><span class="s1">&#39;mlp&#39;</span><span class="p">,</span> <span class="n">MLPRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">))</span>
        <span class="p">])</span>
        
        <span class="n">meta_pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
            <span class="p">(</span><span class="s1">&#39;scaler&#39;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>  
            <span class="p">(</span><span class="s1">&#39;ridge_meta&#39;</span><span class="p">,</span> <span class="n">Ridge</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">))</span>
        <span class="p">])</span>
        
        <span class="n">stacking_core</span> <span class="o">=</span> <span class="n">StackingRegressor</span><span class="p">(</span>
            <span class="n">estimators</span><span class="o">=</span><span class="p">[</span>
                <span class="p">(</span><span class="s2">&quot;rf&quot;</span><span class="p">,</span> <span class="n">rf_model</span><span class="p">),</span>   <span class="c1"># RF/XGB are scale-invariant but will target anomalies</span>
                <span class="p">(</span><span class="s2">&quot;xgb&quot;</span><span class="p">,</span> <span class="n">xgb_model</span><span class="p">),</span> 
                <span class="p">(</span><span class="s2">&quot;mlp&quot;</span><span class="p">,</span> <span class="n">mlp_base</span><span class="p">)</span>
            <span class="p">],</span>
            <span class="n">final_estimator</span><span class="o">=</span><span class="n">meta_pipeline</span><span class="p">,</span>
            <span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
            <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span>
        <span class="p">)</span>
        
        <span class="n">stacking_ridge</span> <span class="o">=</span> <span class="n">TransformedTargetRegressor</span><span class="p">(</span>
            <span class="n">regressor</span><span class="o">=</span><span class="n">stacking_core</span><span class="p">,</span>
            <span class="n">transformer</span><span class="o">=</span><span class="n">StandardScaler</span><span class="p">()</span>
        <span class="p">)</span>

        <span class="c1"># Apply local best params</span>
        <span class="n">stacking_ridge</span><span class="o">.</span><span class="n">regressor</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="o">**</span><span class="n">best_params</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">mask</span><span class="p">):</span>
            <span class="n">X_c</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="n">mask</span><span class="p">,</span> <span class="p">:]</span>
            <span class="n">y_c</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>
            <span class="n">stacking_ridge</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_c</span><span class="p">,</span> <span class="n">y_c</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">X_test</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

            <span class="n">preds</span> <span class="o">=</span> <span class="n">stacking_ridge</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
            <span class="n">preds</span><span class="p">[</span><span class="n">preds</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># clip negative if modeling precip</span>
            <span class="n">err</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span> <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span> <span class="k">else</span> <span class="p">(</span><span class="n">y_test</span> <span class="o">-</span> <span class="n">preds</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">err</span><span class="p">,</span> <span class="n">preds</span><span class="p">])</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">])</span></div>


    <span class="c1"># ------------------------------------------------------------------</span>
    <span class="c1"># 3) PARALLEL MODELING ACROSS SPACE</span>
    <span class="c1"># ------------------------------------------------------------------</span>
<div class="viewcode-block" id="WAS_Stacking_Ridge.compute_model">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_Stacking_Ridge.compute_model">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">compute_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">best_param_da</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Parallel training + prediction across all spatial grid points.</span>
<span class="sd">        Uses local best hyperparams from best_param_da for each pixel.</span>

<span class="sd">        Returns an xarray.DataArray with dim (&#39;output&#39;,&#39;Y&#39;,&#39;X&#39;) =&gt; [error, prediction].</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">chunksize_x</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="o">.</span><span class="n">get_index</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">))</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span><span class="p">))</span>
        <span class="n">chunksize_y</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="o">.</span><span class="n">get_index</span><span class="p">(</span><span class="s2">&quot;Y&quot;</span><span class="p">))</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span><span class="p">))</span>

        <span class="n">X_train</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span>
        <span class="n">y_train</span> <span class="o">=</span> <span class="n">y_train</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="s1">&#39;T&#39;</span><span class="p">,</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span><span class="s1">&#39;X&#39;</span><span class="p">)</span>
        <span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
        <span class="n">y_test</span> <span class="o">=</span> <span class="n">y_test</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span><span class="s1">&#39;X&#39;</span><span class="p">)</span>

        <span class="n">client</span> <span class="o">=</span> <span class="n">Client</span><span class="p">(</span><span class="n">n_workers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span><span class="p">,</span> <span class="n">threads_per_worker</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">result_da</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">,</span>
            <span class="n">X_train</span><span class="p">,</span>
            <span class="n">y_train</span><span class="o">.</span><span class="n">chunk</span><span class="p">({</span><span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">chunksize_y</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">chunksize_x</span><span class="p">}),</span>
            <span class="n">X_test</span><span class="p">,</span>
            <span class="n">y_test</span><span class="o">.</span><span class="n">chunk</span><span class="p">({</span><span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">chunksize_y</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">chunksize_x</span><span class="p">}),</span>
            <span class="n">best_param_da</span><span class="o">.</span><span class="n">chunk</span><span class="p">({</span><span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">chunksize_y</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">chunksize_x</span><span class="p">}),</span>
            <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[</span>
                <span class="p">(</span><span class="s1">&#39;T&#39;</span><span class="p">,</span><span class="s1">&#39;features&#39;</span><span class="p">),</span>  <span class="c1"># X_train</span>
                <span class="p">(</span><span class="s1">&#39;T&#39;</span><span class="p">,),</span>           <span class="c1"># y_train</span>
                <span class="p">(</span><span class="s1">&#39;features&#39;</span><span class="p">,),</span>    <span class="c1"># X_test</span>
                <span class="p">(),</span>
                <span class="p">()</span>
            <span class="p">],</span>
            <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">dask</span><span class="o">=</span><span class="s1">&#39;parallelized&#39;</span><span class="p">,</span>
            <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s1">&#39;output&#39;</span><span class="p">,)],</span>
            <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>
            <span class="n">dask_gufunc_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;output_sizes&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;output&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">}},</span>
        <span class="p">)</span>
        <span class="n">result_</span> <span class="o">=</span> <span class="n">result_da</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
        <span class="n">client</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">result_</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">output</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></div>


    <span class="c1"># ------------------ Probability Calculation Methods ------------------</span>

<div class="viewcode-block" id="WAS_Stacking_Ridge._ppf_terciles_from_code">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_Stacking_Ridge._ppf_terciles_from_code">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_ppf_terciles_from_code</span><span class="p">(</span><span class="n">dist_code</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return tercile thresholds (T1, T2) from best-fit distribution parameters.</span>
<span class="sd">    </span>
<span class="sd">        dist_code:</span>
<span class="sd">            1: norm</span>
<span class="sd">            2: lognorm</span>
<span class="sd">            3: expon</span>
<span class="sd">            4: gamma</span>
<span class="sd">            5: weibull_min</span>
<span class="sd">            6: t</span>
<span class="sd">            7: poisson</span>
<span class="sd">            8: nbinom</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">dist_code</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
    
        <span class="n">code</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">dist_code</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                    <span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">lognorm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                    <span class="n">lognorm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">expon</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                    <span class="n">expon</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">gamma</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                    <span class="n">gamma</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">5</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">weibull_min</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                    <span class="n">weibull_min</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">6</span><span class="p">:</span>
                <span class="c1"># Note: Renamed &#39;t_dist&#39; to &#39;t&#39; for standard scipy.stats</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">t</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                    <span class="n">t</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">7</span><span class="p">:</span>
                <span class="c1"># Poisson: poisson.ppf(q, mu, loc=0)</span>
                <span class="c1"># ASSUMPTION: &#39;mu&#39; (mean) is passed as &#39;shape&#39;</span>
                <span class="c1">#             &#39;loc&#39; is passed as &#39;loc&#39;</span>
                <span class="c1">#             &#39;scale&#39; is unused</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">poisson</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">),</span>
                    <span class="n">poisson</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">8</span><span class="p">:</span>
                <span class="c1"># Negative Binomial: nbinom.ppf(q, n, p, loc=0)</span>
                <span class="c1"># ASSUMPTION: &#39;n&#39; (successes) is passed as &#39;shape&#39;</span>
                <span class="c1">#             &#39;p&#39; (probability) is passed as &#39;scale&#39;</span>
                <span class="c1">#             &#39;loc&#39; is passed as &#39;loc&#39;</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">nbinom</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">scale</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">),</span>
                    <span class="n">nbinom</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">scale</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">),</span>
                <span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
    
        <span class="c1"># Fallback if code is not 1-8</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span></div>

        
<div class="viewcode-block" id="WAS_Stacking_Ridge.weibull_shape_solver">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_Stacking_Ridge.weibull_shape_solver">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">weibull_shape_solver</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">V</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Function to find the root of the Weibull shape parameter &#39;k&#39;.</span>
<span class="sd">        We find &#39;k&#39; such that the theoretical variance/mean^2 ratio</span>
<span class="sd">        matches the observed V/M^2 ratio.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Guard against invalid &#39;k&#39; values during solving</span>
        <span class="k">if</span> <span class="n">k</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">g1</span> <span class="o">=</span> <span class="n">gamma_function</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="mi">1</span><span class="o">/</span><span class="n">k</span><span class="p">)</span>
            <span class="n">g2</span> <span class="o">=</span> <span class="n">gamma_function</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="mi">2</span><span class="o">/</span><span class="n">k</span><span class="p">)</span>
            
            <span class="c1"># This is the V/M^2 ratio *implied by k*</span>
            <span class="n">implied_v_over_m_sq</span> <span class="o">=</span> <span class="p">(</span><span class="n">g2</span> <span class="o">/</span> <span class="p">(</span><span class="n">g1</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span> <span class="o">-</span> <span class="mi">1</span>
            
            <span class="c1"># This is the *observed* ratio</span>
            <span class="n">observed_v_over_m_sq</span> <span class="o">=</span> <span class="n">V</span> <span class="o">/</span> <span class="p">(</span><span class="n">M</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
            
            <span class="c1"># Return the difference (we want this to be 0)</span>
            <span class="k">return</span> <span class="n">observed_v_over_m_sq</span> <span class="o">-</span> <span class="n">implied_v_over_m_sq</span>
        <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
            <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span> <span class="c1"># Handle math errors</span></div>


<div class="viewcode-block" id="WAS_Stacking_Ridge.calculate_tercile_probabilities_bestfit">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_Stacking_Ridge.calculate_tercile_probabilities_bestfit">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">calculate_tercile_probabilities_bestfit</span><span class="p">(</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">error_variance</span><span class="p">,</span> <span class="n">T1</span><span class="p">,</span> <span class="n">T2</span><span class="p">,</span> <span class="n">dist_code</span><span class="p">,</span> <span class="n">dof</span> 
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generic tercile probabilities using best-fit family per grid cell.</span>

<span class="sd">        Inputs (per grid cell):</span>
<span class="sd">        - best_guess : 1D array over T (hindcast_det or forecast_det)</span>
<span class="sd">        - T1, T2     : scalar terciles from climatological best-fit distribution</span>
<span class="sd">        - dist_code  : int, as in _ppf_terciles_from_code</span>
<span class="sd">        - shape, loc, scale : scalars from climatology fit</span>

<span class="sd">        Strategy:</span>
<span class="sd">        - For each time step, build a predictive distribution of the same family:</span>
<span class="sd">            * Use best_guess[t] to adjust mean / location;</span>
<span class="sd">            * Keep shape parameters from climatology.</span>
<span class="sd">        - Then compute probabilities:</span>
<span class="sd">            P(B) = F(T1), P(N) = F(T2) - F(T1), P(A) = 1 - F(T2).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        
        <span class="n">best_guess</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">best_guess</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span>
        <span class="n">error_variance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">error_variance</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
        <span class="c1"># T1 = np.asarray(T1, dtype=float)</span>
        <span class="c1"># T2 = np.asarray(T2, dtype=float)</span>
        <span class="n">n_time</span> <span class="o">=</span> <span class="n">best_guess</span><span class="o">.</span><span class="n">size</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="n">n_time</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">best_guess</span><span class="p">))</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">dist_code</span><span class="p">)</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">T1</span><span class="p">)</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">T2</span><span class="p">)</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">error_variance</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">out</span>

        <span class="n">code</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">dist_code</span><span class="p">)</span>

        <span class="c1"># Normal: loc = forecast; scale from clim</span>
        <span class="k">if</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">error_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">error_variance</span><span class="p">)</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">error_std</span><span class="p">)</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">error_std</span><span class="p">)</span> <span class="o">-</span> <span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">error_std</span><span class="p">)</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">error_std</span><span class="p">)</span>

        <span class="c1"># Lognormal: shape = sigma from clim; enforce mean = best_guess</span>
        <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">sigma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">error_variance</span> <span class="o">/</span> <span class="p">(</span><span class="n">best_guess</span><span class="o">**</span><span class="mi">2</span><span class="p">)))</span>
            <span class="n">mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">best_guess</span><span class="p">)</span> <span class="o">-</span> <span class="n">sigma</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="mi">2</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">lognorm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">mu</span><span class="p">))</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">lognorm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">mu</span><span class="p">))</span> <span class="o">-</span> <span class="n">lognorm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">mu</span><span class="p">))</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">lognorm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">mu</span><span class="p">))</span>      


        <span class="c1"># Exponential: keep scale from clim; shift loc so mean = best_guess</span>
        <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
            <span class="n">c1</span> <span class="o">=</span> <span class="n">expon</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">error_variance</span><span class="p">))</span>
            <span class="n">c2</span> <span class="o">=</span> <span class="n">expon</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc_t</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">error_variance</span><span class="p">))</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c2</span> <span class="o">-</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">c2</span>

        <span class="c1"># Gamma: use shape from clim; set scale so mean = best_guess</span>
        <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
            <span class="n">alpha</span> <span class="o">=</span> <span class="p">(</span><span class="n">best_guess</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="n">error_variance</span>
            <span class="n">theta</span> <span class="o">=</span> <span class="n">error_variance</span> <span class="o">/</span> <span class="n">best_guess</span>
            <span class="n">c1</span> <span class="o">=</span> <span class="n">gamma</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">theta</span><span class="p">)</span>
            <span class="n">c2</span> <span class="o">=</span> <span class="n">gamma</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">theta</span><span class="p">)</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c2</span> <span class="o">-</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">c2</span>

        <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">5</span><span class="p">:</span> <span class="c1"># Assuming 5 is for Weibull   </span>
        
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_time</span><span class="p">):</span>
                <span class="c1"># Get the scalar values for this specific element (e.g., grid cell)</span>
                <span class="n">M</span> <span class="o">=</span> <span class="n">best_guess</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">M</span><span class="p">)</span>
                <span class="n">V</span> <span class="o">=</span> <span class="n">error_variance</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">V</span><span class="p">)</span>
                
                <span class="c1"># Handle cases with no variance to avoid division by zero</span>
                <span class="k">if</span> <span class="n">V</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">M</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                    <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                    <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                    <span class="k">continue</span> <span class="c1"># Skip to the next element</span>
        
                <span class="c1"># --- 1. Numerically solve for shape &#39;k&#39; ---</span>
                <span class="c1"># We need a reasonable starting guess. 2.0 is common (Rayleigh dist.)</span>
                <span class="n">initial_guess</span> <span class="o">=</span> <span class="mf">2.0</span>
                
                <span class="c1"># fsolve finds the root of our helper function</span>
                <span class="n">k</span> <span class="o">=</span> <span class="n">fsolve</span><span class="p">(</span><span class="n">weibull_shape_solver</span><span class="p">,</span> <span class="n">initial_guess</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">V</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>
        
                <span class="c1"># --- 2. Check for bad solution and calculate scale &#39;lambda&#39; ---</span>
                <span class="k">if</span> <span class="n">k</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="c1"># Solver failed</span>
                    <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                    <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                    <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                    <span class="k">continue</span>
                
                <span class="c1"># With &#39;k&#39; found, we can now algebraically find scale &#39;lambda&#39;</span>
                <span class="c1"># In scipy.stats, scale is &#39;scale&#39;</span>
                <span class="n">lambda_scale</span> <span class="o">=</span> <span class="n">M</span> <span class="o">/</span> <span class="n">gamma_function</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="mi">1</span><span class="o">/</span><span class="n">k</span><span class="p">)</span>
        
                <span class="c1"># --- 3. Calculate Probabilities ---</span>
                <span class="c1"># In scipy.stats, shape &#39;k&#39; is &#39;c&#39;</span>
                <span class="c1"># Use the T1 and T2 values for this specific element</span>
                
                <span class="n">c1</span> <span class="o">=</span> <span class="n">weibull_min</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">lambda_scale</span><span class="p">)</span>
                <span class="n">c2</span> <span class="o">=</span> <span class="n">weibull_min</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">lambda_scale</span><span class="p">)</span>
        
                <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">c1</span>
                <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">c2</span> <span class="o">-</span> <span class="n">c1</span>
                <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">c2</span>

        <span class="c1"># Student-t: df from clim; scale from clim; loc = best_guess</span>
        <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">6</span><span class="p">:</span>       
            <span class="c1"># Check if df is valid for variance calculation</span>
            <span class="k">if</span> <span class="n">dof</span> <span class="o">&lt;=</span> <span class="mi">2</span><span class="p">:</span>
                <span class="c1"># Cannot calculate scale, fill with NaNs</span>
                <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># 1. Calculate t-distribution parameters</span>
                <span class="c1"># &#39;loc&#39; (mean) is just the best_guess</span>
                <span class="n">loc</span> <span class="o">=</span> <span class="n">best_guess</span>
                <span class="c1"># &#39;scale&#39; is calculated from the variance and df</span>
                <span class="c1"># Variance = scale**2 * (df / (df - 2))</span>
                <span class="n">scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">error_variance</span> <span class="o">*</span> <span class="p">(</span><span class="n">dof</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="n">dof</span><span class="p">)</span>
                
                <span class="c1"># 2. Calculate probabilities</span>
                <span class="n">c1</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">dof</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">)</span>
                <span class="n">c2</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">dof</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">)</span>

                <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c1</span>
                <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c2</span> <span class="o">-</span> <span class="n">c1</span>
                <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">c2</span>

        <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">7</span><span class="p">:</span> <span class="c1"># Assuming 7 is for Poisson</span>
            
            <span class="c1"># --- 1. Set the Poisson parameter &#39;mu&#39; ---</span>
            <span class="c1"># The &#39;mu&#39; parameter is the mean.</span>
            
            <span class="c1"># A warning is strongly recommended if error_variance is different from best_guess</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">error_variance</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Warning: &#39;error_variance&#39; is not equal to &#39;best_guess&#39;.&quot;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Poisson model assumes mean=variance and is likely inappropriate.&quot;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Consider using Negative Binomial.&quot;</span><span class="p">)</span>
            
            <span class="n">mu</span> <span class="o">=</span> <span class="n">best_guess</span>
        
            <span class="c1"># --- 2. Calculate Probabilities ---</span>
            <span class="c1"># poisson.cdf(k, mu) calculates P(X &lt;= k)</span>
            
            <span class="n">c1</span> <span class="o">=</span> <span class="n">poisson</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">mu</span><span class="p">)</span>
            <span class="n">c2</span> <span class="o">=</span> <span class="n">poisson</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">mu</span><span class="p">)</span>
            
            <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c2</span> <span class="o">-</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">c2</span>

        <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">8</span><span class="p">:</span> <span class="c1"># Assuming 8 is for Negative Binomial</span>
            
            <span class="c1"># --- 1. Calculate Negative Binomial Parameters ---</span>
            <span class="c1"># This model is ONLY valid for overdispersion (Variance &gt; Mean).</span>
            <span class="c1"># We will use np.where to set parameters to NaN if V &lt;= M.</span>
            
            <span class="c1"># p = Mean / Variance</span>
            <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">error_variance</span> <span class="o">&gt;</span> <span class="n">best_guess</span><span class="p">,</span> 
                         <span class="n">best_guess</span> <span class="o">/</span> <span class="n">error_variance</span><span class="p">,</span> 
                         <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
            
            <span class="c1"># n = Mean^2 / (Variance - Mean)</span>
            <span class="n">n</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">error_variance</span> <span class="o">&gt;</span> <span class="n">best_guess</span><span class="p">,</span> 
                         <span class="p">(</span><span class="n">best_guess</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">error_variance</span> <span class="o">-</span> <span class="n">best_guess</span><span class="p">),</span> 
                         <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
            
            <span class="c1"># --- 2. Calculate Probabilities ---</span>
            <span class="c1"># The nbinom.cdf function will propagate NaNs, correctly</span>
            <span class="c1"># handling the cases where the model was invalid.</span>
            
            <span class="n">c1</span> <span class="o">=</span> <span class="n">nbinom</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">)</span>
            <span class="n">c2</span> <span class="o">=</span> <span class="n">nbinom</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">)</span>
            
            <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c2</span> <span class="o">-</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">c2</span>
            
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid distribution&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">out</span></div>


<div class="viewcode-block" id="WAS_Stacking_Ridge.calculate_tercile_probabilities_nonparametric">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_Stacking_Ridge.calculate_tercile_probabilities_nonparametric">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">calculate_tercile_probabilities_nonparametric</span><span class="p">(</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">error_samples</span><span class="p">,</span> <span class="n">first_tercile</span><span class="p">,</span> <span class="n">second_tercile</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Non-parametric method using historical error samples.&quot;&quot;&quot;</span>
        <span class="n">n_time</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">best_guess</span><span class="p">)</span>
        <span class="n">pred_prob</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="n">n_time</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_time</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">best_guess</span><span class="p">[</span><span class="n">t</span><span class="p">]):</span>
                <span class="k">continue</span>
            <span class="n">dist</span> <span class="o">=</span> <span class="n">best_guess</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">+</span> <span class="n">error_samples</span>
            <span class="n">dist</span> <span class="o">=</span> <span class="n">dist</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">dist</span><span class="p">)]</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">dist</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="n">p_below</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dist</span> <span class="o">&lt;</span> <span class="n">first_tercile</span><span class="p">)</span>
            <span class="n">p_between</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">dist</span> <span class="o">&gt;=</span> <span class="n">first_tercile</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">dist</span> <span class="o">&lt;</span> <span class="n">second_tercile</span><span class="p">))</span>
            <span class="n">p_above</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="p">(</span><span class="n">p_below</span> <span class="o">+</span> <span class="n">p_between</span><span class="p">)</span>
            <span class="n">pred_prob</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">p_below</span>
            <span class="n">pred_prob</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">p_between</span>
            <span class="n">pred_prob</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">p_above</span>
        <span class="k">return</span> <span class="n">pred_prob</span></div>




<div class="viewcode-block" id="WAS_Stacking_Ridge.compute_prob">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_Stacking_Ridge.compute_prob">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">compute_prob</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">Predictant</span><span class="p">:</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span><span class="p">,</span>
        <span class="n">clim_year_start</span><span class="p">,</span>
        <span class="n">clim_year_end</span><span class="p">,</span>
        <span class="n">hindcast_det</span><span class="p">:</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span><span class="p">,</span>
        <span class="n">best_code_da</span><span class="p">:</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">best_shape_da</span><span class="p">:</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">best_loc_da</span><span class="p">:</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">best_scale_da</span><span class="p">:</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute tercile probabilities for deterministic hindcasts.</span>

<span class="sd">        If dist_method == &#39;bestfit&#39;:</span>
<span class="sd">            - Use cluster-based best-fit distributions to:</span>
<span class="sd">                * derive terciles analytically from (best_code_da, best_shape_da, best_loc_da, best_scale_da),</span>
<span class="sd">                * compute predictive probabilities using the same family.</span>

<span class="sd">        Otherwise:</span>
<span class="sd">            - Use empirical terciles from Predictant climatology and the selected</span>
<span class="sd">              parametric / nonparametric method.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Predictant : xarray.DataArray</span>
<span class="sd">            Observed data (T, Y, X) or (T, Y, X, M).</span>
<span class="sd">        clim_year_start, clim_year_end : int or str</span>
<span class="sd">            Climatology period (inclusive) for thresholds.</span>
<span class="sd">        hindcast_det : xarray.DataArray</span>
<span class="sd">            Deterministic hindcast (T, Y, X).</span>
<span class="sd">        best_code_da, best_shape_da, best_loc_da, best_scale_da : xarray.DataArray, optional</span>
<span class="sd">            Output from WAS_TransformData.fit_best_distribution_grid, required for &#39;bestfit&#39;.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        hindcast_prob : xarray.DataArray</span>
<span class="sd">            Probabilities with dims (probability=[&#39;PB&#39;,&#39;PN&#39;,&#39;PA&#39;], T, Y, X).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Handle member dimension if present</span>
        <span class="k">if</span> <span class="s2">&quot;M&quot;</span> <span class="ow">in</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">dims</span><span class="p">:</span>
            <span class="n">Predictant</span> <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">M</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">drop_vars</span><span class="p">(</span><span class="s2">&quot;M&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>

        <span class="c1"># Ensure dimension order</span>
        <span class="n">Predictant</span> <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="s2">&quot;Y&quot;</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">)</span>

        <span class="c1"># Spatial mask</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="o">~</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">Predictant</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="mi">0</span><span class="p">)),</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>

        <span class="c1"># Climatology subset</span>
        <span class="n">clim</span> <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">sel</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="nb">slice</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">clim_year_start</span><span class="p">),</span> <span class="nb">str</span><span class="p">(</span><span class="n">clim_year_end</span><span class="p">)))</span>
        <span class="k">if</span> <span class="n">clim</span><span class="o">.</span><span class="n">sizes</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">3</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Not enough years in climatology period for terciles.&quot;</span><span class="p">)</span>

        <span class="c1"># Error variance for predictive distributions</span>
        <span class="n">error_variance</span> <span class="o">=</span> <span class="p">(</span><span class="n">Predictant</span> <span class="o">-</span> <span class="n">hindcast_det</span><span class="p">)</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="s2">&quot;T&quot;</span><span class="p">)</span>
        <span class="n">dof</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">clim</span><span class="o">.</span><span class="n">sizes</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">])</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

        <span class="c1"># Empirical terciles (used by non-bestfit methods)</span>
        <span class="n">terciles_emp</span> <span class="o">=</span> <span class="n">clim</span><span class="o">.</span><span class="n">quantile</span><span class="p">([</span><span class="mf">0.32</span><span class="p">,</span> <span class="mf">0.67</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="s2">&quot;T&quot;</span><span class="p">)</span>
        <span class="n">T1_emp</span> <span class="o">=</span> <span class="n">terciles_emp</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">quantile</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">drop_vars</span><span class="p">(</span><span class="s2">&quot;quantile&quot;</span><span class="p">)</span>
        <span class="n">T2_emp</span> <span class="o">=</span> <span class="n">terciles_emp</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">quantile</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">drop_vars</span><span class="p">(</span><span class="s2">&quot;quantile&quot;</span><span class="p">)</span>
        

        <span class="n">dm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dist_method</span>

        <span class="c1"># ---------- BESTFIT: zone-wise optimal distributions ----------</span>
        <span class="k">if</span> <span class="n">dm</span> <span class="o">==</span> <span class="s2">&quot;bestfit&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">v</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="p">(</span><span class="n">best_code_da</span><span class="p">,</span> <span class="n">best_shape_da</span><span class="p">,</span> <span class="n">best_loc_da</span><span class="p">,</span> <span class="n">best_scale_da</span><span class="p">)):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;dist_method=&#39;bestfit&#39; requires best_code_da, best_shape_da_da, best_loc_da, best_scale_da.&quot;</span>
                <span class="p">)</span>

            <span class="c1"># T1, T2 from best-fit distributions (per grid)</span>
            <span class="n">T1</span><span class="p">,</span> <span class="n">T2</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_ppf_terciles_from_code</span><span class="p">,</span>
                <span class="n">best_code_da</span><span class="p">,</span>
                <span class="n">best_shape_da</span><span class="p">,</span>
                <span class="n">best_loc_da</span><span class="p">,</span>
                <span class="n">best_scale_da</span><span class="p">,</span>
                <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[(),</span> <span class="p">(),</span> <span class="p">(),</span> <span class="p">()],</span>
                <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(),</span> <span class="p">()],</span>
                <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">dask</span><span class="o">=</span><span class="s2">&quot;parallelized&quot;</span><span class="p">,</span>
                <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span>
            <span class="p">)</span>

            <span class="c1"># Predictive probabilities using same family</span>
            <span class="n">hindcast_prob</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">calculate_tercile_probabilities_bestfit</span><span class="p">,</span>
                <span class="n">hindcast_det</span><span class="p">,</span>
                <span class="n">error_variance</span><span class="p">,</span>
                <span class="n">T1</span><span class="p">,</span>
                <span class="n">T2</span><span class="p">,</span>
                <span class="n">best_code_da</span><span class="p">,</span>
                <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;T&quot;</span><span class="p">,),</span> <span class="p">(),</span> <span class="p">(),</span> <span class="p">(),</span> <span class="p">()],</span>
                <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;probability&quot;</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">)],</span>
                <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;dof&#39;</span><span class="p">:</span> <span class="n">dof</span><span class="p">},</span>
                <span class="n">dask</span><span class="o">=</span><span class="s2">&quot;parallelized&quot;</span><span class="p">,</span>
                <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>
                <span class="n">dask_gufunc_kwargs</span><span class="o">=</span><span class="p">{</span>
                    <span class="s2">&quot;output_sizes&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;probability&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">},</span>
                    <span class="s2">&quot;allow_rechunk&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                <span class="p">},</span>
            <span class="p">)</span>

        <span class="c1"># ---------- Nonparametric ----------</span>
        <span class="k">elif</span> <span class="n">dm</span> <span class="o">==</span> <span class="s2">&quot;nonparam&quot;</span><span class="p">:</span>
            <span class="n">error_samples</span> <span class="o">=</span> <span class="n">Predictant</span> <span class="o">-</span> <span class="n">hindcast_det</span>
            <span class="n">hindcast_prob</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">calculate_tercile_probabilities_nonparametric</span><span class="p">,</span>
                <span class="n">hindcast_det</span><span class="p">,</span>
                <span class="n">error_samples</span><span class="p">,</span>
                <span class="n">T1_emp</span><span class="p">,</span>
                <span class="n">T2_emp</span><span class="p">,</span>
                <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;T&quot;</span><span class="p">,),</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,),</span> <span class="p">(),</span> <span class="p">()],</span>
                <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;probability&quot;</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">)],</span>
                <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">dask</span><span class="o">=</span><span class="s2">&quot;parallelized&quot;</span><span class="p">,</span>
                <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>
                <span class="n">dask_gufunc_kwargs</span><span class="o">=</span><span class="p">{</span>
                    <span class="s2">&quot;output_sizes&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;probability&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">},</span>
                    <span class="s2">&quot;allow_rechunk&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                <span class="p">},</span>
            <span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid dist_method: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">dist_method</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">hindcast_prob</span> <span class="o">=</span> <span class="n">hindcast_prob</span><span class="o">.</span><span class="n">assign_coords</span><span class="p">(</span>
            <span class="n">probability</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;probability&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;PB&quot;</span><span class="p">,</span> <span class="s2">&quot;PN&quot;</span><span class="p">,</span> <span class="s2">&quot;PA&quot;</span><span class="p">])</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">hindcast_prob</span> <span class="o">*</span> <span class="n">mask</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="s2">&quot;probability&quot;</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="s2">&quot;Y&quot;</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">)</span></div>



    <span class="c1"># ------------------------------------------------------------------</span>
    <span class="c1"># 6) FORECAST METHOD</span>
    <span class="c1"># ------------------------------------------------------------------</span>
<div class="viewcode-block" id="WAS_Stacking_Ridge.forecast">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_Stacking_Ridge.forecast">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">forecast</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Predictant</span><span class="p">,</span> <span class="n">clim_year_start</span><span class="p">,</span> <span class="n">clim_year_end</span><span class="p">,</span> <span class="n">Predictor</span><span class="p">,</span> <span class="n">hindcast_det</span><span class="p">,</span> <span class="n">Predictor_for_year</span><span class="p">,</span> <span class="n">best_param_da</span><span class="p">,</span> <span class="n">best_code_da</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">best_shape_da</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">best_loc_da</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">best_scale_da</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Forecast for a single future year (or time) and compute tercile probabilities.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Predictant : xarray.DataArray</span>
<span class="sd">            Observed data with dims (T, Y, X), used for computing climatology thresholds.</span>
<span class="sd">        clim_year_start : int</span>
<span class="sd">            Start of climatology period.</span>
<span class="sd">        clim_year_end : int</span>
<span class="sd">            End of climatology period.</span>
<span class="sd">        Predictor : xarray.DataArray</span>
<span class="sd">            Historical predictor data, shape (T, features).</span>
<span class="sd">        hindcast_det : xarray.DataArray</span>
<span class="sd">            Historical deterministic forecast with dims (output=[error,prediction], T, Y, X) </span>
<span class="sd">            for computing error variance or samples.</span>
<span class="sd">        Predictor_for_year : xarray.DataArray</span>
<span class="sd">            Predictor data for the forecast year, shape (features,) or (1, features).</span>
<span class="sd">        best_param_da : xarray.DataArray</span>
<span class="sd">            Local best hyperparams from compute_hyperparameters, shape (Y, X).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        result_ : xarray.DataArray</span>
<span class="sd">            dims (output=2, Y, X) =&gt; [error, prediction].</span>
<span class="sd">            In a real forecast, &quot;error&quot; is typically NaN since we have no future observation.</span>
<span class="sd">        hindcast_prob : xarray.DataArray</span>
<span class="sd">            dims (probability=3, Y, X) =&gt; [PB, PN, PA].</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Create a dummy y_test (NaN) for the forecast</span>
        <span class="n">y_test_dummy</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">Predictant</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>  <span class="c1"># shape (Y, X)</span>

        <span class="c1"># Chunk sizes for parallel</span>
        <span class="n">chunksize_x</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">Predictant</span><span class="o">.</span><span class="n">get_index</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">))</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span><span class="p">))</span>
        <span class="n">chunksize_y</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">Predictant</span><span class="o">.</span><span class="n">get_index</span><span class="p">(</span><span class="s2">&quot;Y&quot;</span><span class="p">))</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span><span class="p">))</span>

        <span class="c1"># Align times</span>
        <span class="n">Predictor</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">Predictant</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span>
        <span class="n">Predictant</span> <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="s1">&#39;T&#39;</span><span class="p">,</span> <span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">)</span>
        <span class="n">Predictor_for_year_</span> <span class="o">=</span> <span class="n">Predictor_for_year</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
        <span class="c1"># Predictant_st = standardize_timeseries(Predictant, clim_year_start, clim_year_end)</span>
        
        <span class="c1"># 1) Fit+predict in parallel =&gt; shape (2, Y, X)</span>
        <span class="n">client</span> <span class="o">=</span> <span class="n">Client</span><span class="p">(</span><span class="n">n_workers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span><span class="p">,</span> <span class="n">threads_per_worker</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">result_da</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">,</span>
            <span class="n">Predictor</span><span class="p">,</span>
            <span class="n">Predictant</span><span class="o">.</span><span class="n">chunk</span><span class="p">({</span><span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">chunksize_y</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">chunksize_x</span><span class="p">}),</span>
            <span class="n">Predictor_for_year_</span><span class="p">,</span>
            <span class="n">y_test_dummy</span><span class="o">.</span><span class="n">chunk</span><span class="p">({</span><span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">chunksize_y</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">chunksize_x</span><span class="p">}),</span>     <span class="c1"># dummy y_test</span>
            <span class="n">best_param_da</span><span class="o">.</span><span class="n">chunk</span><span class="p">({</span><span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">chunksize_y</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">chunksize_x</span><span class="p">}),</span>
            <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[</span>
                <span class="p">(</span><span class="s1">&#39;T&#39;</span><span class="p">,</span><span class="s1">&#39;features&#39;</span><span class="p">),</span>  <span class="c1"># X_train</span>
                <span class="p">(</span><span class="s1">&#39;T&#39;</span><span class="p">,),</span>           <span class="c1"># y_train</span>
                <span class="p">(</span><span class="s1">&#39;features&#39;</span><span class="p">,),</span>    <span class="c1"># X_test</span>
                <span class="p">(),</span>               <span class="c1"># y_test</span>
                <span class="p">()</span>                <span class="c1"># best_params_str</span>
            <span class="p">],</span>
            <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">dask</span><span class="o">=</span><span class="s1">&#39;parallelized&#39;</span><span class="p">,</span>
            <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s1">&#39;output&#39;</span><span class="p">,)],</span>
            <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>
            <span class="n">dask_gufunc_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;output_sizes&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;output&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">}},</span>
        <span class="p">)</span>
        <span class="n">result_</span> <span class="o">=</span> <span class="n">result_da</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
        <span class="n">client</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
        <span class="n">result_</span> <span class="o">=</span> <span class="n">result_</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">output</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># result_ = reverse_standardize(result_, Predictant, clim_year_start, clim_year_end)</span>
        
        <span class="c1"># result_ =&gt; dims (output=2, Y, X). </span>
        <span class="c1"># For a real future forecast, &quot;error&quot; is NaN, &quot;prediction&quot; is the forecast.</span>

        <span class="c1"># 2) Compute thresholds T1, T2 from climatology</span>
        <span class="n">index_start</span> <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">get_index</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">get_loc</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">clim_year_start</span><span class="p">))</span><span class="o">.</span><span class="n">start</span>
        <span class="n">index_end</span>   <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">get_index</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">get_loc</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">clim_year_end</span><span class="p">))</span><span class="o">.</span><span class="n">stop</span>
        <span class="n">rainfall_for_tercile</span> <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="nb">slice</span><span class="p">(</span><span class="n">index_start</span><span class="p">,</span> <span class="n">index_end</span><span class="p">))</span>
        <span class="n">terciles</span> <span class="o">=</span> <span class="n">rainfall_for_tercile</span><span class="o">.</span><span class="n">quantile</span><span class="p">([</span><span class="mf">0.32</span><span class="p">,</span> <span class="mf">0.67</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="s1">&#39;T&#39;</span><span class="p">)</span>
        <span class="n">T1</span> <span class="o">=</span> <span class="n">terciles</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">quantile</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">drop_vars</span><span class="p">(</span><span class="s1">&#39;quantile&#39;</span><span class="p">)</span>
        <span class="n">T2</span> <span class="o">=</span> <span class="n">terciles</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">quantile</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">drop_vars</span><span class="p">(</span><span class="s1">&#39;quantile&#39;</span><span class="p">)</span>
        <span class="n">error_variance</span> <span class="o">=</span> <span class="p">(</span><span class="n">Predictant</span> <span class="o">-</span> <span class="n">hindcast_det</span><span class="p">)</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="s1">&#39;T&#39;</span><span class="p">)</span>
        
        <span class="c1"># Expand single prediction to T=1 so probability methods can handle it</span>
        <span class="n">forecast_expanded</span> <span class="o">=</span> <span class="n">result_</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span>
            <span class="n">T</span><span class="o">=</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">Timestamp</span><span class="p">(</span><span class="n">Predictor_for_year</span><span class="o">.</span><span class="n">coords</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">to_pydatetime</span><span class="p">()]</span>
        <span class="p">)</span>
        <span class="n">year</span> <span class="o">=</span> <span class="n">Predictor_for_year</span><span class="o">.</span><span class="n">coords</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;datetime64[Y]&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1970</span>
        <span class="c1"># year = Predictor_for_year.coords[&#39;T&#39;].values.astype(&#39;datetime64[Y]&#39;).astype(int)[0] + 1970  </span>
        <span class="n">T_value_1</span> <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">coords</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>  <span class="c1"># Get the datetime64 value from da1</span>
        <span class="n">month_1</span> <span class="o">=</span> <span class="n">T_value_1</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;datetime64[M]&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span> <span class="o">%</span> <span class="mi">12</span> <span class="o">+</span> <span class="mi">1</span>  <span class="c1"># Extract month</span>
        <span class="n">new_T_value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">datetime64</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">year</span><span class="si">}</span><span class="s2">-</span><span class="si">{</span><span class="n">month_1</span><span class="si">:</span><span class="s2">02d</span><span class="si">}</span><span class="s2">-</span><span class="si">{</span><span class="mi">1</span><span class="si">:</span><span class="s2">02d</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        
        <span class="n">forecast_expanded</span> <span class="o">=</span> <span class="n">forecast_expanded</span><span class="o">.</span><span class="n">assign_coords</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span><span class="p">([</span><span class="n">new_T_value</span><span class="p">],</span> <span class="n">dims</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">]))</span>
        <span class="n">forecast_expanded</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">forecast_expanded</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;datetime64[ns]&#39;</span><span class="p">)</span>

        <span class="n">dof</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">rainfall_for_tercile</span><span class="o">.</span><span class="n">sizes</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">])</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

        <span class="n">dm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dist_method</span>

        <span class="c1"># ---------- BESTFIT ----------</span>
        <span class="k">if</span> <span class="n">dm</span> <span class="o">==</span> <span class="s2">&quot;bestfit&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">v</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="p">(</span><span class="n">best_code_da</span><span class="p">,</span> <span class="n">best_shape_da</span><span class="p">,</span> <span class="n">best_loc_da</span><span class="p">,</span> <span class="n">best_scale_da</span><span class="p">)):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;dist_method=&#39;bestfit&#39; requires best_code_da, best_shape_da, best_loc_da, best_scale_da.&quot;</span>
                <span class="p">)</span>
            
            <span class="n">T1</span><span class="p">,</span> <span class="n">T2</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_ppf_terciles_from_code</span><span class="p">,</span>
                <span class="n">best_code_da</span><span class="p">,</span>
                <span class="n">best_shape_da</span><span class="p">,</span>
                <span class="n">best_loc_da</span><span class="p">,</span>
                <span class="n">best_scale_da</span><span class="p">,</span>
                <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[(),</span> <span class="p">(),</span> <span class="p">(),</span> <span class="p">()],</span>
                <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(),</span> <span class="p">()],</span>
                <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">dask</span><span class="o">=</span><span class="s2">&quot;parallelized&quot;</span><span class="p">,</span>
                <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span>
            <span class="p">)</span>

            <span class="n">forecast_prob</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">calculate_tercile_probabilities_bestfit</span><span class="p">,</span>
                <span class="n">forecast_expanded</span><span class="p">,</span>
                <span class="n">error_variance</span><span class="p">,</span>
                <span class="n">T1</span><span class="p">,</span>
                <span class="n">T2</span><span class="p">,</span>
                <span class="n">best_code_da</span><span class="p">,</span>
                <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;T&quot;</span><span class="p">,),</span> <span class="p">(),</span> <span class="p">(),</span> <span class="p">(),</span> <span class="p">()],</span>
                <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;probability&quot;</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">)],</span>
                <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">dask</span><span class="o">=</span><span class="s2">&quot;parallelized&quot;</span><span class="p">,</span>
                <span class="n">kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;dof&quot;</span><span class="p">:</span> <span class="n">dof</span><span class="p">},</span>
                <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>
                <span class="n">dask_gufunc_kwargs</span><span class="o">=</span><span class="p">{</span>
                    <span class="s2">&quot;output_sizes&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;probability&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">},</span>
                    <span class="s2">&quot;allow_rechunk&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                <span class="p">},</span>
            <span class="p">)</span>

        <span class="c1"># ---------- Nonparametric ----------</span>
        <span class="k">elif</span> <span class="n">dm</span> <span class="o">==</span> <span class="s2">&quot;nonparam&quot;</span><span class="p">:</span>
            <span class="n">error_samples</span> <span class="o">=</span> <span class="n">Predictant</span> <span class="o">-</span> <span class="n">hindcast_det</span>
            <span class="n">forecast_prob</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">calculate_tercile_probabilities_nonparametric</span><span class="p">,</span>
                <span class="n">forecast_expanded</span><span class="p">,</span>
                <span class="n">error_samples</span><span class="p">,</span>
                <span class="n">T1_emp</span><span class="p">,</span>
                <span class="n">T2_emp</span><span class="p">,</span>
                <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;T&quot;</span><span class="p">,),</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,),</span> <span class="p">(),</span> <span class="p">()],</span>
                <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;probability&quot;</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">)],</span>
                <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">dask</span><span class="o">=</span><span class="s2">&quot;parallelized&quot;</span><span class="p">,</span>
                <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>
                <span class="n">dask_gufunc_kwargs</span><span class="o">=</span><span class="p">{</span>
                    <span class="s2">&quot;output_sizes&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;probability&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">},</span>
                    <span class="s2">&quot;allow_rechunk&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                <span class="p">},</span>
            <span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid dist_method: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">dist_method</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">forecast_prob</span> <span class="o">=</span> <span class="n">forecast_prob</span><span class="o">.</span><span class="n">assign_coords</span><span class="p">(</span><span class="n">probability</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;probability&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;PB&#39;</span><span class="p">,</span> <span class="s1">&#39;PN&#39;</span><span class="p">,</span> <span class="s1">&#39;PA&#39;</span><span class="p">]))</span>
        <span class="k">return</span> <span class="n">forecast_expanded</span><span class="p">,</span> <span class="n">forecast_prob</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="s1">&#39;probability&#39;</span><span class="p">,</span> <span class="s1">&#39;T&#39;</span><span class="p">,</span> <span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">)</span></div>
</div>




<div class="viewcode-block" id="WAS_LogisticRegression_Model">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_LogisticRegression_Model">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">WAS_LogisticRegression_Model</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Logistic regression for tercile classification (0/1/2) with:</span>
<span class="sd">      1) compute_class(): build tercile classes</span>
<span class="sd">      2) clustering on a spatial statistic of predictand (default: climatological mean)</span>
<span class="sd">      3) hyperparameter optimization per cluster (via BaseOptimizer)</span>
<span class="sd">      4) broadcast best params to (Y,X)</span>
<span class="sd">      5) fit/predict per grid cell using the locally broadcast params</span>

<span class="sd">    Notes:</span>
<span class="sd">    - &quot;Scale y only&quot; does not apply here because y is categorical (0/1/2).</span>
<span class="sd">    - X scaling is OFF by default, but you can enable it (x_scaler=&#39;standard&#39; or &#39;robust&#39;).</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="WAS_LogisticRegression_Model.__init__">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_LogisticRegression_Model.__init__">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">nb_cores</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">dist_method</span><span class="o">=</span><span class="s2">&quot;nonparam&quot;</span><span class="p">,</span>
        <span class="n">n_clusters</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
        <span class="n">param_grid</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">optimization_method</span><span class="o">=</span><span class="s2">&quot;grid&quot;</span><span class="p">,</span>
        <span class="n">n_trials</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
        <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
        <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
        <span class="n">x_scaler</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>   <span class="c1"># None | &quot;standard&quot; | &quot;robust&quot;</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">nb_cores</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dist_method</span> <span class="o">=</span> <span class="n">dist_method</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_clusters</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimization_method</span> <span class="o">=</span> <span class="n">optimization_method</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_trials</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_trials</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cv</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">cv</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">random_state</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">x_scaler</span> <span class="o">=</span> <span class="n">x_scaler</span>

        <span class="c1"># Default search space (SAFE with multinomial + lbfgs: penalty must be &#39;l2&#39;)</span>
        
        <span class="k">if</span> <span class="n">param_grid</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s2">&quot;C&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">],</span>
                <span class="s2">&quot;class_weight&quot;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;balanced&quot;</span><span class="p">],</span>
                <span class="s2">&quot;max_iter&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">300</span><span class="p">,</span> <span class="mi">600</span><span class="p">,</span> <span class="mi">1000</span><span class="p">],</span>
                <span class="c1"># keep solver fixed to avoid invalid combos</span>
                <span class="s2">&quot;solver&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;lbfgs&quot;</span><span class="p">],</span>
            <span class="p">}</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">param_grid</span> <span class="o">=</span> <span class="n">param_grid</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">BaseOptimizer</span><span class="p">(</span>
            <span class="n">optimization_method</span><span class="o">=</span><span class="n">optimization_method</span><span class="p">,</span>
            <span class="n">n_trials</span><span class="o">=</span><span class="n">n_trials</span><span class="p">,</span>
            <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span>
            <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span>
        <span class="p">)</span>

        <span class="c1"># Encodings for broadcast arrays (avoid storing dict strings per cell)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_cw_map</span> <span class="o">=</span> <span class="p">{</span><span class="kc">None</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;balanced&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_cw_inv</span> <span class="o">=</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span> <span class="s2">&quot;balanced&quot;</span><span class="p">}</span></div>


    <span class="c1"># ------------------------------------------------------------------</span>
    <span class="c1"># 0) Helpers</span>
    <span class="c1"># ------------------------------------------------------------------</span>
<div class="viewcode-block" id="WAS_LogisticRegression_Model._safe_chunk_size">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_LogisticRegression_Model._safe_chunk_size">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">_safe_chunk_size</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">max</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">n</span> <span class="o">/</span> <span class="nb">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span><span class="p">,</span> <span class="mi">1</span><span class="p">))),</span> <span class="mi">1</span><span class="p">)</span></div>


<div class="viewcode-block" id="WAS_LogisticRegression_Model._make_estimator">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_LogisticRegression_Model._make_estimator">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">_make_estimator</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">class_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s2">&quot;lbfgs&quot;</span><span class="p">):</span>
        <span class="n">clf</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span>
            <span class="n">C</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="n">C</span><span class="p">),</span>
            <span class="n">class_weight</span><span class="o">=</span><span class="n">class_weight</span><span class="p">,</span>
            <span class="n">max_iter</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">max_iter</span><span class="p">),</span>
            <span class="n">solver</span><span class="o">=</span><span class="n">solver</span><span class="p">,</span>
            <span class="n">multi_class</span><span class="o">=</span><span class="s2">&quot;multinomial&quot;</span><span class="p">,</span>
            <span class="n">random_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">x_scaler</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">clf</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">x_scaler</span> <span class="o">==</span> <span class="s2">&quot;standard&quot;</span><span class="p">:</span>
            <span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">x_scaler</span> <span class="o">==</span> <span class="s2">&quot;robust&quot;</span><span class="p">:</span>
            <span class="n">scaler</span> <span class="o">=</span> <span class="n">RobustScaler</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;x_scaler must be one of {None, &#39;standard&#39;, &#39;robust&#39;}&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">Pipeline</span><span class="p">([(</span><span class="s2">&quot;scaler&quot;</span><span class="p">,</span> <span class="n">scaler</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;logit&quot;</span><span class="p">,</span> <span class="n">clf</span><span class="p">)])</span></div>


<div class="viewcode-block" id="WAS_LogisticRegression_Model._mode3_ignore_nan">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_LogisticRegression_Model._mode3_ignore_nan">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_mode3_ignore_nan</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return mode over {0,1,2} for a 1D array, ignoring NaN.&quot;&quot;&quot;</span>
        <span class="n">v</span> <span class="o">=</span> <span class="n">v</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">v</span><span class="p">)]</span>
        <span class="k">if</span> <span class="n">v</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
        <span class="n">v</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
        <span class="n">counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">minlength</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">counts</span><span class="p">))</span></div>


    <span class="c1"># ------------------------------------------------------------------</span>
    <span class="c1"># 1) Tercile classification</span>
    <span class="c1"># ------------------------------------------------------------------</span>
<div class="viewcode-block" id="WAS_LogisticRegression_Model.classify">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_LogisticRegression_Model.classify">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">classify</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">index_start</span><span class="p">,</span> <span class="n">index_end</span><span class="p">):</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">mask</span><span class="p">):</span>
            <span class="n">terciles</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nanpercentile</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="n">index_start</span><span class="p">:</span><span class="n">index_end</span><span class="p">],</span> <span class="p">[</span><span class="mi">33</span><span class="p">,</span> <span class="mi">67</span><span class="p">])</span>
            <span class="n">y_class</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">digitize</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="n">terciles</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># 0/1/2</span>
            <span class="k">return</span> <span class="n">y_class</span><span class="p">,</span> <span class="n">terciles</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">terciles</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span></div>


<div class="viewcode-block" id="WAS_LogisticRegression_Model.compute_class">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_LogisticRegression_Model.compute_class">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">compute_class</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Predictant</span><span class="p">:</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span><span class="p">,</span> <span class="n">clim_year_start</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">clim_year_end</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>

        <span class="n">index_start</span> <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">get_index</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">get_loc</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">clim_year_start</span><span class="p">))</span><span class="o">.</span><span class="n">start</span>
        <span class="n">index_end</span> <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">get_index</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">get_loc</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">clim_year_end</span><span class="p">))</span><span class="o">.</span><span class="n">stop</span>

        <span class="n">y_class</span><span class="p">,</span> <span class="n">terc33</span><span class="p">,</span> <span class="n">terc67</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">classify</span><span class="p">,</span>
            <span class="n">Predictant</span><span class="p">,</span>
            <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;T&quot;</span><span class="p">,)],</span>
            <span class="n">kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;index_start&quot;</span><span class="p">:</span> <span class="n">index_start</span><span class="p">,</span> <span class="s2">&quot;index_end&quot;</span><span class="p">:</span> <span class="n">index_end</span><span class="p">},</span>
            <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">dask</span><span class="o">=</span><span class="s2">&quot;parallelized&quot;</span><span class="p">,</span>
            <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;T&quot;</span><span class="p">,),</span> <span class="p">(),</span> <span class="p">()],</span>
            <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;float&quot;</span><span class="p">,</span> <span class="s2">&quot;float&quot;</span><span class="p">,</span> <span class="s2">&quot;float&quot;</span><span class="p">],</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">y_class</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="s2">&quot;Y&quot;</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">),</span> <span class="n">terc33</span><span class="p">,</span> <span class="n">terc67</span></div>


    <span class="c1"># ------------------------------------------------------------------</span>
    <span class="c1"># 2) Clustering (spatial) and HPO per cluster</span>
    <span class="c1"># ------------------------------------------------------------------</span>
<div class="viewcode-block" id="WAS_LogisticRegression_Model._build_cluster_map">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_LogisticRegression_Model._build_cluster_map">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">_build_cluster_map</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">predictand</span><span class="p">:</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        KMeans on a spatial statistic (default: climatological mean over T).</span>
<span class="sd">        Produces cluster_da with dims (Y,X) and NaN where predictand is NaN.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">field</span> <span class="o">=</span> <span class="n">predictand</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">skipna</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">vals</span> <span class="o">=</span> <span class="n">field</span><span class="o">.</span><span class="n">values</span>
        <span class="n">flat</span> <span class="o">=</span> <span class="n">vals</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">valid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">flat</span><span class="p">)</span>

        <span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">flat</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">valid</span><span class="p">):</span>
            <span class="n">km</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>
            <span class="n">labels_valid</span> <span class="o">=</span> <span class="n">km</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">flat</span><span class="p">[</span><span class="n">valid</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
            <span class="n">labels</span><span class="p">[</span><span class="n">valid</span><span class="p">]</span> <span class="o">=</span> <span class="n">labels_valid</span>

        <span class="n">cluster_2d</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">vals</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">cluster_da</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span><span class="p">(</span><span class="n">cluster_2d</span><span class="p">,</span> <span class="n">coords</span><span class="o">=</span><span class="n">field</span><span class="o">.</span><span class="n">coords</span><span class="p">,</span> <span class="n">dims</span><span class="o">=</span><span class="n">field</span><span class="o">.</span><span class="n">dims</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;cluster&quot;</span><span class="p">)</span>

        <span class="c1"># Ensure NaNs align with predictand mask</span>
        <span class="n">cluster_da</span> <span class="o">=</span> <span class="n">cluster_da</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">field</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">cluster_da</span></div>


<div class="viewcode-block" id="WAS_LogisticRegression_Model.compute_hyperparameters">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_LogisticRegression_Model.compute_hyperparameters">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">compute_hyperparameters</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">predictand</span><span class="p">:</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span><span class="p">,</span>
        <span class="n">predictor</span><span class="p">:</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span><span class="p">,</span>
        <span class="n">clim_year_start</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">clim_year_end</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">scoring</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;neg_log_loss&quot;</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns broadcast hyperparameter arrays + cluster map.</span>
<span class="sd">        </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">predictor</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">predictand</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span>
        <span class="c1"># (a) classify predictand into tercile classes</span>
        <span class="n">y_class</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_class</span><span class="p">(</span><span class="n">predictand</span><span class="p">,</span> <span class="n">clim_year_start</span><span class="p">,</span> <span class="n">clim_year_end</span><span class="p">)</span>

        <span class="c1"># (b) build clusters in space</span>
        <span class="n">cluster_da</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_build_cluster_map</span><span class="p">(</span><span class="n">predictand</span><span class="p">)</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">cluster_da</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">align</span><span class="p">(</span><span class="n">predictand</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">cluster_da</span><span class="p">,</span> <span class="n">join</span><span class="o">=</span><span class="s2">&quot;outer&quot;</span><span class="p">)</span>

        <span class="n">clusters</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">cluster_da</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
        <span class="n">clusters</span> <span class="o">=</span> <span class="n">clusters</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">clusters</span><span class="p">)]</span>

        <span class="n">best_params_for_cluster</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">clusters</span><span class="p">:</span>
            <span class="n">mask_c</span> <span class="o">=</span> <span class="p">(</span><span class="n">cluster_da</span> <span class="o">==</span> <span class="n">c</span><span class="p">)</span>

            <span class="c1"># Build a cluster-level time series label: spatial mode over (Y,X) at each T</span>
            <span class="n">y_stack</span> <span class="o">=</span> <span class="n">y_class</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">mask_c</span><span class="p">)</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">Z</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;Y&quot;</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">))</span>
            <span class="n">y_mode</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_mode3_ignore_nan</span><span class="p">,</span>
                <span class="n">y_stack</span><span class="p">,</span>
                <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;Z&quot;</span><span class="p">,)],</span>
                <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[()],</span>
                <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">dask</span><span class="o">=</span><span class="s2">&quot;parallelized&quot;</span><span class="p">,</span>
                <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;float&quot;</span><span class="p">],</span>
            <span class="p">)</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">y_mode</span><span class="o">.</span><span class="n">sizes</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">continue</span>

            <span class="c1"># Align predictors on the same times</span>
            <span class="n">X_c</span> <span class="o">=</span> <span class="n">predictor</span><span class="o">.</span><span class="n">sel</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="n">y_mode</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">])</span>
            <span class="n">X_mat</span> <span class="o">=</span> <span class="n">X_c</span><span class="o">.</span><span class="n">values</span>
            <span class="n">y_vec</span> <span class="o">=</span> <span class="n">y_mode</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

            <span class="c1"># Optimize hyperparameters for this cluster</span>
            <span class="n">base_est</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_estimator</span><span class="p">()</span>
            <span class="n">bp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span>
                <span class="n">base_est</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">param_grid</span><span class="p">,</span>
                <span class="n">X_mat</span><span class="p">,</span>
                <span class="n">y_vec</span><span class="p">,</span>
                <span class="n">scoring</span><span class="o">=</span><span class="n">scoring</span>
            <span class="p">)</span>
            <span class="n">best_params_for_cluster</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">c</span><span class="p">)]</span> <span class="o">=</span> <span class="n">bp</span>

        <span class="c1"># (c) broadcast best params to each (Y,X)</span>
        <span class="n">C_da</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">cluster_da</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
        <span class="n">cw_code_da</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">cluster_da</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
        <span class="n">maxiter_da</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">cluster_da</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
        <span class="n">solver_da</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">cluster_da</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">object</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">c</span><span class="p">,</span> <span class="n">bp</span> <span class="ow">in</span> <span class="n">best_params_for_cluster</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">c_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">cluster_da</span> <span class="o">==</span> <span class="n">c</span><span class="p">)</span>

            <span class="n">C_val</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">bp</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;C&quot;</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">))</span>
            <span class="n">cw_val</span> <span class="o">=</span> <span class="n">bp</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;class_weight&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="n">mi_val</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">bp</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;max_iter&quot;</span><span class="p">,</span> <span class="mi">500</span><span class="p">))</span>
            <span class="n">sv_val</span> <span class="o">=</span> <span class="n">bp</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;solver&quot;</span><span class="p">,</span> <span class="s2">&quot;lbfgs&quot;</span><span class="p">)</span>

            <span class="n">C_da</span> <span class="o">=</span> <span class="n">C_da</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="o">~</span><span class="n">c_mask</span><span class="p">,</span> <span class="n">other</span><span class="o">=</span><span class="n">C_val</span><span class="p">)</span>
            <span class="n">cw_code_da</span> <span class="o">=</span> <span class="n">cw_code_da</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="o">~</span><span class="n">c_mask</span><span class="p">,</span> <span class="n">other</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_cw_map</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">cw_val</span><span class="p">,</span> <span class="mi">0</span><span class="p">)))</span>
            <span class="n">maxiter_da</span> <span class="o">=</span> <span class="n">maxiter_da</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="o">~</span><span class="n">c_mask</span><span class="p">,</span> <span class="n">other</span><span class="o">=</span><span class="n">mi_val</span><span class="p">)</span>
            <span class="n">solver_da</span> <span class="o">=</span> <span class="n">solver_da</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="o">~</span><span class="n">c_mask</span><span class="p">,</span> <span class="n">other</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">sv_val</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">C_da</span><span class="p">,</span> <span class="n">cw_code_da</span><span class="p">,</span> <span class="n">maxiter_da</span><span class="p">,</span> <span class="n">solver_da</span><span class="p">,</span> <span class="n">cluster_da</span></div>


    <span class="c1"># ------------------------------------------------------------------</span>
    <span class="c1"># 3) Fit + predict at one grid cell using local/broadcast params</span>
    <span class="c1"># ------------------------------------------------------------------</span>
<div class="viewcode-block" id="WAS_LogisticRegression_Model.fit_predict">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_LogisticRegression_Model.fit_predict">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">fit_predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">cw_code</span><span class="p">,</span> <span class="n">max_iter</span><span class="p">,</span> <span class="n">solver</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Trains with local hyperparameters and returns proba for classes 0/1/2,</span>
<span class="sd">        correctly mapped via classes_ (fix vs positional padding). </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">C</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">cw_code</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">max_iter</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="mi">3</span><span class="p">,),</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>

        <span class="n">class_weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cw_inv</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">cw_code</span><span class="p">),</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">est</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_estimator</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="n">C</span><span class="p">,</span> <span class="n">class_weight</span><span class="o">=</span><span class="n">class_weight</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="n">max_iter</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">solver</span><span class="p">))</span>

        <span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">&amp;</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">mask</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="mi">3</span><span class="p">,),</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>

        <span class="n">x_c</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">mask</span><span class="p">,</span> <span class="p">:]</span>
        <span class="n">y_c</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

        <span class="n">uniq</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y_c</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">uniq</span><span class="o">.</span><span class="n">size</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
            <span class="n">out</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">uniq</span><span class="p">[</span><span class="mi">0</span><span class="p">])]</span> <span class="o">=</span> <span class="mf">1.0</span>
            <span class="k">return</span> <span class="n">out</span>

        <span class="n">est</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_c</span><span class="p">,</span> <span class="n">y_c</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">x_test</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">x_test</span> <span class="o">=</span> <span class="n">x_test</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">proba</span> <span class="o">=</span> <span class="n">est</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># classes_ location differs if pipeline is used</span>
        <span class="n">classes</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">est</span><span class="p">,</span> <span class="s2">&quot;classes_&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">classes</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">est</span><span class="p">,</span> <span class="n">Pipeline</span><span class="p">):</span>
            <span class="n">classes</span> <span class="o">=</span> <span class="n">est</span><span class="o">.</span><span class="n">named_steps</span><span class="p">[</span><span class="s2">&quot;logit&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">classes_</span>

        <span class="n">out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
        <span class="k">for</span> <span class="bp">cls</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">classes</span><span class="p">,</span> <span class="n">proba</span><span class="p">):</span>
            <span class="bp">cls</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">cls</span><span class="p">)</span>
            <span class="k">if</span> <span class="mi">0</span> <span class="o">&lt;=</span> <span class="bp">cls</span> <span class="o">&lt;=</span> <span class="mi">2</span><span class="p">:</span>
                <span class="n">out</span><span class="p">[</span><span class="bp">cls</span><span class="p">]</span> <span class="o">=</span> <span class="n">p</span>
        <span class="k">return</span> <span class="n">out</span></div>


    <span class="c1"># ------------------------------------------------------------------</span>
    <span class="c1"># 4) Parallel model over grid with local params</span>
    <span class="c1"># ------------------------------------------------------------------</span>
<div class="viewcode-block" id="WAS_LogisticRegression_Model.compute_model">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_LogisticRegression_Model.compute_model">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">compute_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">C_da</span><span class="p">,</span> <span class="n">cw_code_da</span><span class="p">,</span> <span class="n">maxiter_da</span><span class="p">,</span> <span class="n">solver_da</span><span class="p">):</span>
        <span class="n">chunksize_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_safe_chunk_size</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="o">.</span><span class="n">get_index</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">)))</span>
        <span class="n">chunksize_y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_safe_chunk_size</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="o">.</span><span class="n">get_index</span><span class="p">(</span><span class="s2">&quot;Y&quot;</span><span class="p">)))</span>

        <span class="n">X_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">X_train</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">]</span>
        <span class="n">y_train</span> <span class="o">=</span> <span class="n">y_train</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="s2">&quot;Y&quot;</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">)</span>

        <span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="s2">&quot;features&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>

        <span class="n">client</span> <span class="o">=</span> <span class="n">Client</span><span class="p">(</span><span class="n">n_workers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span><span class="p">,</span> <span class="n">threads_per_worker</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">,</span>
                <span class="n">X_train</span><span class="p">,</span>
                <span class="n">y_train</span><span class="o">.</span><span class="n">chunk</span><span class="p">({</span><span class="s2">&quot;Y&quot;</span><span class="p">:</span> <span class="n">chunksize_y</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">:</span> <span class="n">chunksize_x</span><span class="p">}),</span>
                <span class="n">X_test</span><span class="p">,</span>
                <span class="n">C_da</span><span class="p">,</span>
                <span class="n">cw_code_da</span><span class="p">,</span>
                <span class="n">maxiter_da</span><span class="p">,</span>
                <span class="n">solver_da</span><span class="p">,</span>
                <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="s2">&quot;features&quot;</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,),</span> <span class="p">(</span><span class="s2">&quot;features&quot;</span><span class="p">,),</span> <span class="p">(),</span> <span class="p">(),</span> <span class="p">(),</span> <span class="p">()],</span>
                <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;probability&quot;</span><span class="p">,)],</span>
                <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">dask</span><span class="o">=</span><span class="s2">&quot;parallelized&quot;</span><span class="p">,</span>
                <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;float&quot;</span><span class="p">],</span>
                <span class="n">dask_gufunc_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;output_sizes&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;probability&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">}},</span>
            <span class="p">)</span>
            <span class="n">result_</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="s2">&quot;compute&quot;</span><span class="p">)</span> <span class="k">else</span> <span class="n">result</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">client</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">client</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

        <span class="n">result_</span> <span class="o">=</span> <span class="n">result_</span><span class="o">.</span><span class="n">assign_coords</span><span class="p">(</span><span class="n">probability</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;probability&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;PB&quot;</span><span class="p">,</span> <span class="s2">&quot;PN&quot;</span><span class="p">,</span> <span class="s2">&quot;PA&quot;</span><span class="p">]))</span>
        <span class="k">return</span> <span class="n">result_</span></div>


    <span class="c1"># ------------------------------------------------------------------</span>
    <span class="c1"># 5) Forecast (end-to-end): compute classes -&gt; HPO -&gt; local fit/predict</span>
    <span class="c1"># ------------------------------------------------------------------</span>
<div class="viewcode-block" id="WAS_LogisticRegression_Model.forecast">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_LogisticRegression_Model.forecast">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">forecast</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">Predictant</span><span class="p">:</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span><span class="p">,</span>
        <span class="n">clim_year_start</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">clim_year_end</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">Predictor</span><span class="p">:</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span><span class="p">,</span>
        <span class="n">Predictor_for_year</span><span class="p">:</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span><span class="p">,</span>
        <span class="n">C_da</span><span class="p">,</span> <span class="n">cw_code_da</span><span class="p">,</span> <span class="n">maxiter_da</span><span class="p">,</span> <span class="n">solver_da</span>
    <span class="p">):</span>
        <span class="c1"># 1) classify predictand</span>
        <span class="n">y_class</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_class</span><span class="p">(</span><span class="n">Predictant</span><span class="p">,</span> <span class="n">clim_year_start</span><span class="p">,</span> <span class="n">clim_year_end</span><span class="p">)</span>

        <span class="c1"># 3) align T for training predictors</span>
        <span class="n">Predictor</span> <span class="o">=</span> <span class="n">Predictor</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">Predictor</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_class</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">]</span>

        <span class="c1"># 4) ensure forecast predictor has T</span>
        <span class="n">X_test</span> <span class="o">=</span> <span class="n">Predictor_for_year</span>
        <span class="k">if</span> <span class="s2">&quot;T&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">X_test</span><span class="o">.</span><span class="n">dims</span><span class="p">:</span>
            <span class="k">if</span> <span class="s2">&quot;T&quot;</span> <span class="ow">in</span> <span class="n">Predictor_for_year</span><span class="o">.</span><span class="n">coords</span> <span class="ow">and</span> <span class="n">Predictor_for_year</span><span class="o">.</span><span class="n">coords</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">t0</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Timestamp</span><span class="p">(</span><span class="n">Predictor_for_year</span><span class="o">.</span><span class="n">coords</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">to_datetime64</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">t0</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Timestamp</span><span class="p">(</span><span class="n">Predictor</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">to_datetime64</span><span class="p">()</span>
            <span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="p">[</span><span class="n">t0</span><span class="p">])</span>
        
        <span class="n">client</span> <span class="o">=</span> <span class="n">Client</span><span class="p">(</span><span class="n">n_workers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span><span class="p">,</span> <span class="n">threads_per_worker</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">proba</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">,</span>
                <span class="n">Predictor</span><span class="p">,</span>
                <span class="n">y_class</span><span class="o">.</span><span class="n">chunk</span><span class="p">({</span><span class="s2">&quot;Y&quot;</span><span class="p">:</span> <span class="n">chunksize_y</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">:</span> <span class="n">chunksize_x</span><span class="p">}),</span>
                <span class="n">X_test</span><span class="p">,</span>
                <span class="n">C_da</span><span class="p">,</span>
                <span class="n">cw_code_da</span><span class="p">,</span>
                <span class="n">maxiter_da</span><span class="p">,</span>
                <span class="n">solver_da</span><span class="p">,</span>
                <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="s2">&quot;features&quot;</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,),</span> <span class="p">(</span><span class="s2">&quot;features&quot;</span><span class="p">,),</span> <span class="p">(),</span> <span class="p">(),</span> <span class="p">(),</span> <span class="p">()],</span>
                <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;probability&quot;</span><span class="p">,)],</span>
                <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">dask</span><span class="o">=</span><span class="s2">&quot;parallelized&quot;</span><span class="p">,</span>
                <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;float&quot;</span><span class="p">],</span>
                <span class="n">dask_gufunc_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;output_sizes&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;probability&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">}},</span>
            <span class="p">)</span>
            <span class="n">proba_</span> <span class="o">=</span> <span class="n">proba</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">proba</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="s2">&quot;compute&quot;</span><span class="p">)</span> <span class="k">else</span> <span class="n">proba</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">client</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">client</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

        <span class="c1"># keep time dim for single forecast (T=1)</span>
        <span class="k">if</span> <span class="s2">&quot;T&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">proba</span><span class="o">.</span><span class="n">dims</span><span class="p">:</span>
            <span class="n">proba_</span> <span class="o">=</span> <span class="n">proba_</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="n">X_test</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">proba_</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="s2">&quot;probability&quot;</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="s2">&quot;Y&quot;</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">)</span></div>
</div>



<div class="viewcode-block" id="WAS_PolynomialRegression">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_PolynomialRegression">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">WAS_PolynomialRegression</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A class to perform Polynomial Regression on spatiotemporal datasets for climate prediction.</span>

<span class="sd">    This class is designed to work with Dask and Xarray for parallelized, high-performance </span>
<span class="sd">    regression computations across large datasets with spatial and temporal dimensions. The primary </span>
<span class="sd">    methods are for fitting the polynomial regression model, making predictions, and calculating </span>
<span class="sd">    probabilistic predictions for climate terciles.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    nb_cores : int, optional</span>
<span class="sd">        The number of CPU cores to use for parallel computation (default is 1).</span>
<span class="sd">    degree : int, optional</span>
<span class="sd">        The degree of the polynomial (default is 2).</span>
<span class="sd">    dist_method : str, optional</span>
<span class="sd">        The distribution method to compute tercile probabilities. One of </span>
<span class="sd">        {&quot;t&quot;, &quot;gamma&quot;, &quot;normal&quot;, &quot;lognormal&quot;, &quot;nonparam&quot;} (default is &quot;gamma&quot;).</span>

<span class="sd">    Methods</span>
<span class="sd">    -------</span>
<span class="sd">    fit_predict(x, y, x_test, y_test)</span>
<span class="sd">        Fits a Polynomial Regression model to the training data, predicts on test data, </span>
<span class="sd">        and computes error.</span>
<span class="sd">    compute_model(X_train, y_train, X_test, y_test)</span>
<span class="sd">        Applies the Polynomial Regression model across a dataset using parallel computation </span>
<span class="sd">        with Dask, returning predictions and error metrics.</span>
<span class="sd">    compute_prob(Predictant, clim_year_start, clim_year_end, Predictor, hindcast_det)</span>
<span class="sd">        Computes tercile probabilities for hindcast rainfall predictions </span>
<span class="sd">        over specified climatological years.</span>
<span class="sd">    forecast(Predictant, clim_year_start, clim_year_end, Predictor, hindcast_det, Predictor_for_year)</span>
<span class="sd">        Generates a forecast for a single year (or time step) and calculates tercile probabilities </span>
<span class="sd">        using the chosen distribution method.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="WAS_PolynomialRegression.__init__">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_PolynomialRegression.__init__">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nb_cores</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">degree</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dist_method</span><span class="o">=</span><span class="s2">&quot;nonparam&quot;</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initializes the WAS_PolynomialRegression with a specified number of CPU cores and polynomial degree.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        nb_cores : int, optional</span>
<span class="sd">            Number of CPU cores to use for parallel computation, by default 1.</span>
<span class="sd">        degree : int, optional</span>
<span class="sd">            The degree of the polynomial, by default 2.</span>
<span class="sd">        dist_method : str, optional</span>
<span class="sd">            The method to compute tercile probabilities (&quot;t&quot;, &quot;gamma&quot;, &quot;normal&quot;, &quot;lognormal&quot;, &quot;nonparam&quot;), </span>
<span class="sd">            by default &quot;gamma&quot;.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span> <span class="o">=</span> <span class="n">nb_cores</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">=</span> <span class="n">degree</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dist_method</span> <span class="o">=</span> <span class="n">dist_method</span></div>


<div class="viewcode-block" id="WAS_PolynomialRegression.fit_predict">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_PolynomialRegression.fit_predict">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">fit_predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fits a Polynomial Regression model to the provided training data, makes predictions </span>
<span class="sd">        on the test data, and calculates the prediction error.</span>
<span class="sd">.</span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        x : array-like, shape (n_samples, n_features)</span>
<span class="sd">            Training data (predictors).</span>
<span class="sd">        y : array-like, shape (n_samples,)</span>
<span class="sd">            Training targets.</span>
<span class="sd">        x_test : array-like, shape (n_features,) or (1, n_features)</span>
<span class="sd">            Test data (predictors) for which we want predictions.</span>
<span class="sd">        y_test : float</span>
<span class="sd">            Test target value (for computing error).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        np.ndarray of shape (2,)</span>
<span class="sd">            Array containing [prediction_error, predicted_value].</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Create a PolynomialFeatures transformer for the specified degree</span>
        <span class="n">poly</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="p">)</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>

        <span class="c1"># Identify valid (finite) samples</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">&amp;</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="c1"># If we have at least one valid sample, we can train a model</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">mask</span><span class="p">):</span>
            <span class="n">y_clean</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>
            <span class="n">x_clean</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">mask</span><span class="p">,</span> <span class="p">:]</span>

            <span class="c1"># Transform x_clean into polynomial feature space</span>
            <span class="n">x_clean_poly</span> <span class="o">=</span> <span class="n">poly</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">x_clean</span><span class="p">)</span>
            <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_clean_poly</span><span class="p">,</span> <span class="n">y_clean</span><span class="p">)</span>

            <span class="c1"># Reshape x_test if needed and transform it</span>
            <span class="k">if</span> <span class="n">x_test</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">x_test</span> <span class="o">=</span> <span class="n">x_test</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">x_test_poly</span> <span class="o">=</span> <span class="n">poly</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>

            <span class="c1"># Make predictions</span>
            <span class="n">preds</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test_poly</span><span class="p">)</span>

            <span class="n">preds</span><span class="p">[</span><span class="n">preds</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="c1"># Compute prediction error</span>
            <span class="n">error_</span> <span class="o">=</span> <span class="n">y_test</span> <span class="o">-</span> <span class="n">preds</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">error_</span><span class="p">,</span> <span class="n">preds</span><span class="p">])</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># If no valid data, return NaNs</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">])</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span></div>


<div class="viewcode-block" id="WAS_PolynomialRegression.compute_model">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_PolynomialRegression.compute_model">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">compute_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes predictions for spatiotemporal data using Polynomial Regression with parallel processing.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X_train : xarray.DataArray</span>
<span class="sd">            Training data (predictors) with dimensions (T, features).</span>
<span class="sd">            (It must be chunked properly in Dask, or at least be amenable to chunking.)</span>
<span class="sd">        y_train : xarray.DataArray</span>
<span class="sd">            Training target values with dimensions (T, Y, X).</span>
<span class="sd">        X_test : xarray.DataArray</span>
<span class="sd">            Test data (predictors) with dimensions (features,) or (T, features).</span>
<span class="sd">            Typically, you&#39;d match time steps or have a single test.</span>
<span class="sd">        y_test : xarray.DataArray</span>
<span class="sd">            Test target values with dimensions (Y, X) or broadcastable to (T, Y, X).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        xarray.DataArray</span>
<span class="sd">            An array with shape (2, Y, X) after computing, where the first index </span>
<span class="sd">            is error and the second is the prediction.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Determine chunk sizes so each worker handles a portion of the spatial domain</span>
        <span class="n">chunksize_x</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="o">.</span><span class="n">get_index</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">))</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span><span class="p">))</span>
        <span class="n">chunksize_y</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="o">.</span><span class="n">get_index</span><span class="p">(</span><span class="s2">&quot;Y&quot;</span><span class="p">))</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span><span class="p">))</span>

        <span class="c1"># Align time dimension: we want X_train and y_train to have the same &#39;T&#39;</span>
        <span class="c1"># (We assume X_train has dimension (T, features) and y_train has dimension (T, Y, X))</span>
        <span class="n">X_train</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span>
        <span class="n">y_train</span> <span class="o">=</span> <span class="n">y_train</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="s1">&#39;T&#39;</span><span class="p">,</span> <span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">)</span>

        <span class="c1"># Squeeze X_test (if it has extra dims)</span>
        <span class="c1"># Usually, X_test would be (features,) or (T, features)</span>
        <span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>

        <span class="c1"># y_test might have shape (Y, X) or (T, Y, X). </span>
        <span class="c1"># If it&#39;s purely spatial, no &#39;T&#39; dimension. We remove it if present.</span>
        <span class="k">if</span> <span class="s1">&#39;T&#39;</span> <span class="ow">in</span> <span class="n">y_test</span><span class="o">.</span><span class="n">dims</span><span class="p">:</span>
            <span class="n">y_test</span> <span class="o">=</span> <span class="n">y_test</span><span class="o">.</span><span class="n">drop_vars</span><span class="p">(</span><span class="s1">&#39;T&#39;</span><span class="p">)</span>
        <span class="n">y_test</span> <span class="o">=</span> <span class="n">y_test</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">)</span>

        <span class="c1"># Create a Dask client for parallel processing</span>
        <span class="n">client</span> <span class="o">=</span> <span class="n">Client</span><span class="p">(</span><span class="n">n_workers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span><span class="p">,</span> <span class="n">threads_per_worker</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Apply `fit_predict` across each (Y,X) grid cell in parallel.</span>
        
        <span class="n">result</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">,</span>
            <span class="n">X_train</span><span class="p">,</span>                                   <span class="c1"># shape (T, features)</span>
            <span class="n">y_train</span><span class="o">.</span><span class="n">chunk</span><span class="p">({</span><span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">chunksize_y</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">chunksize_x</span><span class="p">}),</span>
            <span class="n">X_test</span><span class="p">,</span>
            <span class="n">y_test</span><span class="o">.</span><span class="n">chunk</span><span class="p">({</span><span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">chunksize_y</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">chunksize_x</span><span class="p">}),</span>
            <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s1">&#39;T&#39;</span><span class="p">,</span> <span class="s1">&#39;features&#39;</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;T&#39;</span><span class="p">,),</span> <span class="p">(</span><span class="s1">&#39;features&#39;</span><span class="p">,),</span> <span class="p">()],</span>
            <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s1">&#39;output&#39;</span><span class="p">,)],</span>           <span class="c1"># We&#39;ll have a new dim &#39;output&#39; of size 2</span>
            <span class="n">dask</span><span class="o">=</span><span class="s1">&#39;parallelized&#39;</span><span class="p">,</span>
            <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;float&#39;</span><span class="p">],</span>
            <span class="n">dask_gufunc_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;output_sizes&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;output&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">}},</span>
        <span class="p">)</span>

        <span class="c1"># Trigger computation</span>
        <span class="n">result_</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
        <span class="n">client</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

        <span class="c1"># Return an xarray.DataArray with dimension &#39;output&#39; of size 2: [error, prediction]</span>
        <span class="k">return</span> <span class="n">result_</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">output</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></div>


    <span class="c1"># ------------------ Probability Calculation Methods ------------------</span>

<div class="viewcode-block" id="WAS_PolynomialRegression._ppf_terciles_from_code">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_PolynomialRegression._ppf_terciles_from_code">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_ppf_terciles_from_code</span><span class="p">(</span><span class="n">dist_code</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return tercile thresholds (T1, T2) from best-fit distribution parameters.</span>
<span class="sd">    </span>
<span class="sd">        dist_code:</span>
<span class="sd">            1: norm</span>
<span class="sd">            2: lognorm</span>
<span class="sd">            3: expon</span>
<span class="sd">            4: gamma</span>
<span class="sd">            5: weibull_min</span>
<span class="sd">            6: t</span>
<span class="sd">            7: poisson</span>
<span class="sd">            8: nbinom</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">dist_code</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
    
        <span class="n">code</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">dist_code</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                    <span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">lognorm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                    <span class="n">lognorm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">expon</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                    <span class="n">expon</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">gamma</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                    <span class="n">gamma</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">5</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">weibull_min</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                    <span class="n">weibull_min</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">6</span><span class="p">:</span>
                <span class="c1"># Note: Renamed &#39;t_dist&#39; to &#39;t&#39; for standard scipy.stats</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">t</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                    <span class="n">t</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">7</span><span class="p">:</span>
                <span class="c1"># Poisson: poisson.ppf(q, mu, loc=0)</span>
                <span class="c1"># ASSUMPTION: &#39;mu&#39; (mean) is passed as &#39;shape&#39;</span>
                <span class="c1">#             &#39;loc&#39; is passed as &#39;loc&#39;</span>
                <span class="c1">#             &#39;scale&#39; is unused</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">poisson</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">),</span>
                    <span class="n">poisson</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">8</span><span class="p">:</span>
                <span class="c1"># Negative Binomial: nbinom.ppf(q, n, p, loc=0)</span>
                <span class="c1"># ASSUMPTION: &#39;n&#39; (successes) is passed as &#39;shape&#39;</span>
                <span class="c1">#             &#39;p&#39; (probability) is passed as &#39;scale&#39;</span>
                <span class="c1">#             &#39;loc&#39; is passed as &#39;loc&#39;</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">nbinom</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">scale</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">),</span>
                    <span class="n">nbinom</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">scale</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">),</span>
                <span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
    
        <span class="c1"># Fallback if code is not 1-8</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span></div>

        
<div class="viewcode-block" id="WAS_PolynomialRegression.weibull_shape_solver">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_PolynomialRegression.weibull_shape_solver">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">weibull_shape_solver</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">V</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Function to find the root of the Weibull shape parameter &#39;k&#39;.</span>
<span class="sd">        We find &#39;k&#39; such that the theoretical variance/mean^2 ratio</span>
<span class="sd">        matches the observed V/M^2 ratio.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Guard against invalid &#39;k&#39; values during solving</span>
        <span class="k">if</span> <span class="n">k</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">g1</span> <span class="o">=</span> <span class="n">gamma_function</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="mi">1</span><span class="o">/</span><span class="n">k</span><span class="p">)</span>
            <span class="n">g2</span> <span class="o">=</span> <span class="n">gamma_function</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="mi">2</span><span class="o">/</span><span class="n">k</span><span class="p">)</span>
            
            <span class="c1"># This is the V/M^2 ratio *implied by k*</span>
            <span class="n">implied_v_over_m_sq</span> <span class="o">=</span> <span class="p">(</span><span class="n">g2</span> <span class="o">/</span> <span class="p">(</span><span class="n">g1</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span> <span class="o">-</span> <span class="mi">1</span>
            
            <span class="c1"># This is the *observed* ratio</span>
            <span class="n">observed_v_over_m_sq</span> <span class="o">=</span> <span class="n">V</span> <span class="o">/</span> <span class="p">(</span><span class="n">M</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
            
            <span class="c1"># Return the difference (we want this to be 0)</span>
            <span class="k">return</span> <span class="n">observed_v_over_m_sq</span> <span class="o">-</span> <span class="n">implied_v_over_m_sq</span>
        <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
            <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span> <span class="c1"># Handle math errors</span></div>


<div class="viewcode-block" id="WAS_PolynomialRegression.calculate_tercile_probabilities_bestfit">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_PolynomialRegression.calculate_tercile_probabilities_bestfit">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">calculate_tercile_probabilities_bestfit</span><span class="p">(</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">error_variance</span><span class="p">,</span> <span class="n">T1</span><span class="p">,</span> <span class="n">T2</span><span class="p">,</span> <span class="n">dist_code</span><span class="p">,</span> <span class="n">dof</span> 
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generic tercile probabilities using best-fit family per grid cell.</span>

<span class="sd">        Inputs (per grid cell):</span>
<span class="sd">        - best_guess : 1D array over T (hindcast_det or forecast_det)</span>
<span class="sd">        - T1, T2     : scalar terciles from climatological best-fit distribution</span>
<span class="sd">        - dist_code  : int, as in _ppf_terciles_from_code</span>
<span class="sd">        - shape, loc, scale : scalars from climatology fit</span>

<span class="sd">        Strategy:</span>
<span class="sd">        - For each time step, build a predictive distribution of the same family:</span>
<span class="sd">            * Use best_guess[t] to adjust mean / location;</span>
<span class="sd">            * Keep shape parameters from climatology.</span>
<span class="sd">        - Then compute probabilities:</span>
<span class="sd">            P(B) = F(T1), P(N) = F(T2) - F(T1), P(A) = 1 - F(T2).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        
        <span class="n">best_guess</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">best_guess</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span>
        <span class="n">error_variance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">error_variance</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
        <span class="c1"># T1 = np.asarray(T1, dtype=float)</span>
        <span class="c1"># T2 = np.asarray(T2, dtype=float)</span>
        <span class="n">n_time</span> <span class="o">=</span> <span class="n">best_guess</span><span class="o">.</span><span class="n">size</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="n">n_time</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">best_guess</span><span class="p">))</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">dist_code</span><span class="p">)</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">T1</span><span class="p">)</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">T2</span><span class="p">)</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">error_variance</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">out</span>

        <span class="n">code</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">dist_code</span><span class="p">)</span>

        <span class="c1"># Normal: loc = forecast; scale from clim</span>
        <span class="k">if</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">error_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">error_variance</span><span class="p">)</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">error_std</span><span class="p">)</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">error_std</span><span class="p">)</span> <span class="o">-</span> <span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">error_std</span><span class="p">)</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">error_std</span><span class="p">)</span>

        <span class="c1"># Lognormal: shape = sigma from clim; enforce mean = best_guess</span>
        <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">sigma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">error_variance</span> <span class="o">/</span> <span class="p">(</span><span class="n">best_guess</span><span class="o">**</span><span class="mi">2</span><span class="p">)))</span>
            <span class="n">mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">best_guess</span><span class="p">)</span> <span class="o">-</span> <span class="n">sigma</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="mi">2</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">lognorm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">mu</span><span class="p">))</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">lognorm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">mu</span><span class="p">))</span> <span class="o">-</span> <span class="n">lognorm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">mu</span><span class="p">))</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">lognorm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">mu</span><span class="p">))</span>      


        <span class="c1"># Exponential: keep scale from clim; shift loc so mean = best_guess</span>
        <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
            <span class="n">c1</span> <span class="o">=</span> <span class="n">expon</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">error_variance</span><span class="p">))</span>
            <span class="n">c2</span> <span class="o">=</span> <span class="n">expon</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc_t</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">error_variance</span><span class="p">))</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c2</span> <span class="o">-</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">c2</span>

        <span class="c1"># Gamma: use shape from clim; set scale so mean = best_guess</span>
        <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
            <span class="n">alpha</span> <span class="o">=</span> <span class="p">(</span><span class="n">best_guess</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="n">error_variance</span>
            <span class="n">theta</span> <span class="o">=</span> <span class="n">error_variance</span> <span class="o">/</span> <span class="n">best_guess</span>
            <span class="n">c1</span> <span class="o">=</span> <span class="n">gamma</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">theta</span><span class="p">)</span>
            <span class="n">c2</span> <span class="o">=</span> <span class="n">gamma</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">theta</span><span class="p">)</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c2</span> <span class="o">-</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">c2</span>

        <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">5</span><span class="p">:</span> <span class="c1"># Assuming 5 is for Weibull   </span>
        
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_time</span><span class="p">):</span>
                <span class="c1"># Get the scalar values for this specific element (e.g., grid cell)</span>
                <span class="n">M</span> <span class="o">=</span> <span class="n">best_guess</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">M</span><span class="p">)</span>
                <span class="n">V</span> <span class="o">=</span> <span class="n">error_variance</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">V</span><span class="p">)</span>
                
                <span class="c1"># Handle cases with no variance to avoid division by zero</span>
                <span class="k">if</span> <span class="n">V</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">M</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                    <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                    <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                    <span class="k">continue</span> <span class="c1"># Skip to the next element</span>
        
                <span class="c1"># --- 1. Numerically solve for shape &#39;k&#39; ---</span>
                <span class="c1"># We need a reasonable starting guess. 2.0 is common (Rayleigh dist.)</span>
                <span class="n">initial_guess</span> <span class="o">=</span> <span class="mf">2.0</span>
                
                <span class="c1"># fsolve finds the root of our helper function</span>
                <span class="n">k</span> <span class="o">=</span> <span class="n">fsolve</span><span class="p">(</span><span class="n">weibull_shape_solver</span><span class="p">,</span> <span class="n">initial_guess</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">V</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>
        
                <span class="c1"># --- 2. Check for bad solution and calculate scale &#39;lambda&#39; ---</span>
                <span class="k">if</span> <span class="n">k</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="c1"># Solver failed</span>
                    <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                    <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                    <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                    <span class="k">continue</span>
                
                <span class="c1"># With &#39;k&#39; found, we can now algebraically find scale &#39;lambda&#39;</span>
                <span class="c1"># In scipy.stats, scale is &#39;scale&#39;</span>
                <span class="n">lambda_scale</span> <span class="o">=</span> <span class="n">M</span> <span class="o">/</span> <span class="n">gamma_function</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="mi">1</span><span class="o">/</span><span class="n">k</span><span class="p">)</span>
        
                <span class="c1"># --- 3. Calculate Probabilities ---</span>
                <span class="c1"># In scipy.stats, shape &#39;k&#39; is &#39;c&#39;</span>
                <span class="c1"># Use the T1 and T2 values for this specific element</span>
                
                <span class="n">c1</span> <span class="o">=</span> <span class="n">weibull_min</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">lambda_scale</span><span class="p">)</span>
                <span class="n">c2</span> <span class="o">=</span> <span class="n">weibull_min</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">lambda_scale</span><span class="p">)</span>
        
                <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">c1</span>
                <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">c2</span> <span class="o">-</span> <span class="n">c1</span>
                <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">c2</span>

        <span class="c1"># Student-t: df from clim; scale from clim; loc = best_guess</span>
        <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">6</span><span class="p">:</span>       
            <span class="c1"># Check if df is valid for variance calculation</span>
            <span class="k">if</span> <span class="n">dof</span> <span class="o">&lt;=</span> <span class="mi">2</span><span class="p">:</span>
                <span class="c1"># Cannot calculate scale, fill with NaNs</span>
                <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># 1. Calculate t-distribution parameters</span>
                <span class="c1"># &#39;loc&#39; (mean) is just the best_guess</span>
                <span class="n">loc</span> <span class="o">=</span> <span class="n">best_guess</span>
                <span class="c1"># &#39;scale&#39; is calculated from the variance and df</span>
                <span class="c1"># Variance = scale**2 * (df / (df - 2))</span>
                <span class="n">scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">error_variance</span> <span class="o">*</span> <span class="p">(</span><span class="n">dof</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="n">dof</span><span class="p">)</span>
                
                <span class="c1"># 2. Calculate probabilities</span>
                <span class="n">c1</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">dof</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">)</span>
                <span class="n">c2</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">dof</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">)</span>

                <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c1</span>
                <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c2</span> <span class="o">-</span> <span class="n">c1</span>
                <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">c2</span>

        <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">7</span><span class="p">:</span> <span class="c1"># Assuming 7 is for Poisson</span>
            
            <span class="c1"># --- 1. Set the Poisson parameter &#39;mu&#39; ---</span>
            <span class="c1"># The &#39;mu&#39; parameter is the mean.</span>
            
            <span class="c1"># A warning is strongly recommended if error_variance is different from best_guess</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">error_variance</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Warning: &#39;error_variance&#39; is not equal to &#39;best_guess&#39;.&quot;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Poisson model assumes mean=variance and is likely inappropriate.&quot;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Consider using Negative Binomial.&quot;</span><span class="p">)</span>
            
            <span class="n">mu</span> <span class="o">=</span> <span class="n">best_guess</span>
        
            <span class="c1"># --- 2. Calculate Probabilities ---</span>
            <span class="c1"># poisson.cdf(k, mu) calculates P(X &lt;= k)</span>
            
            <span class="n">c1</span> <span class="o">=</span> <span class="n">poisson</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">mu</span><span class="p">)</span>
            <span class="n">c2</span> <span class="o">=</span> <span class="n">poisson</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">mu</span><span class="p">)</span>
            
            <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c2</span> <span class="o">-</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">c2</span>

        <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">8</span><span class="p">:</span> <span class="c1"># Assuming 8 is for Negative Binomial</span>
            
            <span class="c1"># --- 1. Calculate Negative Binomial Parameters ---</span>
            <span class="c1"># This model is ONLY valid for overdispersion (Variance &gt; Mean).</span>
            <span class="c1"># We will use np.where to set parameters to NaN if V &lt;= M.</span>
            
            <span class="c1"># p = Mean / Variance</span>
            <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">error_variance</span> <span class="o">&gt;</span> <span class="n">best_guess</span><span class="p">,</span> 
                         <span class="n">best_guess</span> <span class="o">/</span> <span class="n">error_variance</span><span class="p">,</span> 
                         <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
            
            <span class="c1"># n = Mean^2 / (Variance - Mean)</span>
            <span class="n">n</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">error_variance</span> <span class="o">&gt;</span> <span class="n">best_guess</span><span class="p">,</span> 
                         <span class="p">(</span><span class="n">best_guess</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">error_variance</span> <span class="o">-</span> <span class="n">best_guess</span><span class="p">),</span> 
                         <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
            
            <span class="c1"># --- 2. Calculate Probabilities ---</span>
            <span class="c1"># The nbinom.cdf function will propagate NaNs, correctly</span>
            <span class="c1"># handling the cases where the model was invalid.</span>
            
            <span class="n">c1</span> <span class="o">=</span> <span class="n">nbinom</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">)</span>
            <span class="n">c2</span> <span class="o">=</span> <span class="n">nbinom</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">)</span>
            
            <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c2</span> <span class="o">-</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">c2</span>
            
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid distribution&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">out</span></div>


<div class="viewcode-block" id="WAS_PolynomialRegression.calculate_tercile_probabilities_nonparametric">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_PolynomialRegression.calculate_tercile_probabilities_nonparametric">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">calculate_tercile_probabilities_nonparametric</span><span class="p">(</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">error_samples</span><span class="p">,</span> <span class="n">first_tercile</span><span class="p">,</span> <span class="n">second_tercile</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Non-parametric method using historical error samples.&quot;&quot;&quot;</span>
        <span class="n">n_time</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">best_guess</span><span class="p">)</span>
        <span class="n">pred_prob</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="n">n_time</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_time</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">best_guess</span><span class="p">[</span><span class="n">t</span><span class="p">]):</span>
                <span class="k">continue</span>
            <span class="n">dist</span> <span class="o">=</span> <span class="n">best_guess</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">+</span> <span class="n">error_samples</span>
            <span class="n">dist</span> <span class="o">=</span> <span class="n">dist</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">dist</span><span class="p">)]</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">dist</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="n">p_below</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dist</span> <span class="o">&lt;</span> <span class="n">first_tercile</span><span class="p">)</span>
            <span class="n">p_between</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">dist</span> <span class="o">&gt;=</span> <span class="n">first_tercile</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">dist</span> <span class="o">&lt;</span> <span class="n">second_tercile</span><span class="p">))</span>
            <span class="n">p_above</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="p">(</span><span class="n">p_below</span> <span class="o">+</span> <span class="n">p_between</span><span class="p">)</span>
            <span class="n">pred_prob</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">p_below</span>
            <span class="n">pred_prob</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">p_between</span>
            <span class="n">pred_prob</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">p_above</span>
        <span class="k">return</span> <span class="n">pred_prob</span></div>




<div class="viewcode-block" id="WAS_PolynomialRegression.compute_prob">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_PolynomialRegression.compute_prob">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">compute_prob</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">Predictant</span><span class="p">:</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span><span class="p">,</span>
        <span class="n">clim_year_start</span><span class="p">,</span>
        <span class="n">clim_year_end</span><span class="p">,</span>
        <span class="n">hindcast_det</span><span class="p">:</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span><span class="p">,</span>
        <span class="n">best_code_da</span><span class="p">:</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">best_shape_da</span><span class="p">:</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">best_loc_da</span><span class="p">:</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">best_scale_da</span><span class="p">:</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute tercile probabilities for deterministic hindcasts.</span>

<span class="sd">        If dist_method == &#39;bestfit&#39;:</span>
<span class="sd">            - Use cluster-based best-fit distributions to:</span>
<span class="sd">                * derive terciles analytically from (best_code_da, best_shape_da, best_loc_da, best_scale_da),</span>
<span class="sd">                * compute predictive probabilities using the same family.</span>

<span class="sd">        Otherwise:</span>
<span class="sd">            - Use empirical terciles from Predictant climatology and the selected</span>
<span class="sd">              parametric / nonparametric method.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Predictant : xarray.DataArray</span>
<span class="sd">            Observed data (T, Y, X) or (T, Y, X, M).</span>
<span class="sd">        clim_year_start, clim_year_end : int or str</span>
<span class="sd">            Climatology period (inclusive) for thresholds.</span>
<span class="sd">        hindcast_det : xarray.DataArray</span>
<span class="sd">            Deterministic hindcast (T, Y, X).</span>
<span class="sd">        best_code_da, best_shape_da, best_loc_da, best_scale_da : xarray.DataArray, optional</span>
<span class="sd">            Output from WAS_TransformData.fit_best_distribution_grid, required for &#39;bestfit&#39;.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        hindcast_prob : xarray.DataArray</span>
<span class="sd">            Probabilities with dims (probability=[&#39;PB&#39;,&#39;PN&#39;,&#39;PA&#39;], T, Y, X).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Handle member dimension if present</span>
        <span class="k">if</span> <span class="s2">&quot;M&quot;</span> <span class="ow">in</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">dims</span><span class="p">:</span>
            <span class="n">Predictant</span> <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">M</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">drop_vars</span><span class="p">(</span><span class="s2">&quot;M&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>

        <span class="c1"># Ensure dimension order</span>
        <span class="n">Predictant</span> <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="s2">&quot;Y&quot;</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">)</span>

        <span class="c1"># Spatial mask</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="o">~</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">Predictant</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="mi">0</span><span class="p">)),</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>

        <span class="c1"># Climatology subset</span>
        <span class="n">clim</span> <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">sel</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="nb">slice</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">clim_year_start</span><span class="p">),</span> <span class="nb">str</span><span class="p">(</span><span class="n">clim_year_end</span><span class="p">)))</span>
        <span class="k">if</span> <span class="n">clim</span><span class="o">.</span><span class="n">sizes</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">3</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Not enough years in climatology period for terciles.&quot;</span><span class="p">)</span>

        <span class="c1"># Error variance for predictive distributions</span>
        <span class="n">error_variance</span> <span class="o">=</span> <span class="p">(</span><span class="n">Predictant</span> <span class="o">-</span> <span class="n">hindcast_det</span><span class="p">)</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="s2">&quot;T&quot;</span><span class="p">)</span>
        <span class="n">dof</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">clim</span><span class="o">.</span><span class="n">sizes</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">])</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

        <span class="c1"># Empirical terciles (used by non-bestfit methods)</span>
        <span class="n">terciles_emp</span> <span class="o">=</span> <span class="n">clim</span><span class="o">.</span><span class="n">quantile</span><span class="p">([</span><span class="mf">0.32</span><span class="p">,</span> <span class="mf">0.67</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="s2">&quot;T&quot;</span><span class="p">)</span>
        <span class="n">T1_emp</span> <span class="o">=</span> <span class="n">terciles_emp</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">quantile</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">drop_vars</span><span class="p">(</span><span class="s2">&quot;quantile&quot;</span><span class="p">)</span>
        <span class="n">T2_emp</span> <span class="o">=</span> <span class="n">terciles_emp</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">quantile</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">drop_vars</span><span class="p">(</span><span class="s2">&quot;quantile&quot;</span><span class="p">)</span>
        

        <span class="n">dm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dist_method</span>

        <span class="c1"># ---------- BESTFIT: zone-wise optimal distributions ----------</span>
        <span class="k">if</span> <span class="n">dm</span> <span class="o">==</span> <span class="s2">&quot;bestfit&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">v</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="p">(</span><span class="n">best_code_da</span><span class="p">,</span> <span class="n">best_shape_da</span><span class="p">,</span> <span class="n">best_loc_da</span><span class="p">,</span> <span class="n">best_scale_da</span><span class="p">)):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;dist_method=&#39;bestfit&#39; requires best_code_da, best_shape_da_da, best_loc_da, best_scale_da.&quot;</span>
                <span class="p">)</span>

            <span class="c1"># T1, T2 from best-fit distributions (per grid)</span>
            <span class="n">T1</span><span class="p">,</span> <span class="n">T2</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_ppf_terciles_from_code</span><span class="p">,</span>
                <span class="n">best_code_da</span><span class="p">,</span>
                <span class="n">best_shape_da</span><span class="p">,</span>
                <span class="n">best_loc_da</span><span class="p">,</span>
                <span class="n">best_scale_da</span><span class="p">,</span>
                <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[(),</span> <span class="p">(),</span> <span class="p">(),</span> <span class="p">()],</span>
                <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(),</span> <span class="p">()],</span>
                <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">dask</span><span class="o">=</span><span class="s2">&quot;parallelized&quot;</span><span class="p">,</span>
                <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span>
            <span class="p">)</span>

            <span class="c1"># Predictive probabilities using same family</span>
            <span class="n">hindcast_prob</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">calculate_tercile_probabilities_bestfit</span><span class="p">,</span>
                <span class="n">hindcast_det</span><span class="p">,</span>
                <span class="n">error_variance</span><span class="p">,</span>
                <span class="n">T1</span><span class="p">,</span>
                <span class="n">T2</span><span class="p">,</span>
                <span class="n">best_code_da</span><span class="p">,</span>
                <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;T&quot;</span><span class="p">,),</span> <span class="p">(),</span> <span class="p">(),</span> <span class="p">(),</span> <span class="p">()],</span>
                <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;probability&quot;</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">)],</span>
                <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;dof&#39;</span><span class="p">:</span> <span class="n">dof</span><span class="p">},</span>
                <span class="n">dask</span><span class="o">=</span><span class="s2">&quot;parallelized&quot;</span><span class="p">,</span>
                <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>
                <span class="n">dask_gufunc_kwargs</span><span class="o">=</span><span class="p">{</span>
                    <span class="s2">&quot;output_sizes&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;probability&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">},</span>
                    <span class="s2">&quot;allow_rechunk&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                <span class="p">},</span>
            <span class="p">)</span>

        <span class="c1"># ---------- Nonparametric ----------</span>
        <span class="k">elif</span> <span class="n">dm</span> <span class="o">==</span> <span class="s2">&quot;nonparam&quot;</span><span class="p">:</span>
            <span class="n">error_samples</span> <span class="o">=</span> <span class="n">Predictant</span> <span class="o">-</span> <span class="n">hindcast_det</span>
            <span class="n">hindcast_prob</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">calculate_tercile_probabilities_nonparametric</span><span class="p">,</span>
                <span class="n">hindcast_det</span><span class="p">,</span>
                <span class="n">error_samples</span><span class="p">,</span>
                <span class="n">T1_emp</span><span class="p">,</span>
                <span class="n">T2_emp</span><span class="p">,</span>
                <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;T&quot;</span><span class="p">,),</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,),</span> <span class="p">(),</span> <span class="p">()],</span>
                <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;probability&quot;</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">)],</span>
                <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">dask</span><span class="o">=</span><span class="s2">&quot;parallelized&quot;</span><span class="p">,</span>
                <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>
                <span class="n">dask_gufunc_kwargs</span><span class="o">=</span><span class="p">{</span>
                    <span class="s2">&quot;output_sizes&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;probability&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">},</span>
                    <span class="s2">&quot;allow_rechunk&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                <span class="p">},</span>
            <span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid dist_method: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">dist_method</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">hindcast_prob</span> <span class="o">=</span> <span class="n">hindcast_prob</span><span class="o">.</span><span class="n">assign_coords</span><span class="p">(</span>
            <span class="n">probability</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;probability&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;PB&quot;</span><span class="p">,</span> <span class="s2">&quot;PN&quot;</span><span class="p">,</span> <span class="s2">&quot;PA&quot;</span><span class="p">])</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">hindcast_prob</span> <span class="o">*</span> <span class="n">mask</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="s2">&quot;probability&quot;</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="s2">&quot;Y&quot;</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">)</span></div>



<div class="viewcode-block" id="WAS_PolynomialRegression.forecast">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_PolynomialRegression.forecast">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">forecast</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Predictant</span><span class="p">,</span> <span class="n">clim_year_start</span><span class="p">,</span> <span class="n">clim_year_end</span><span class="p">,</span> <span class="n">Predictor</span><span class="p">,</span> <span class="n">hindcast_det</span><span class="p">,</span> <span class="n">Predictor_for_year</span><span class="p">,</span> <span class="n">best_code_da</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">best_shape_da</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">best_loc_da</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">best_scale_da</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generate forecasts for a single time (e.g., future year) and compute </span>
<span class="sd">        tercile probabilities based on the chosen distribution method.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Predictant : xarray.DataArray</span>
<span class="sd">            Target variable with dimensions (T, Y, X).</span>
<span class="sd">        clim_year_start : int</span>
<span class="sd">            Start year of climatology period.</span>
<span class="sd">        clim_year_end : int</span>
<span class="sd">            End year of climatology period.</span>
<span class="sd">        Predictor : xarray.DataArray</span>
<span class="sd">            Historical predictor data with dimensions (T, features).</span>
<span class="sd">        hindcast_det : xarray.DataArray</span>
<span class="sd">            Deterministic hindcast array that includes &#39;error&#39; and &#39;prediction&#39; over the historical period.</span>
<span class="sd">        Predictor_for_year : xarray.DataArray</span>
<span class="sd">            Predictor data for the forecast year, shape (features,) or (1, features).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        tuple (result_, hindcast_prob)</span>
<span class="sd">            result_  : xarray.DataArray or numpy array with the forecast&#39;s [error, prediction].</span>
<span class="sd">            hindcast_prob : xarray.DataArray of shape (probability=3, Y, X) with PB, PN, and PA.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Chunk sizes for parallel processing</span>
        <span class="n">chunksize_x</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">Predictant</span><span class="o">.</span><span class="n">get_index</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">))</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span><span class="p">))</span>
        <span class="n">chunksize_y</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">Predictant</span><span class="o">.</span><span class="n">get_index</span><span class="p">(</span><span class="s2">&quot;Y&quot;</span><span class="p">))</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span><span class="p">))</span>

        <span class="c1"># Align the time dimension</span>
        <span class="n">Predictor</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">Predictant</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span>
        <span class="n">Predictant_st</span> <span class="o">=</span> <span class="n">standardize_timeseries</span><span class="p">(</span><span class="n">Predictant</span><span class="p">,</span> <span class="n">clim_year_start</span><span class="p">,</span> <span class="n">clim_year_end</span><span class="p">)</span> 
        <span class="n">Predictant_st</span> <span class="o">=</span> <span class="n">Predictant_st</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="s1">&#39;T&#39;</span><span class="p">,</span> <span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">)</span>

        <span class="c1"># Squeeze the forecast predictor data if needed</span>
        <span class="n">Predictor_for_year_</span> <span class="o">=</span> <span class="n">Predictor_for_year</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>

        <span class="c1"># We&#39;ll apply our polynomial regression in parallel across Y,X. </span>
        <span class="c1"># Because we are forecasting a single point in time, y_test is unknown, so we omit it or set it to NaN.</span>
        <span class="n">y_test</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">Predictant</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>  <span class="c1"># shape (Y,X)</span>

        <span class="c1"># Create a Dask client</span>
        <span class="n">client</span> <span class="o">=</span> <span class="n">Client</span><span class="p">(</span><span class="n">n_workers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span><span class="p">,</span> <span class="n">threads_per_worker</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Apply fit_predict to get the forecast for each grid cell </span>
        <span class="c1"># We&#39;ll produce shape (2,) for each cell: [error, prediction]</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">,</span>
            <span class="n">Predictor</span><span class="p">,</span>                         <span class="c1"># shape (T, features)</span>
            <span class="n">Predictant_st</span><span class="o">.</span><span class="n">chunk</span><span class="p">({</span><span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">chunksize_y</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">chunksize_x</span><span class="p">}),</span>
            <span class="n">Predictor_for_year_</span><span class="p">,</span>
            <span class="n">y_test</span><span class="o">.</span><span class="n">chunk</span><span class="p">({</span><span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">chunksize_y</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">chunksize_x</span><span class="p">}),</span>
            <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s1">&#39;T&#39;</span><span class="p">,</span> <span class="s1">&#39;features&#39;</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;T&#39;</span><span class="p">,),</span> <span class="p">(</span><span class="s1">&#39;features&#39;</span><span class="p">,),</span> <span class="p">()],</span>
            <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">dask</span><span class="o">=</span><span class="s1">&#39;parallelized&#39;</span><span class="p">,</span>
            <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s1">&#39;output&#39;</span><span class="p">,)],</span>
            <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;float&#39;</span><span class="p">],</span>
            <span class="n">dask_gufunc_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;output_sizes&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;output&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">}}</span>
        <span class="p">)</span>

        <span class="c1"># Compute and close the client</span>
        <span class="n">result_</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
        <span class="n">result_</span> <span class="o">=</span> <span class="n">result_</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">output</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">result_</span> <span class="o">=</span> <span class="n">reverse_standardize</span><span class="p">(</span><span class="n">result_</span><span class="p">,</span> <span class="n">Predictant</span><span class="p">,</span> <span class="n">clim_year_start</span><span class="p">,</span> <span class="n">clim_year_end</span><span class="p">)</span>
        <span class="c1"># result_ =&gt; dims (output=2, Y, X). </span>
        <span class="c1"># For a real future forecast, &quot;error&quot; is NaN, &quot;prediction&quot; is the forecast.</span>

        <span class="c1"># 2) Compute thresholds T1, T2 from climatology</span>
        <span class="n">index_start</span> <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">get_index</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">get_loc</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">clim_year_start</span><span class="p">))</span><span class="o">.</span><span class="n">start</span>
        <span class="n">index_end</span>   <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">get_index</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">get_loc</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">clim_year_end</span><span class="p">))</span><span class="o">.</span><span class="n">stop</span>
        <span class="n">rainfall_for_tercile</span> <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="nb">slice</span><span class="p">(</span><span class="n">index_start</span><span class="p">,</span> <span class="n">index_end</span><span class="p">))</span>
        <span class="n">terciles</span> <span class="o">=</span> <span class="n">rainfall_for_tercile</span><span class="o">.</span><span class="n">quantile</span><span class="p">([</span><span class="mf">0.32</span><span class="p">,</span> <span class="mf">0.67</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="s1">&#39;T&#39;</span><span class="p">)</span>
        <span class="n">T1_emp</span> <span class="o">=</span> <span class="n">terciles</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">quantile</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">drop_vars</span><span class="p">(</span><span class="s1">&#39;quantile&#39;</span><span class="p">)</span>
        <span class="n">T2_emp</span> <span class="o">=</span> <span class="n">terciles</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">quantile</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">drop_vars</span><span class="p">(</span><span class="s1">&#39;quantile&#39;</span><span class="p">)</span>
        <span class="n">error_variance</span> <span class="o">=</span> <span class="p">(</span><span class="n">Predictant</span> <span class="o">-</span> <span class="n">hindcast_det</span><span class="p">)</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="s1">&#39;T&#39;</span><span class="p">)</span>
        
        <span class="c1"># Expand single prediction to T=1 so probability methods can handle it</span>
        <span class="n">forecast_expanded</span> <span class="o">=</span> <span class="n">result_</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span>
            <span class="n">T</span><span class="o">=</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">Timestamp</span><span class="p">(</span><span class="n">Predictor_for_year</span><span class="o">.</span><span class="n">coords</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">to_pydatetime</span><span class="p">()]</span>
        <span class="p">)</span>
        <span class="n">year</span> <span class="o">=</span> <span class="n">Predictor_for_year</span><span class="o">.</span><span class="n">coords</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;datetime64[Y]&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1970</span>
        <span class="c1"># year = Predictor_for_year.coords[&#39;T&#39;].values.astype(&#39;datetime64[Y]&#39;).astype(int)[0] + 1970  </span>
        <span class="n">T_value_1</span> <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">coords</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>  <span class="c1"># Get the datetime64 value from da1</span>
        <span class="n">month_1</span> <span class="o">=</span> <span class="n">T_value_1</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;datetime64[M]&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span> <span class="o">%</span> <span class="mi">12</span> <span class="o">+</span> <span class="mi">1</span>  <span class="c1"># Extract month</span>
        <span class="n">new_T_value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">datetime64</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">year</span><span class="si">}</span><span class="s2">-</span><span class="si">{</span><span class="n">month_1</span><span class="si">:</span><span class="s2">02d</span><span class="si">}</span><span class="s2">-</span><span class="si">{</span><span class="mi">1</span><span class="si">:</span><span class="s2">02d</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        
        <span class="n">forecast_expanded</span> <span class="o">=</span> <span class="n">forecast_expanded</span><span class="o">.</span><span class="n">assign_coords</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span><span class="p">([</span><span class="n">new_T_value</span><span class="p">],</span> <span class="n">dims</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">]))</span>
        <span class="n">forecast_expanded</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">forecast_expanded</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;datetime64[ns]&#39;</span><span class="p">)</span>

        <span class="n">dof</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">rainfall_for_tercile</span><span class="o">.</span><span class="n">sizes</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">])</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

        <span class="n">dm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dist_method</span>

        <span class="c1"># ---------- BESTFIT ----------</span>
        <span class="k">if</span> <span class="n">dm</span> <span class="o">==</span> <span class="s2">&quot;bestfit&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">v</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="p">(</span><span class="n">best_code_da</span><span class="p">,</span> <span class="n">best_shape_da</span><span class="p">,</span> <span class="n">best_loc_da</span><span class="p">,</span> <span class="n">best_scale_da</span><span class="p">)):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;dist_method=&#39;bestfit&#39; requires best_code_da, best_shape_da, best_loc_da, best_scale_da.&quot;</span>
                <span class="p">)</span>
            
            <span class="n">T1</span><span class="p">,</span> <span class="n">T2</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_ppf_terciles_from_code</span><span class="p">,</span>
                <span class="n">best_code_da</span><span class="p">,</span>
                <span class="n">best_shape_da</span><span class="p">,</span>
                <span class="n">best_loc_da</span><span class="p">,</span>
                <span class="n">best_scale_da</span><span class="p">,</span>
                <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[(),</span> <span class="p">(),</span> <span class="p">(),</span> <span class="p">()],</span>
                <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(),</span> <span class="p">()],</span>
                <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">dask</span><span class="o">=</span><span class="s2">&quot;parallelized&quot;</span><span class="p">,</span>
                <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span>
            <span class="p">)</span>

            <span class="n">forecast_prob</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">calculate_tercile_probabilities_bestfit</span><span class="p">,</span>
                <span class="n">forecast_expanded</span><span class="p">,</span>
                <span class="n">error_variance</span><span class="p">,</span>
                <span class="n">T1</span><span class="p">,</span>
                <span class="n">T2</span><span class="p">,</span>
                <span class="n">best_code_da</span><span class="p">,</span>
                <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;T&quot;</span><span class="p">,),</span> <span class="p">(),</span> <span class="p">(),</span> <span class="p">(),</span> <span class="p">()],</span>
                <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;probability&quot;</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">)],</span>
                <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">dask</span><span class="o">=</span><span class="s2">&quot;parallelized&quot;</span><span class="p">,</span>
                <span class="n">kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;dof&quot;</span><span class="p">:</span> <span class="n">dof</span><span class="p">},</span>
                <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>
                <span class="n">dask_gufunc_kwargs</span><span class="o">=</span><span class="p">{</span>
                    <span class="s2">&quot;output_sizes&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;probability&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">},</span>
                    <span class="s2">&quot;allow_rechunk&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                <span class="p">},</span>
            <span class="p">)</span>

        <span class="c1"># ---------- Nonparametric ----------</span>
        <span class="k">elif</span> <span class="n">dm</span> <span class="o">==</span> <span class="s2">&quot;nonparam&quot;</span><span class="p">:</span>
            <span class="n">error_samples</span> <span class="o">=</span> <span class="n">Predictant</span> <span class="o">-</span> <span class="n">hindcast_det</span>
            <span class="n">forecast_prob</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">calculate_tercile_probabilities_nonparametric</span><span class="p">,</span>
                <span class="n">forecast_expanded</span><span class="p">,</span>
                <span class="n">error_samples</span><span class="p">,</span>
                <span class="n">T1_emp</span><span class="p">,</span>
                <span class="n">T2_emp</span><span class="p">,</span>
                <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;T&quot;</span><span class="p">,),</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,),</span> <span class="p">(),</span> <span class="p">()],</span>
                <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;probability&quot;</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">)],</span>
                <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">dask</span><span class="o">=</span><span class="s2">&quot;parallelized&quot;</span><span class="p">,</span>
                <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>
                <span class="n">dask_gufunc_kwargs</span><span class="o">=</span><span class="p">{</span>
                    <span class="s2">&quot;output_sizes&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;probability&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">},</span>
                    <span class="s2">&quot;allow_rechunk&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                <span class="p">},</span>
            <span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid dist_method: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">dist_method</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">forecast_prob</span> <span class="o">=</span> <span class="n">forecast_prob</span><span class="o">.</span><span class="n">assign_coords</span><span class="p">(</span><span class="n">probability</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;probability&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;PB&#39;</span><span class="p">,</span> <span class="s1">&#39;PN&#39;</span><span class="p">,</span> <span class="s1">&#39;PA&#39;</span><span class="p">]))</span>
        <span class="k">return</span> <span class="n">result_da</span> <span class="o">*</span> <span class="n">mask</span><span class="p">,</span> <span class="n">mask</span> <span class="o">*</span> <span class="n">forecast_prob</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="s1">&#39;probability&#39;</span><span class="p">,</span> <span class="s1">&#39;T&#39;</span><span class="p">,</span> <span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">)</span></div>
</div>


        
<span class="c1">###########################################</span>

<div class="viewcode-block" id="WAS_PoissonRegression">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_PoissonRegression">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">WAS_PoissonRegression</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A class to perform Poisson Regression on spatiotemporal datasets for count data prediction.</span>

<span class="sd">    This class is designed to work with Dask and Xarray for parallelized, high-performance </span>
<span class="sd">    regression computations across large datasets with spatial and temporal dimensions. The primary </span>
<span class="sd">    methods are for fitting the Poisson regression model, making predictions, and calculating </span>
<span class="sd">    probabilistic predictions for climate terciles.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    nb_cores : int</span>
<span class="sd">        The number of CPU cores to use for parallel computation (default is 1).</span>
<span class="sd">    dist_method : str</span>
<span class="sd">        The method to use for tercile probability calculations, e.g. {&quot;t&quot;, &quot;gamma&quot;, &quot;normal&quot;, </span>
<span class="sd">        &quot;lognormal&quot;, &quot;nonparam&quot;} (default is &quot;gamma&quot;).</span>

<span class="sd">    Methods</span>
<span class="sd">    -------</span>
<span class="sd">    fit_predict(x, y, x_test, y_test)</span>
<span class="sd">        Fits a Poisson regression model to the training data, predicts on test data, and computes error.</span>
<span class="sd">    compute_model(X_train, y_train, X_test, y_test)</span>
<span class="sd">        Applies the Poisson regression model across a dataset using parallel computation </span>
<span class="sd">        with Dask, returning predictions and error metrics.</span>
<span class="sd">    compute_prob(Predictant, clim_year_start, clim_year_end, Predictor, hindcast_det)</span>
<span class="sd">        Computes tercile probabilities for hindcast rainfall (or count data) predictions </span>
<span class="sd">        over specified climatological years, using the chosen `dist_method`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="WAS_PoissonRegression.__init__">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_PoissonRegression.__init__">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nb_cores</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dist_method</span><span class="o">=</span><span class="s2">&quot;nonparam&quot;</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initializes the WAS_PoissonRegression with a specified number of CPU cores and </span>
<span class="sd">        a default distribution method for tercile probability calculations.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        nb_cores : int, optional</span>
<span class="sd">            Number of CPU cores to use for parallel computation, by default 1.</span>
<span class="sd">        dist_method : str, optional</span>
<span class="sd">            The distribution method to compute tercile probabilities, by default &quot;gamma&quot;.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span> <span class="o">=</span> <span class="n">nb_cores</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dist_method</span> <span class="o">=</span> <span class="n">dist_method</span></div>


<div class="viewcode-block" id="WAS_PoissonRegression.fit_predict">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_PoissonRegression.fit_predict">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">fit_predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fits a Poisson regression model to the provided training data, makes predictions </span>
<span class="sd">        on the test data, and calculates the prediction error.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        x : array-like, shape (n_samples, n_features)</span>
<span class="sd">            Training data (predictors).</span>
<span class="sd">        y : array-like, shape (n_samples,)</span>
<span class="sd">            Training targets (non-negative count data).</span>
<span class="sd">        x_test : array-like, shape (n_features,) or (1, n_features)</span>
<span class="sd">            Test data (predictors).</span>
<span class="sd">        y_test : float</span>
<span class="sd">            Test target value (actual counts).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        np.ndarray of shape (2,)</span>
<span class="sd">            [prediction_error, predicted_value]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># PoissonRegressor requires non-negative y. We assume the user has handled invalid data.</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">PoissonRegressor</span><span class="p">()</span>

        <span class="c1"># Fit on all provided samples. (If any NaNs exist, user must filter them out externally </span>
        <span class="c1"># or we might add a mask for valid data.)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

        <span class="c1"># Predict on the test data</span>
        <span class="k">if</span> <span class="n">x_test</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">x_test</span> <span class="o">=</span> <span class="n">x_test</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">preds</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>

        <span class="c1"># Poisson rates should not be negative, but numeric or solver issues could occur</span>
        <span class="n">preds</span><span class="p">[</span><span class="n">preds</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># Compute difference from actual</span>
        <span class="n">error_</span> <span class="o">=</span> <span class="n">y_test</span> <span class="o">-</span> <span class="n">preds</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">error_</span><span class="p">,</span> <span class="n">preds</span><span class="p">])</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span></div>


<div class="viewcode-block" id="WAS_PoissonRegression.compute_model">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_PoissonRegression.compute_model">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">compute_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes predictions for spatiotemporal data using Poisson Regression with parallel processing.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X_train : xarray.DataArray</span>
<span class="sd">            Predictor data with dimensions (T, features).</span>
<span class="sd">        y_train : xarray.DataArray</span>
<span class="sd">            Training target values (count data) with dimensions (T, Y, X).</span>
<span class="sd">        X_test : xarray.DataArray</span>
<span class="sd">            Test data (predictors) with shape (features,) or (T, features), typically squeezed.</span>
<span class="sd">        y_test : xarray.DataArray</span>
<span class="sd">            Test target values (count data) with dimensions (Y, X) or broadcastable to (T, Y, X).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        xarray.DataArray</span>
<span class="sd">            An array with a new dimension (&#39;output&#39;, size=2) capturing [error, prediction].</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Determine chunk sizes so each worker handles a portion of the spatial domain</span>
        <span class="n">chunksize_x</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="o">.</span><span class="n">get_index</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">))</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span><span class="p">))</span>
        <span class="n">chunksize_y</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="o">.</span><span class="n">get_index</span><span class="p">(</span><span class="s2">&quot;Y&quot;</span><span class="p">))</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span><span class="p">))</span>

        <span class="c1"># Align the &#39;T&#39; dimension</span>
        <span class="n">X_train</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span>
        <span class="n">y_train</span> <span class="o">=</span> <span class="n">y_train</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="s1">&#39;T&#39;</span><span class="p">,</span> <span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">)</span>

        <span class="c1"># Squeeze test arrays in case of extra dimensions</span>
        <span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
        <span class="c1"># If y_test has a &#39;T&#39; dimension, remove/ignore it since we only need (Y,X)</span>
        <span class="k">if</span> <span class="s1">&#39;T&#39;</span> <span class="ow">in</span> <span class="n">y_test</span><span class="o">.</span><span class="n">dims</span><span class="p">:</span>
            <span class="n">y_test</span> <span class="o">=</span> <span class="n">y_test</span><span class="o">.</span><span class="n">drop_vars</span><span class="p">(</span><span class="s1">&#39;T&#39;</span><span class="p">)</span>
        <span class="n">y_test</span> <span class="o">=</span> <span class="n">y_test</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">)</span>

        <span class="c1"># Create a Dask client for parallel computing</span>
        <span class="n">client</span> <span class="o">=</span> <span class="n">Client</span><span class="p">(</span><span class="n">n_workers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span><span class="p">,</span> <span class="n">threads_per_worker</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Apply our fit_predict method across each spatial cell in parallel</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">,</span>
            <span class="n">X_train</span><span class="p">,</span>                                 <span class="c1"># shape (T, features)</span>
            <span class="n">y_train</span><span class="o">.</span><span class="n">chunk</span><span class="p">({</span><span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">chunksize_y</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">chunksize_x</span><span class="p">}),</span>  <span class="c1"># shape (T,)</span>
            <span class="n">X_test</span><span class="p">,</span>
            <span class="n">y_test</span><span class="o">.</span><span class="n">chunk</span><span class="p">({</span><span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">chunksize_y</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">chunksize_x</span><span class="p">}),</span>
            <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s1">&#39;T&#39;</span><span class="p">,</span> <span class="s1">&#39;features&#39;</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;T&#39;</span><span class="p">,),</span> <span class="p">(</span><span class="s1">&#39;features&#39;</span><span class="p">,),</span> <span class="p">()],</span>
            <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s1">&#39;output&#39;</span><span class="p">,)],</span>         <span class="c1"># We&#39;ll have an &#39;output&#39; dimension of size 2</span>
            <span class="n">dask</span><span class="o">=</span><span class="s1">&#39;parallelized&#39;</span><span class="p">,</span>
            <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;float&#39;</span><span class="p">],</span>
            <span class="n">dask_gufunc_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;output_sizes&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;output&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">}}</span>
        <span class="p">)</span>

        <span class="n">result_</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
        <span class="n">client</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">result_</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">output</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></div>


      <span class="c1"># ------------------ Probability Calculation Methods ------------------</span>

<div class="viewcode-block" id="WAS_PoissonRegression._ppf_terciles_from_code">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_PoissonRegression._ppf_terciles_from_code">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_ppf_terciles_from_code</span><span class="p">(</span><span class="n">dist_code</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return tercile thresholds (T1, T2) from best-fit distribution parameters.</span>
<span class="sd">    </span>
<span class="sd">        dist_code:</span>
<span class="sd">            1: norm</span>
<span class="sd">            2: lognorm</span>
<span class="sd">            3: expon</span>
<span class="sd">            4: gamma</span>
<span class="sd">            5: weibull_min</span>
<span class="sd">            6: t</span>
<span class="sd">            7: poisson</span>
<span class="sd">            8: nbinom</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">dist_code</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
    
        <span class="n">code</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">dist_code</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                    <span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">lognorm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                    <span class="n">lognorm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">expon</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                    <span class="n">expon</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">gamma</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                    <span class="n">gamma</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">5</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">weibull_min</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                    <span class="n">weibull_min</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">6</span><span class="p">:</span>
                <span class="c1"># Note: Renamed &#39;t_dist&#39; to &#39;t&#39; for standard scipy.stats</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">t</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                    <span class="n">t</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">7</span><span class="p">:</span>
                <span class="c1"># Poisson: poisson.ppf(q, mu, loc=0)</span>
                <span class="c1"># ASSUMPTION: &#39;mu&#39; (mean) is passed as &#39;shape&#39;</span>
                <span class="c1">#             &#39;loc&#39; is passed as &#39;loc&#39;</span>
                <span class="c1">#             &#39;scale&#39; is unused</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">poisson</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">),</span>
                    <span class="n">poisson</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">8</span><span class="p">:</span>
                <span class="c1"># Negative Binomial: nbinom.ppf(q, n, p, loc=0)</span>
                <span class="c1"># ASSUMPTION: &#39;n&#39; (successes) is passed as &#39;shape&#39;</span>
                <span class="c1">#             &#39;p&#39; (probability) is passed as &#39;scale&#39;</span>
                <span class="c1">#             &#39;loc&#39; is passed as &#39;loc&#39;</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">nbinom</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">scale</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">),</span>
                    <span class="n">nbinom</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">scale</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">),</span>
                <span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
    
        <span class="c1"># Fallback if code is not 1-8</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span></div>

        
<div class="viewcode-block" id="WAS_PoissonRegression.weibull_shape_solver">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_PoissonRegression.weibull_shape_solver">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">weibull_shape_solver</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">V</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Function to find the root of the Weibull shape parameter &#39;k&#39;.</span>
<span class="sd">        We find &#39;k&#39; such that the theoretical variance/mean^2 ratio</span>
<span class="sd">        matches the observed V/M^2 ratio.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Guard against invalid &#39;k&#39; values during solving</span>
        <span class="k">if</span> <span class="n">k</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">g1</span> <span class="o">=</span> <span class="n">gamma_function</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="mi">1</span><span class="o">/</span><span class="n">k</span><span class="p">)</span>
            <span class="n">g2</span> <span class="o">=</span> <span class="n">gamma_function</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="mi">2</span><span class="o">/</span><span class="n">k</span><span class="p">)</span>
            
            <span class="c1"># This is the V/M^2 ratio *implied by k*</span>
            <span class="n">implied_v_over_m_sq</span> <span class="o">=</span> <span class="p">(</span><span class="n">g2</span> <span class="o">/</span> <span class="p">(</span><span class="n">g1</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span> <span class="o">-</span> <span class="mi">1</span>
            
            <span class="c1"># This is the *observed* ratio</span>
            <span class="n">observed_v_over_m_sq</span> <span class="o">=</span> <span class="n">V</span> <span class="o">/</span> <span class="p">(</span><span class="n">M</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
            
            <span class="c1"># Return the difference (we want this to be 0)</span>
            <span class="k">return</span> <span class="n">observed_v_over_m_sq</span> <span class="o">-</span> <span class="n">implied_v_over_m_sq</span>
        <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
            <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span> <span class="c1"># Handle math errors</span></div>


<div class="viewcode-block" id="WAS_PoissonRegression.calculate_tercile_probabilities_bestfit">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_PoissonRegression.calculate_tercile_probabilities_bestfit">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">calculate_tercile_probabilities_bestfit</span><span class="p">(</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">error_variance</span><span class="p">,</span> <span class="n">T1</span><span class="p">,</span> <span class="n">T2</span><span class="p">,</span> <span class="n">dist_code</span><span class="p">,</span> <span class="n">dof</span> 
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generic tercile probabilities using best-fit family per grid cell.</span>

<span class="sd">        Inputs (per grid cell):</span>
<span class="sd">        - best_guess : 1D array over T (hindcast_det or forecast_det)</span>
<span class="sd">        - T1, T2     : scalar terciles from climatological best-fit distribution</span>
<span class="sd">        - dist_code  : int, as in _ppf_terciles_from_code</span>
<span class="sd">        - shape, loc, scale : scalars from climatology fit</span>

<span class="sd">        Strategy:</span>
<span class="sd">        - For each time step, build a predictive distribution of the same family:</span>
<span class="sd">            * Use best_guess[t] to adjust mean / location;</span>
<span class="sd">            * Keep shape parameters from climatology.</span>
<span class="sd">        - Then compute probabilities:</span>
<span class="sd">            P(B) = F(T1), P(N) = F(T2) - F(T1), P(A) = 1 - F(T2).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        
        <span class="n">best_guess</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">best_guess</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span>
        <span class="n">error_variance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">error_variance</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
        <span class="c1"># T1 = np.asarray(T1, dtype=float)</span>
        <span class="c1"># T2 = np.asarray(T2, dtype=float)</span>
        <span class="n">n_time</span> <span class="o">=</span> <span class="n">best_guess</span><span class="o">.</span><span class="n">size</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="n">n_time</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">best_guess</span><span class="p">))</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">dist_code</span><span class="p">)</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">T1</span><span class="p">)</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">T2</span><span class="p">)</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">error_variance</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">out</span>

        <span class="n">code</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">dist_code</span><span class="p">)</span>

        <span class="c1"># Normal: loc = forecast; scale from clim</span>
        <span class="k">if</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">error_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">error_variance</span><span class="p">)</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">error_std</span><span class="p">)</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">error_std</span><span class="p">)</span> <span class="o">-</span> <span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">error_std</span><span class="p">)</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">error_std</span><span class="p">)</span>

        <span class="c1"># Lognormal: shape = sigma from clim; enforce mean = best_guess</span>
        <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">sigma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">error_variance</span> <span class="o">/</span> <span class="p">(</span><span class="n">best_guess</span><span class="o">**</span><span class="mi">2</span><span class="p">)))</span>
            <span class="n">mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">best_guess</span><span class="p">)</span> <span class="o">-</span> <span class="n">sigma</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="mi">2</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">lognorm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">mu</span><span class="p">))</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">lognorm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">mu</span><span class="p">))</span> <span class="o">-</span> <span class="n">lognorm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">mu</span><span class="p">))</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">lognorm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">mu</span><span class="p">))</span>      


        <span class="c1"># Exponential: keep scale from clim; shift loc so mean = best_guess</span>
        <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
            <span class="n">c1</span> <span class="o">=</span> <span class="n">expon</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">error_variance</span><span class="p">))</span>
            <span class="n">c2</span> <span class="o">=</span> <span class="n">expon</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc_t</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">error_variance</span><span class="p">))</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c2</span> <span class="o">-</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">c2</span>

        <span class="c1"># Gamma: use shape from clim; set scale so mean = best_guess</span>
        <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
            <span class="n">alpha</span> <span class="o">=</span> <span class="p">(</span><span class="n">best_guess</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="n">error_variance</span>
            <span class="n">theta</span> <span class="o">=</span> <span class="n">error_variance</span> <span class="o">/</span> <span class="n">best_guess</span>
            <span class="n">c1</span> <span class="o">=</span> <span class="n">gamma</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">theta</span><span class="p">)</span>
            <span class="n">c2</span> <span class="o">=</span> <span class="n">gamma</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">theta</span><span class="p">)</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c2</span> <span class="o">-</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">c2</span>

        <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">5</span><span class="p">:</span> <span class="c1"># Assuming 5 is for Weibull   </span>
        
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_time</span><span class="p">):</span>
                <span class="c1"># Get the scalar values for this specific element (e.g., grid cell)</span>
                <span class="n">M</span> <span class="o">=</span> <span class="n">best_guess</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">M</span><span class="p">)</span>
                <span class="n">V</span> <span class="o">=</span> <span class="n">error_variance</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">V</span><span class="p">)</span>
                
                <span class="c1"># Handle cases with no variance to avoid division by zero</span>
                <span class="k">if</span> <span class="n">V</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">M</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                    <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                    <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                    <span class="k">continue</span> <span class="c1"># Skip to the next element</span>
        
                <span class="c1"># --- 1. Numerically solve for shape &#39;k&#39; ---</span>
                <span class="c1"># We need a reasonable starting guess. 2.0 is common (Rayleigh dist.)</span>
                <span class="n">initial_guess</span> <span class="o">=</span> <span class="mf">2.0</span>
                
                <span class="c1"># fsolve finds the root of our helper function</span>
                <span class="n">k</span> <span class="o">=</span> <span class="n">fsolve</span><span class="p">(</span><span class="n">weibull_shape_solver</span><span class="p">,</span> <span class="n">initial_guess</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">V</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>
        
                <span class="c1"># --- 2. Check for bad solution and calculate scale &#39;lambda&#39; ---</span>
                <span class="k">if</span> <span class="n">k</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="c1"># Solver failed</span>
                    <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                    <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                    <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                    <span class="k">continue</span>
                
                <span class="c1"># With &#39;k&#39; found, we can now algebraically find scale &#39;lambda&#39;</span>
                <span class="c1"># In scipy.stats, scale is &#39;scale&#39;</span>
                <span class="n">lambda_scale</span> <span class="o">=</span> <span class="n">M</span> <span class="o">/</span> <span class="n">gamma_function</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="mi">1</span><span class="o">/</span><span class="n">k</span><span class="p">)</span>
        
                <span class="c1"># --- 3. Calculate Probabilities ---</span>
                <span class="c1"># In scipy.stats, shape &#39;k&#39; is &#39;c&#39;</span>
                <span class="c1"># Use the T1 and T2 values for this specific element</span>
                
                <span class="n">c1</span> <span class="o">=</span> <span class="n">weibull_min</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">lambda_scale</span><span class="p">)</span>
                <span class="n">c2</span> <span class="o">=</span> <span class="n">weibull_min</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">lambda_scale</span><span class="p">)</span>
        
                <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">c1</span>
                <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">c2</span> <span class="o">-</span> <span class="n">c1</span>
                <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">c2</span>

        <span class="c1"># Student-t: df from clim; scale from clim; loc = best_guess</span>
        <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">6</span><span class="p">:</span>       
            <span class="c1"># Check if df is valid for variance calculation</span>
            <span class="k">if</span> <span class="n">dof</span> <span class="o">&lt;=</span> <span class="mi">2</span><span class="p">:</span>
                <span class="c1"># Cannot calculate scale, fill with NaNs</span>
                <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># 1. Calculate t-distribution parameters</span>
                <span class="c1"># &#39;loc&#39; (mean) is just the best_guess</span>
                <span class="n">loc</span> <span class="o">=</span> <span class="n">best_guess</span>
                <span class="c1"># &#39;scale&#39; is calculated from the variance and df</span>
                <span class="c1"># Variance = scale**2 * (df / (df - 2))</span>
                <span class="n">scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">error_variance</span> <span class="o">*</span> <span class="p">(</span><span class="n">dof</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="n">dof</span><span class="p">)</span>
                
                <span class="c1"># 2. Calculate probabilities</span>
                <span class="n">c1</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">dof</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">)</span>
                <span class="n">c2</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">dof</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">)</span>

                <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c1</span>
                <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c2</span> <span class="o">-</span> <span class="n">c1</span>
                <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">c2</span>

        <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">7</span><span class="p">:</span> <span class="c1"># Assuming 7 is for Poisson</span>
            
            <span class="c1"># --- 1. Set the Poisson parameter &#39;mu&#39; ---</span>
            <span class="c1"># The &#39;mu&#39; parameter is the mean.</span>
            
            <span class="c1"># A warning is strongly recommended if error_variance is different from best_guess</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">error_variance</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Warning: &#39;error_variance&#39; is not equal to &#39;best_guess&#39;.&quot;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Poisson model assumes mean=variance and is likely inappropriate.&quot;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Consider using Negative Binomial.&quot;</span><span class="p">)</span>
            
            <span class="n">mu</span> <span class="o">=</span> <span class="n">best_guess</span>
        
            <span class="c1"># --- 2. Calculate Probabilities ---</span>
            <span class="c1"># poisson.cdf(k, mu) calculates P(X &lt;= k)</span>
            
            <span class="n">c1</span> <span class="o">=</span> <span class="n">poisson</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">mu</span><span class="p">)</span>
            <span class="n">c2</span> <span class="o">=</span> <span class="n">poisson</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">mu</span><span class="p">)</span>
            
            <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c2</span> <span class="o">-</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">c2</span>

        <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">8</span><span class="p">:</span> <span class="c1"># Assuming 8 is for Negative Binomial</span>
            
            <span class="c1"># --- 1. Calculate Negative Binomial Parameters ---</span>
            <span class="c1"># This model is ONLY valid for overdispersion (Variance &gt; Mean).</span>
            <span class="c1"># We will use np.where to set parameters to NaN if V &lt;= M.</span>
            
            <span class="c1"># p = Mean / Variance</span>
            <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">error_variance</span> <span class="o">&gt;</span> <span class="n">best_guess</span><span class="p">,</span> 
                         <span class="n">best_guess</span> <span class="o">/</span> <span class="n">error_variance</span><span class="p">,</span> 
                         <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
            
            <span class="c1"># n = Mean^2 / (Variance - Mean)</span>
            <span class="n">n</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">error_variance</span> <span class="o">&gt;</span> <span class="n">best_guess</span><span class="p">,</span> 
                         <span class="p">(</span><span class="n">best_guess</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">error_variance</span> <span class="o">-</span> <span class="n">best_guess</span><span class="p">),</span> 
                         <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
            
            <span class="c1"># --- 2. Calculate Probabilities ---</span>
            <span class="c1"># The nbinom.cdf function will propagate NaNs, correctly</span>
            <span class="c1"># handling the cases where the model was invalid.</span>
            
            <span class="n">c1</span> <span class="o">=</span> <span class="n">nbinom</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">)</span>
            <span class="n">c2</span> <span class="o">=</span> <span class="n">nbinom</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">)</span>
            
            <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c2</span> <span class="o">-</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">c2</span>
            
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid distribution&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">out</span></div>


<div class="viewcode-block" id="WAS_PoissonRegression.calculate_tercile_probabilities_nonparametric">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_PoissonRegression.calculate_tercile_probabilities_nonparametric">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">calculate_tercile_probabilities_nonparametric</span><span class="p">(</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">error_samples</span><span class="p">,</span> <span class="n">first_tercile</span><span class="p">,</span> <span class="n">second_tercile</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Non-parametric method using historical error samples.&quot;&quot;&quot;</span>
        <span class="n">n_time</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">best_guess</span><span class="p">)</span>
        <span class="n">pred_prob</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="n">n_time</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_time</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">best_guess</span><span class="p">[</span><span class="n">t</span><span class="p">]):</span>
                <span class="k">continue</span>
            <span class="n">dist</span> <span class="o">=</span> <span class="n">best_guess</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">+</span> <span class="n">error_samples</span>
            <span class="n">dist</span> <span class="o">=</span> <span class="n">dist</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">dist</span><span class="p">)]</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">dist</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="n">p_below</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dist</span> <span class="o">&lt;</span> <span class="n">first_tercile</span><span class="p">)</span>
            <span class="n">p_between</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">dist</span> <span class="o">&gt;=</span> <span class="n">first_tercile</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">dist</span> <span class="o">&lt;</span> <span class="n">second_tercile</span><span class="p">))</span>
            <span class="n">p_above</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="p">(</span><span class="n">p_below</span> <span class="o">+</span> <span class="n">p_between</span><span class="p">)</span>
            <span class="n">pred_prob</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">p_below</span>
            <span class="n">pred_prob</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">p_between</span>
            <span class="n">pred_prob</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">p_above</span>
        <span class="k">return</span> <span class="n">pred_prob</span></div>




<div class="viewcode-block" id="WAS_PoissonRegression.compute_prob">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_PoissonRegression.compute_prob">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">compute_prob</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">Predictant</span><span class="p">:</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span><span class="p">,</span>
        <span class="n">clim_year_start</span><span class="p">,</span>
        <span class="n">clim_year_end</span><span class="p">,</span>
        <span class="n">hindcast_det</span><span class="p">:</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span><span class="p">,</span>
        <span class="n">best_code_da</span><span class="p">:</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">best_shape_da</span><span class="p">:</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">best_loc_da</span><span class="p">:</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">best_scale_da</span><span class="p">:</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute tercile probabilities for deterministic hindcasts.</span>

<span class="sd">        If dist_method == &#39;bestfit&#39;:</span>
<span class="sd">            - Use cluster-based best-fit distributions to:</span>
<span class="sd">                * derive terciles analytically from (best_code_da, best_shape_da, best_loc_da, best_scale_da),</span>
<span class="sd">                * compute predictive probabilities using the same family.</span>

<span class="sd">        Otherwise:</span>
<span class="sd">            - Use empirical terciles from Predictant climatology and the selected</span>
<span class="sd">              parametric / nonparametric method.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Predictant : xarray.DataArray</span>
<span class="sd">            Observed data (T, Y, X) or (T, Y, X, M).</span>
<span class="sd">        clim_year_start, clim_year_end : int or str</span>
<span class="sd">            Climatology period (inclusive) for thresholds.</span>
<span class="sd">        hindcast_det : xarray.DataArray</span>
<span class="sd">            Deterministic hindcast (T, Y, X).</span>
<span class="sd">        best_code_da, best_shape_da, best_loc_da, best_scale_da : xarray.DataArray, optional</span>
<span class="sd">            Output from WAS_TransformData.fit_best_distribution_grid, required for &#39;bestfit&#39;.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        hindcast_prob : xarray.DataArray</span>
<span class="sd">            Probabilities with dims (probability=[&#39;PB&#39;,&#39;PN&#39;,&#39;PA&#39;], T, Y, X).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Handle member dimension if present</span>
        <span class="k">if</span> <span class="s2">&quot;M&quot;</span> <span class="ow">in</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">dims</span><span class="p">:</span>
            <span class="n">Predictant</span> <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">M</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">drop_vars</span><span class="p">(</span><span class="s2">&quot;M&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>

        <span class="c1"># Ensure dimension order</span>
        <span class="n">Predictant</span> <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="s2">&quot;Y&quot;</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">)</span>

        <span class="c1"># Spatial mask</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="o">~</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">Predictant</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="mi">0</span><span class="p">)),</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>

        <span class="c1"># Climatology subset</span>
        <span class="n">clim</span> <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">sel</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="nb">slice</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">clim_year_start</span><span class="p">),</span> <span class="nb">str</span><span class="p">(</span><span class="n">clim_year_end</span><span class="p">)))</span>
        <span class="k">if</span> <span class="n">clim</span><span class="o">.</span><span class="n">sizes</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">3</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Not enough years in climatology period for terciles.&quot;</span><span class="p">)</span>

        <span class="c1"># Error variance for predictive distributions</span>
        <span class="n">error_variance</span> <span class="o">=</span> <span class="p">(</span><span class="n">Predictant</span> <span class="o">-</span> <span class="n">hindcast_det</span><span class="p">)</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="s2">&quot;T&quot;</span><span class="p">)</span>
        <span class="n">dof</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">clim</span><span class="o">.</span><span class="n">sizes</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">])</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

        <span class="c1"># Empirical terciles (used by non-bestfit methods)</span>
        <span class="n">terciles_emp</span> <span class="o">=</span> <span class="n">clim</span><span class="o">.</span><span class="n">quantile</span><span class="p">([</span><span class="mf">0.32</span><span class="p">,</span> <span class="mf">0.67</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="s2">&quot;T&quot;</span><span class="p">)</span>
        <span class="n">T1_emp</span> <span class="o">=</span> <span class="n">terciles_emp</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">quantile</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">drop_vars</span><span class="p">(</span><span class="s2">&quot;quantile&quot;</span><span class="p">)</span>
        <span class="n">T2_emp</span> <span class="o">=</span> <span class="n">terciles_emp</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">quantile</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">drop_vars</span><span class="p">(</span><span class="s2">&quot;quantile&quot;</span><span class="p">)</span>
        

        <span class="n">dm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dist_method</span>

        <span class="c1"># ---------- BESTFIT: zone-wise optimal distributions ----------</span>
        <span class="k">if</span> <span class="n">dm</span> <span class="o">==</span> <span class="s2">&quot;bestfit&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">v</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="p">(</span><span class="n">best_code_da</span><span class="p">,</span> <span class="n">best_shape_da</span><span class="p">,</span> <span class="n">best_loc_da</span><span class="p">,</span> <span class="n">best_scale_da</span><span class="p">)):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;dist_method=&#39;bestfit&#39; requires best_code_da, best_shape_da_da, best_loc_da, best_scale_da.&quot;</span>
                <span class="p">)</span>

            <span class="c1"># T1, T2 from best-fit distributions (per grid)</span>
            <span class="n">T1</span><span class="p">,</span> <span class="n">T2</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_ppf_terciles_from_code</span><span class="p">,</span>
                <span class="n">best_code_da</span><span class="p">,</span>
                <span class="n">best_shape_da</span><span class="p">,</span>
                <span class="n">best_loc_da</span><span class="p">,</span>
                <span class="n">best_scale_da</span><span class="p">,</span>
                <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[(),</span> <span class="p">(),</span> <span class="p">(),</span> <span class="p">()],</span>
                <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(),</span> <span class="p">()],</span>
                <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">dask</span><span class="o">=</span><span class="s2">&quot;parallelized&quot;</span><span class="p">,</span>
                <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span>
            <span class="p">)</span>

            <span class="c1"># Predictive probabilities using same family</span>
            <span class="n">hindcast_prob</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">calculate_tercile_probabilities_bestfit</span><span class="p">,</span>
                <span class="n">hindcast_det</span><span class="p">,</span>
                <span class="n">error_variance</span><span class="p">,</span>
                <span class="n">T1</span><span class="p">,</span>
                <span class="n">T2</span><span class="p">,</span>
                <span class="n">best_code_da</span><span class="p">,</span>
                <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;T&quot;</span><span class="p">,),</span> <span class="p">(),</span> <span class="p">(),</span> <span class="p">(),</span> <span class="p">()],</span>
                <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;probability&quot;</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">)],</span>
                <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;dof&#39;</span><span class="p">:</span> <span class="n">dof</span><span class="p">},</span>
                <span class="n">dask</span><span class="o">=</span><span class="s2">&quot;parallelized&quot;</span><span class="p">,</span>
                <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>
                <span class="n">dask_gufunc_kwargs</span><span class="o">=</span><span class="p">{</span>
                    <span class="s2">&quot;output_sizes&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;probability&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">},</span>
                    <span class="s2">&quot;allow_rechunk&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                <span class="p">},</span>
            <span class="p">)</span>

        <span class="c1"># ---------- Nonparametric ----------</span>
        <span class="k">elif</span> <span class="n">dm</span> <span class="o">==</span> <span class="s2">&quot;nonparam&quot;</span><span class="p">:</span>
            <span class="n">error_samples</span> <span class="o">=</span> <span class="n">Predictant</span> <span class="o">-</span> <span class="n">hindcast_det</span>
            <span class="n">hindcast_prob</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">calculate_tercile_probabilities_nonparametric</span><span class="p">,</span>
                <span class="n">hindcast_det</span><span class="p">,</span>
                <span class="n">error_samples</span><span class="p">,</span>
                <span class="n">T1_emp</span><span class="p">,</span>
                <span class="n">T2_emp</span><span class="p">,</span>
                <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;T&quot;</span><span class="p">,),</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,),</span> <span class="p">(),</span> <span class="p">()],</span>
                <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;probability&quot;</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">)],</span>
                <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">dask</span><span class="o">=</span><span class="s2">&quot;parallelized&quot;</span><span class="p">,</span>
                <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>
                <span class="n">dask_gufunc_kwargs</span><span class="o">=</span><span class="p">{</span>
                    <span class="s2">&quot;output_sizes&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;probability&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">},</span>
                    <span class="s2">&quot;allow_rechunk&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                <span class="p">},</span>
            <span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid dist_method: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">dist_method</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">hindcast_prob</span> <span class="o">=</span> <span class="n">hindcast_prob</span><span class="o">.</span><span class="n">assign_coords</span><span class="p">(</span>
            <span class="n">probability</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;probability&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;PB&quot;</span><span class="p">,</span> <span class="s2">&quot;PN&quot;</span><span class="p">,</span> <span class="s2">&quot;PA&quot;</span><span class="p">])</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">hindcast_prob</span> <span class="o">*</span> <span class="n">mask</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="s2">&quot;probability&quot;</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="s2">&quot;Y&quot;</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">)</span></div>


        
<div class="viewcode-block" id="WAS_PoissonRegression.forecast">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_PoissonRegression.forecast">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">forecast</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Predictant</span><span class="p">,</span> <span class="n">clim_year_start</span><span class="p">,</span> <span class="n">clim_year_end</span><span class="p">,</span> <span class="n">Predictor</span><span class="p">,</span> <span class="n">hindcast_det</span><span class="p">,</span> <span class="n">Predictor_for_year</span><span class="p">,</span> <span class="n">best_code_da</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">best_shape_da</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">best_loc_da</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">best_scale_da</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generate forecasts for a single time (e.g., future year) and compute </span>
<span class="sd">        tercile probabilities based on the chosen distribution method.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Predictant : xarray.DataArray</span>
<span class="sd">            Target variable with dimensions (T, Y, X).</span>
<span class="sd">        clim_year_start : int</span>
<span class="sd">            Start year of climatology period.</span>
<span class="sd">        clim_year_end : int</span>
<span class="sd">            End year of climatology period.</span>
<span class="sd">        Predictor : xarray.DataArray</span>
<span class="sd">            Historical predictor data with dimensions (T, features).</span>
<span class="sd">        hindcast_det : xarray.DataArray</span>
<span class="sd">            Deterministic hindcast array that includes &#39;error&#39; and &#39;prediction&#39; over the historical period.</span>
<span class="sd">        Predictor_for_year : xarray.DataArray</span>
<span class="sd">            Predictor data for the forecast year, shape (features,) or (1, features).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        tuple (result_, hindcast_prob)</span>
<span class="sd">            result_  : xarray.DataArray or numpy array with the forecast&#39;s [error, prediction].</span>
<span class="sd">            hindcast_prob : xarray.DataArray of shape (probability=3, Y, X) with PB, PN, and PA.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Chunk sizes for parallel processing</span>
        <span class="n">chunksize_x</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">Predictant</span><span class="o">.</span><span class="n">get_index</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">))</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span><span class="p">))</span>
        <span class="n">chunksize_y</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">Predictant</span><span class="o">.</span><span class="n">get_index</span><span class="p">(</span><span class="s2">&quot;Y&quot;</span><span class="p">))</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span><span class="p">))</span>

        <span class="c1"># Align the time dimension</span>
        <span class="n">Predictor</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">Predictant</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span>
        <span class="n">Predictant</span> <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="s1">&#39;T&#39;</span><span class="p">,</span> <span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">)</span>

        <span class="c1"># Squeeze the forecast predictor data if needed</span>
        <span class="n">Predictor_for_year_</span> <span class="o">=</span> <span class="n">Predictor_for_year</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>

        <span class="c1"># We&#39;ll apply our polynomial regression in parallel across Y,X. </span>
        <span class="c1"># Because we are forecasting a single point in time, y_test is unknown, so we omit it or set it to NaN.</span>
        <span class="n">y_test</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">Predictant</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>  <span class="c1"># shape (Y,X)</span>

        <span class="c1"># Create a Dask client</span>
        <span class="n">client</span> <span class="o">=</span> <span class="n">Client</span><span class="p">(</span><span class="n">n_workers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span><span class="p">,</span> <span class="n">threads_per_worker</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Apply fit_predict to get the forecast for each grid cell </span>
        <span class="c1"># We&#39;ll produce shape (2,) for each cell: [error, prediction]</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">,</span>
            <span class="n">Predictor</span><span class="p">,</span>                         <span class="c1"># shape (T, features)</span>
            <span class="n">Predictant</span><span class="o">.</span><span class="n">chunk</span><span class="p">({</span><span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">chunksize_y</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">chunksize_x</span><span class="p">}),</span>
            <span class="n">Predictor_for_year_</span><span class="p">,</span>
            <span class="n">y_test</span><span class="o">.</span><span class="n">chunk</span><span class="p">({</span><span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">chunksize_y</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">chunksize_x</span><span class="p">}),</span>
            <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s1">&#39;T&#39;</span><span class="p">,</span> <span class="s1">&#39;features&#39;</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;T&#39;</span><span class="p">,),</span> <span class="p">(</span><span class="s1">&#39;features&#39;</span><span class="p">,),</span> <span class="p">()],</span>
            <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">dask</span><span class="o">=</span><span class="s1">&#39;parallelized&#39;</span><span class="p">,</span>
            <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s1">&#39;output&#39;</span><span class="p">,)],</span>
            <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;float&#39;</span><span class="p">],</span>
            <span class="n">dask_gufunc_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;output_sizes&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;output&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">}}</span>
        <span class="p">)</span>

        <span class="c1"># Compute and close the client</span>
        <span class="n">result_</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
        <span class="n">result_</span> <span class="o">=</span> <span class="n">result_</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">output</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># result_ =&gt; dims (output=2, Y, X). </span>
        <span class="c1"># For a real future forecast, &quot;error&quot; is NaN, &quot;prediction&quot; is the forecast.</span>

        <span class="c1"># 2) Compute thresholds T1, T2 from climatology</span>
        <span class="n">index_start</span> <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">get_index</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">get_loc</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">clim_year_start</span><span class="p">))</span><span class="o">.</span><span class="n">start</span>
        <span class="n">index_end</span>   <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">get_index</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">get_loc</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">clim_year_end</span><span class="p">))</span><span class="o">.</span><span class="n">stop</span>
        <span class="n">rainfall_for_tercile</span> <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="nb">slice</span><span class="p">(</span><span class="n">index_start</span><span class="p">,</span> <span class="n">index_end</span><span class="p">))</span>
        <span class="n">terciles</span> <span class="o">=</span> <span class="n">rainfall_for_tercile</span><span class="o">.</span><span class="n">quantile</span><span class="p">([</span><span class="mf">0.32</span><span class="p">,</span> <span class="mf">0.67</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="s1">&#39;T&#39;</span><span class="p">)</span>
        <span class="n">T1_emp</span> <span class="o">=</span> <span class="n">terciles</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">quantile</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">drop_vars</span><span class="p">(</span><span class="s1">&#39;quantile&#39;</span><span class="p">)</span>
        <span class="n">T2_emp</span> <span class="o">=</span> <span class="n">terciles</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">quantile</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">drop_vars</span><span class="p">(</span><span class="s1">&#39;quantile&#39;</span><span class="p">)</span>
        <span class="n">error_variance</span> <span class="o">=</span> <span class="p">(</span><span class="n">Predictant</span> <span class="o">-</span> <span class="n">hindcast_det</span><span class="p">)</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="s1">&#39;T&#39;</span><span class="p">)</span>
        
        <span class="c1"># Expand single prediction to T=1 so probability methods can handle it</span>
        <span class="n">forecast_expanded</span> <span class="o">=</span> <span class="n">result_</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span>
            <span class="n">T</span><span class="o">=</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">Timestamp</span><span class="p">(</span><span class="n">Predictor_for_year</span><span class="o">.</span><span class="n">coords</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">to_pydatetime</span><span class="p">()]</span>
        <span class="p">)</span>
        <span class="n">year</span> <span class="o">=</span> <span class="n">Predictor_for_year</span><span class="o">.</span><span class="n">coords</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;datetime64[Y]&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1970</span>
        <span class="c1"># year = Predictor_for_year.coords[&#39;T&#39;].values.astype(&#39;datetime64[Y]&#39;).astype(int)[0] + 1970  </span>
        <span class="n">T_value_1</span> <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">coords</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>  <span class="c1"># Get the datetime64 value from da1</span>
        <span class="n">month_1</span> <span class="o">=</span> <span class="n">T_value_1</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;datetime64[M]&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span> <span class="o">%</span> <span class="mi">12</span> <span class="o">+</span> <span class="mi">1</span>  <span class="c1"># Extract month</span>
        <span class="n">new_T_value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">datetime64</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">year</span><span class="si">}</span><span class="s2">-</span><span class="si">{</span><span class="n">month_1</span><span class="si">:</span><span class="s2">02d</span><span class="si">}</span><span class="s2">-</span><span class="si">{</span><span class="mi">1</span><span class="si">:</span><span class="s2">02d</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        
        <span class="n">forecast_expanded</span> <span class="o">=</span> <span class="n">forecast_expanded</span><span class="o">.</span><span class="n">assign_coords</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span><span class="p">([</span><span class="n">new_T_value</span><span class="p">],</span> <span class="n">dims</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">]))</span>
        <span class="n">forecast_expanded</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">forecast_expanded</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;datetime64[ns]&#39;</span><span class="p">)</span>

        <span class="n">dof</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">rainfall_for_tercile</span><span class="o">.</span><span class="n">sizes</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">])</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

        <span class="n">dm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dist_method</span>

        <span class="c1"># ---------- BESTFIT ----------</span>
        <span class="k">if</span> <span class="n">dm</span> <span class="o">==</span> <span class="s2">&quot;bestfit&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">v</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="p">(</span><span class="n">best_code_da</span><span class="p">,</span> <span class="n">best_shape_da</span><span class="p">,</span> <span class="n">best_loc_da</span><span class="p">,</span> <span class="n">best_scale_da</span><span class="p">)):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;dist_method=&#39;bestfit&#39; requires best_code_da, best_shape_da, best_loc_da, best_scale_da.&quot;</span>
                <span class="p">)</span>
            
            <span class="n">T1</span><span class="p">,</span> <span class="n">T2</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_ppf_terciles_from_code</span><span class="p">,</span>
                <span class="n">best_code_da</span><span class="p">,</span>
                <span class="n">best_shape_da</span><span class="p">,</span>
                <span class="n">best_loc_da</span><span class="p">,</span>
                <span class="n">best_scale_da</span><span class="p">,</span>
                <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[(),</span> <span class="p">(),</span> <span class="p">(),</span> <span class="p">()],</span>
                <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(),</span> <span class="p">()],</span>
                <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">dask</span><span class="o">=</span><span class="s2">&quot;parallelized&quot;</span><span class="p">,</span>
                <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span>
            <span class="p">)</span>

            <span class="n">forecast_prob</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">calculate_tercile_probabilities_bestfit</span><span class="p">,</span>
                <span class="n">forecast_expanded</span><span class="p">,</span>
                <span class="n">error_variance</span><span class="p">,</span>
                <span class="n">T1</span><span class="p">,</span>
                <span class="n">T2</span><span class="p">,</span>
                <span class="n">best_code_da</span><span class="p">,</span>
                <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;T&quot;</span><span class="p">,),</span> <span class="p">(),</span> <span class="p">(),</span> <span class="p">(),</span> <span class="p">()],</span>
                <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;probability&quot;</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">)],</span>
                <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">dask</span><span class="o">=</span><span class="s2">&quot;parallelized&quot;</span><span class="p">,</span>
                <span class="n">kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;dof&quot;</span><span class="p">:</span> <span class="n">dof</span><span class="p">},</span>
                <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>
                <span class="n">dask_gufunc_kwargs</span><span class="o">=</span><span class="p">{</span>
                    <span class="s2">&quot;output_sizes&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;probability&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">},</span>
                    <span class="s2">&quot;allow_rechunk&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                <span class="p">},</span>
            <span class="p">)</span>

        <span class="c1"># ---------- Nonparametric ----------</span>
        <span class="k">elif</span> <span class="n">dm</span> <span class="o">==</span> <span class="s2">&quot;nonparam&quot;</span><span class="p">:</span>
            <span class="n">error_samples</span> <span class="o">=</span> <span class="n">Predictant</span> <span class="o">-</span> <span class="n">hindcast_det</span>
            <span class="n">forecast_prob</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">calculate_tercile_probabilities_nonparametric</span><span class="p">,</span>
                <span class="n">forecast_expanded</span><span class="p">,</span>
                <span class="n">error_samples</span><span class="p">,</span>
                <span class="n">T1_emp</span><span class="p">,</span>
                <span class="n">T2_emp</span><span class="p">,</span>
                <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;T&quot;</span><span class="p">,),</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,),</span> <span class="p">(),</span> <span class="p">()],</span>
                <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;probability&quot;</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">)],</span>
                <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">dask</span><span class="o">=</span><span class="s2">&quot;parallelized&quot;</span><span class="p">,</span>
                <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>
                <span class="n">dask_gufunc_kwargs</span><span class="o">=</span><span class="p">{</span>
                    <span class="s2">&quot;output_sizes&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;probability&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">},</span>
                    <span class="s2">&quot;allow_rechunk&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                <span class="p">},</span>
            <span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid dist_method: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">dist_method</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">forecast_prob</span> <span class="o">=</span> <span class="n">forecast_prob</span><span class="o">.</span><span class="n">assign_coords</span><span class="p">(</span><span class="n">probability</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;probability&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;PB&#39;</span><span class="p">,</span> <span class="s1">&#39;PN&#39;</span><span class="p">,</span> <span class="s1">&#39;PA&#39;</span><span class="p">]))</span>
        <span class="k">return</span> <span class="n">forecast_expanded</span><span class="p">,</span><span class="n">forecast_prob</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="s1">&#39;probability&#39;</span><span class="p">,</span> <span class="s1">&#39;T&#39;</span><span class="p">,</span> <span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">)</span></div>
</div>




<div class="viewcode-block" id="MARS">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.MARS">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">MARS</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Multivariate Adaptive Regression Splines with corrected forward/backward passes.&quot;&quot;&quot;</span>
    
<div class="viewcode-block" id="MARS.__init__">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.MARS.__init__">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">max_terms</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">21</span><span class="p">,</span> <span class="n">max_degree</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> 
                 <span class="n">penalty</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">3.0</span><span class="p">,</span> <span class="n">min_span</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Parameters:</span>
<span class="sd">        -----------</span>
<span class="sd">        max_terms : int</span>
<span class="sd">            Maximum number of basis functions (including intercept)</span>
<span class="sd">        max_degree : int</span>
<span class="sd">            Maximum interaction degree (1 = additive, 2 = pairwise interactions)</span>
<span class="sd">        penalty : float</span>
<span class="sd">            GCV penalty per knot (typically 2-4)</span>
<span class="sd">        min_span : int</span>
<span class="sd">            Minimum observations between knots</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_terms</span> <span class="o">=</span> <span class="n">max_terms</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_degree</span> <span class="o">=</span> <span class="n">max_degree</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">penalty</span> <span class="o">=</span> <span class="n">penalty</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_span</span> <span class="o">=</span> <span class="n">min_span</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">basis_functions</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># List of basis functions</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span> <span class="o">=</span> <span class="kc">None</span>          <span class="c1"># Coefficients</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">knots_</span> <span class="o">=</span> <span class="p">[]</span>           <span class="c1"># Knot positions for each variable</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dof_</span> <span class="o">=</span> <span class="mi">0</span>              <span class="c1"># Degrees of freedom</span></div>

        
<div class="viewcode-block" id="MARS._hinge">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.MARS._hinge">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">_hinge</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">knot</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">side</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Hinge function: max(0, x - t) or max(0, t - x).&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">side</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># Right hinge</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">x</span> <span class="o">-</span> <span class="n">knot</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>  <span class="c1"># Left hinge (-1)</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">knot</span> <span class="o">-</span> <span class="n">x</span><span class="p">)</span></div>

    
<div class="viewcode-block" id="MARS._evaluate_basis">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.MARS._evaluate_basis">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">_evaluate_basis</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">basis_idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Evaluate a specific basis function.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">basis_idx</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># Intercept</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        
        <span class="n">basis</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">basis_functions</span><span class="p">[</span><span class="n">basis_idx</span><span class="p">]</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">var_idx</span><span class="p">,</span> <span class="n">knot</span><span class="p">,</span> <span class="n">side</span> <span class="ow">in</span> <span class="n">basis</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_hinge</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="n">var_idx</span><span class="p">],</span> <span class="n">knot</span><span class="p">,</span> <span class="n">side</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">result</span></div>

    
<div class="viewcode-block" id="MARS._create_design_matrix">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.MARS._create_design_matrix">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">_create_design_matrix</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create design matrix from current basis functions.&quot;&quot;&quot;</span>
        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">n_basis</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">basis_functions</span><span class="p">)</span>
        <span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_basis</span><span class="p">))</span>
        
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_basis</span><span class="p">):</span>  <span class="c1"># Skip intercept (j=0)</span>
            <span class="n">B</span><span class="p">[:,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_evaluate_basis</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">B</span></div>

    
<div class="viewcode-block" id="MARS._find_knot_candidates">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.MARS._find_knot_candidates">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">_find_knot_candidates</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Find candidate knot positions for each variable.&quot;&quot;&quot;</span>
        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">candidates</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="c1"># Sort unique values of variable v</span>
            <span class="n">x_sorted</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="n">v</span><span class="p">])</span>
            
            <span class="c1"># Create candidate knots at percentiles (more robust than unique values)</span>
            <span class="n">percentiles</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">90</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>  <span class="c1"># 20 equally spaced percentiles</span>
            <span class="n">knots</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">x_sorted</span><span class="p">,</span> <span class="n">percentiles</span><span class="p">)</span>
            
            <span class="c1"># Remove knots too close to edges</span>
            <span class="n">valid_knots</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">knots</span><span class="p">):</span>
                <span class="n">left_count</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="n">v</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">t</span><span class="p">)</span>
                <span class="n">right_count</span> <span class="o">=</span> <span class="n">n_samples</span> <span class="o">-</span> <span class="n">left_count</span>
                <span class="k">if</span> <span class="n">left_count</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_span</span> <span class="ow">and</span> <span class="n">right_count</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_span</span><span class="p">:</span>
                    <span class="n">valid_knots</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
            
            <span class="n">candidates</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">valid_knots</span><span class="p">))</span>
        
        <span class="k">return</span> <span class="n">candidates</span></div>

    
<div class="viewcode-block" id="MARS._gcv_score">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.MARS._gcv_score">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">_gcv_score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">B</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> 
                   <span class="n">beta</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Calculate Generalized Cross-Validation score.&quot;&quot;&quot;</span>
        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">B</span> <span class="o">@</span> <span class="n">beta</span>
        <span class="n">rss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">y</span> <span class="o">-</span> <span class="n">y_pred</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
        
        <span class="c1"># Count unique knots</span>
        <span class="n">unique_knots</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">basis</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">basis_functions</span><span class="p">[</span><span class="mi">1</span><span class="p">:]:</span>  <span class="c1"># Skip intercept</span>
            <span class="k">for</span> <span class="n">var_idx</span><span class="p">,</span> <span class="n">knot</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">basis</span><span class="p">:</span>
                <span class="n">unique_knots</span><span class="o">.</span><span class="n">add</span><span class="p">((</span><span class="n">var_idx</span><span class="p">,</span> <span class="n">knot</span><span class="p">))</span>
        
        <span class="n">n_knots</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">unique_knots</span><span class="p">)</span>
        <span class="n">n_basis</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">basis_functions</span><span class="p">)</span>
        
        <span class="c1"># Effective degrees of freedom: n_basis + penalty * n_knots</span>
        <span class="n">effective_dof</span> <span class="o">=</span> <span class="n">n_basis</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">penalty</span> <span class="o">*</span> <span class="n">n_knots</span>
        
        <span class="c1"># GCV formula</span>
        <span class="k">if</span> <span class="n">effective_dof</span> <span class="o">&gt;=</span> <span class="n">n_samples</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
        
        <span class="n">gcv</span> <span class="o">=</span> <span class="n">rss</span> <span class="o">/</span> <span class="p">((</span><span class="n">n_samples</span> <span class="o">-</span> <span class="n">effective_dof</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">gcv</span></div>

    
<div class="viewcode-block" id="MARS.forward_pass">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.MARS.forward_pass">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward_pass</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Forward pass to add basis functions.&quot;&quot;&quot;</span>
        <span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">knot_candidates</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_find_knot_candidates</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        
        <span class="c1"># Start with intercept</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">basis_functions</span> <span class="o">=</span> <span class="p">[[]]</span>  <span class="c1"># Intercept</span>
        <span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">n_samples</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">beta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y</span><span class="p">)])</span>
        <span class="n">best_gcv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_gcv_score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
        
        <span class="n">iteration</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">basis_functions</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_terms</span> <span class="ow">and</span> <span class="n">iteration</span> <span class="o">&lt;</span> <span class="mi">100</span><span class="p">:</span>
            <span class="n">iteration</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">best_improvement</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">best_new_basis</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">best_new_B</span> <span class="o">=</span> <span class="kc">None</span>
            
            <span class="c1"># Try adding to each existing basis function</span>
            <span class="k">for</span> <span class="n">parent_idx</span><span class="p">,</span> <span class="n">parent_basis</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">basis_functions</span><span class="p">):</span>
                <span class="c1"># Check degree constraint</span>
                <span class="n">current_degree</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">parent_basis</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">current_degree</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_degree</span><span class="p">:</span>
                    <span class="k">continue</span>
                
                <span class="c1"># Find variables not yet used in this basis</span>
                <span class="n">used_vars</span> <span class="o">=</span> <span class="p">{</span><span class="n">v</span> <span class="k">for</span> <span class="n">v</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">parent_basis</span><span class="p">}</span>
                <span class="n">available_vars</span> <span class="o">=</span> <span class="p">[</span><span class="n">v</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_features</span><span class="p">)</span> <span class="k">if</span> <span class="n">v</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">used_vars</span><span class="p">]</span>
                
                <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">available_vars</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">knot</span> <span class="ow">in</span> <span class="n">knot_candidates</span><span class="p">[</span><span class="n">v</span><span class="p">]:</span>
                        <span class="c1"># Try both hinge directions</span>
                        <span class="k">for</span> <span class="n">side</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
                            <span class="c1"># Create new basis function</span>
                            <span class="n">new_basis</span> <span class="o">=</span> <span class="n">parent_basis</span> <span class="o">+</span> <span class="p">[(</span><span class="n">v</span><span class="p">,</span> <span class="n">knot</span><span class="p">,</span> <span class="n">side</span><span class="p">)]</span>
                            
                            <span class="c1"># Evaluate new basis function</span>
                            <span class="n">new_col</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>
                            <span class="k">for</span> <span class="n">var_idx</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">new_basis</span><span class="p">:</span>
                                <span class="n">new_col</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_hinge</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="n">var_idx</span><span class="p">],</span> <span class="n">t</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
                            
                            <span class="c1"># Add to design matrix</span>
                            <span class="n">new_B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">([</span><span class="n">B</span><span class="p">,</span> <span class="n">new_col</span><span class="p">])</span>
                            
                            <span class="c1"># Solve least squares</span>
                            <span class="k">try</span><span class="p">:</span>
                                <span class="n">new_beta</span><span class="p">,</span> <span class="n">residuals</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">lstsq</span><span class="p">(</span>
                                    <span class="n">new_B</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">rcond</span><span class="o">=</span><span class="kc">None</span>
                                <span class="p">)</span>
                            <span class="k">except</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">LinAlgError</span><span class="p">:</span>
                                <span class="k">continue</span>
                            
                            <span class="c1"># Check if new column is linearly independent</span>
                            <span class="k">if</span> <span class="n">rank</span> <span class="o">&lt;=</span> <span class="n">B</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
                                <span class="k">continue</span>
                            
                            <span class="c1"># Calculate GCV improvement</span>
                            <span class="n">new_gcv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_gcv_score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">new_B</span><span class="p">,</span> <span class="n">new_beta</span><span class="p">)</span>
                            <span class="n">improvement</span> <span class="o">=</span> <span class="n">best_gcv</span> <span class="o">-</span> <span class="n">new_gcv</span>
                            
                            <span class="k">if</span> <span class="n">improvement</span> <span class="o">&gt;</span> <span class="n">best_improvement</span><span class="p">:</span>
                                <span class="n">best_improvement</span> <span class="o">=</span> <span class="n">improvement</span>
                                <span class="n">best_new_basis</span> <span class="o">=</span> <span class="n">new_basis</span>
                                <span class="n">best_new_B</span> <span class="o">=</span> <span class="n">new_B</span>
                                <span class="n">best_new_beta</span> <span class="o">=</span> <span class="n">new_beta</span>
            
            <span class="c1"># Add the best new basis if it improves GCV</span>
            <span class="k">if</span> <span class="n">best_improvement</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">basis_functions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">best_new_basis</span><span class="p">)</span>
                <span class="n">B</span> <span class="o">=</span> <span class="n">best_new_B</span>
                <span class="n">beta</span> <span class="o">=</span> <span class="n">best_new_beta</span>
                <span class="n">best_gcv</span> <span class="o">=</span> <span class="n">best_gcv</span> <span class="o">-</span> <span class="n">best_improvement</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">break</span>
        
        <span class="k">return</span> <span class="n">B</span><span class="p">,</span> <span class="n">beta</span></div>

    
<div class="viewcode-block" id="MARS.backward_pass">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.MARS.backward_pass">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">backward_pass</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">B</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">beta</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Backward pass to prune basis functions.&quot;&quot;&quot;</span>
        <span class="n">n_basis</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">basis_functions</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">n_basis</span> <span class="o">&lt;=</span> <span class="mi">2</span><span class="p">:</span>  <span class="c1"># Need at least intercept + 1 basis</span>
            <span class="k">return</span>
        
        <span class="n">current_gcv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_gcv_score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
        
        <span class="n">improved</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">while</span> <span class="n">improved</span> <span class="ow">and</span> <span class="n">n_basis</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">improved</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="n">best_gcv</span> <span class="o">=</span> <span class="n">current_gcv</span>
            <span class="n">best_idx</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
            <span class="n">best_B</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">best_beta</span> <span class="o">=</span> <span class="kc">None</span>
            
            <span class="c1"># Try removing each basis function (except intercept)</span>
            <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_basis</span><span class="p">):</span>
                <span class="c1"># Create pruned model</span>
                <span class="n">pruned_basis</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">basis_functions</span><span class="p">[:</span><span class="n">idx</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">basis_functions</span><span class="p">[</span><span class="n">idx</span><span class="o">+</span><span class="mi">1</span><span class="p">:]</span>
                
                <span class="c1"># Rebuild design matrix</span>
                <span class="n">pruned_B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">len</span><span class="p">(</span><span class="n">pruned_basis</span><span class="p">)))</span>
                <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">basis</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">pruned_basis</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="mi">1</span><span class="p">):</span>
                    <span class="n">col</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                    <span class="k">for</span> <span class="n">var_idx</span><span class="p">,</span> <span class="n">knot</span><span class="p">,</span> <span class="n">side</span> <span class="ow">in</span> <span class="n">basis</span><span class="p">:</span>
                        <span class="n">col</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_hinge</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="n">var_idx</span><span class="p">],</span> <span class="n">knot</span><span class="p">,</span> <span class="n">side</span><span class="p">)</span>
                    <span class="n">pruned_B</span><span class="p">[:,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">col</span>
                
                <span class="c1"># Fit pruned model</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">pruned_beta</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">lstsq</span><span class="p">(</span><span class="n">pruned_B</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">rcond</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">rank</span> <span class="o">&lt;</span> <span class="n">pruned_B</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
                        <span class="k">continue</span>
                <span class="k">except</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">LinAlgError</span><span class="p">:</span>
                    <span class="k">continue</span>
                
                <span class="c1"># Calculate GCV</span>
                <span class="n">gcv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_gcv_score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">pruned_B</span><span class="p">,</span> <span class="n">pruned_beta</span><span class="p">)</span>
                
                <span class="k">if</span> <span class="n">gcv</span> <span class="o">&lt;</span> <span class="n">best_gcv</span><span class="p">:</span>
                    <span class="n">best_gcv</span> <span class="o">=</span> <span class="n">gcv</span>
                    <span class="n">best_idx</span> <span class="o">=</span> <span class="n">idx</span>
                    <span class="n">best_B</span> <span class="o">=</span> <span class="n">pruned_B</span>
                    <span class="n">best_beta</span> <span class="o">=</span> <span class="n">pruned_beta</span>
            
            <span class="c1"># Apply best pruning if found</span>
            <span class="k">if</span> <span class="n">best_idx</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">basis_functions</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">basis_functions</span><span class="p">[:</span><span class="n">best_idx</span><span class="p">]</span> <span class="o">+</span> 
                    <span class="bp">self</span><span class="o">.</span><span class="n">basis_functions</span><span class="p">[</span><span class="n">best_idx</span><span class="o">+</span><span class="mi">1</span><span class="p">:]</span>
                <span class="p">)</span>
                <span class="n">B</span> <span class="o">=</span> <span class="n">best_B</span>
                <span class="n">beta</span> <span class="o">=</span> <span class="n">best_beta</span>
                <span class="n">current_gcv</span> <span class="o">=</span> <span class="n">best_gcv</span>
                <span class="n">n_basis</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">basis_functions</span><span class="p">)</span>
                <span class="n">improved</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">break</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span> <span class="o">=</span> <span class="n">beta</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dof_</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">basis_functions</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">penalty</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_count_knots</span><span class="p">()</span></div>

    
<div class="viewcode-block" id="MARS._count_knots">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.MARS._count_knots">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">_count_knots</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Count unique knots in the model.&quot;&quot;&quot;</span>
        <span class="n">unique_knots</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">basis</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">basis_functions</span><span class="p">[</span><span class="mi">1</span><span class="p">:]:</span>
            <span class="k">for</span> <span class="n">var_idx</span><span class="p">,</span> <span class="n">knot</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">basis</span><span class="p">:</span>
                <span class="n">unique_knots</span><span class="o">.</span><span class="n">add</span><span class="p">((</span><span class="n">var_idx</span><span class="p">,</span> <span class="n">knot</span><span class="p">))</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">unique_knots</span><span class="p">)</span></div>

    
<div class="viewcode-block" id="MARS.fit">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.MARS.fit">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Fit MARS model.&quot;&quot;&quot;</span>
        <span class="c1"># Input validation</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
        
        <span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;X and y must have same number of samples&quot;</span><span class="p">)</span>
        
        <span class="c1"># Forward pass</span>
        <span class="n">B</span><span class="p">,</span> <span class="n">beta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward_pass</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        
        <span class="c1"># Backward pass</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">backward_pass</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
        
        <span class="c1"># Store final coefficients</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span> <span class="o">=</span> <span class="n">beta</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dof_</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">basis_functions</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">penalty</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_count_knots</span><span class="p">()</span>
        
        <span class="k">return</span> <span class="bp">self</span></div>

    
<div class="viewcode-block" id="MARS.predict">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.MARS.predict">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Predict using fitted MARS model.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Model must be fitted before prediction&quot;</span><span class="p">)</span>
        
        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">n_basis</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">basis_functions</span><span class="p">)</span>
        
        <span class="c1"># Create design matrix</span>
        <span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_basis</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_basis</span><span class="p">):</span>
            <span class="n">col</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">var_idx</span><span class="p">,</span> <span class="n">knot</span><span class="p">,</span> <span class="n">side</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">basis_functions</span><span class="p">[</span><span class="n">j</span><span class="p">]:</span>
                <span class="n">col</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_hinge</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="n">var_idx</span><span class="p">],</span> <span class="n">knot</span><span class="p">,</span> <span class="n">side</span><span class="p">)</span>
            <span class="n">B</span><span class="p">[:,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">col</span>
        
        <span class="k">return</span> <span class="n">B</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span></div>

    
<div class="viewcode-block" id="MARS.get_formula">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.MARS.get_formula">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_formula</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">feature_names</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get human-readable formula for the model.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">feature_names</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">feature_names</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;X</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">)]</span>  <span class="c1"># Placeholder</span>
        
        <span class="n">terms</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="p">(</span><span class="n">coef</span><span class="p">,</span> <span class="n">basis</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">basis_functions</span><span class="p">)):</span>
            <span class="k">if</span> <span class="n">j</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># Intercept</span>
                <span class="n">terms</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">coef</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">basis</span><span class="p">:</span>
                <span class="n">basis_str</span> <span class="o">=</span> <span class="s2">&quot; * &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;max(0, </span><span class="si">{</span><span class="n">feature_names</span><span class="p">[</span><span class="n">v</span><span class="p">]</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">&#39;-&#39;</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">s</span><span class="o">==</span><span class="mi">1</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="s1">&#39;+&#39;</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">t</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">)&quot;</span>
                    <span class="k">for</span> <span class="n">v</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">basis</span>
                <span class="p">)</span>
                <span class="n">terms</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">coef</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> * </span><span class="si">{</span><span class="n">basis_str</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="s2">&quot; + &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">terms</span><span class="p">)</span></div>
</div>


<div class="viewcode-block" id="WAS_MARS_Model">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_MARS_Model">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">WAS_MARS_Model</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A class to perform MARS-based modeling on spatiotemporal datasets for climate prediction.</span>
<span class="sd">    MARS stands for Multivariate Adaptive Regression Splines with Generalized Cross-Validation.</span>

<span class="sd">    This class is designed to work with Dask and Xarray for parallelized, high-performance </span>
<span class="sd">    regression computations across large datasets with spatial and temporal dimensions. The primary </span>
<span class="sd">    methods are for fitting the model, making predictions, and calculating probabilistic predictions </span>
<span class="sd">    for climate terciles. </span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    nb_cores : int, optional</span>
<span class="sd">        The number of CPU cores to use for parallel computation (default is 1).</span>
<span class="sd">    dist_method : str, optional</span>
<span class="sd">        Distribution method for tercile probability calculations. One of</span>
<span class="sd">        {&quot;t&quot;,&quot;gamma&quot;,&quot;normal&quot;,&quot;lognormal&quot;,&quot;nonparam&quot;}. Default = &quot;gamma&quot;.</span>
<span class="sd">    max_terms : int, optional</span>
<span class="sd">        Maximum number of basis functions for MARS (default: 21).</span>
<span class="sd">    max_degree : int, optional</span>
<span class="sd">        Maximum degree of interaction for MARS (default: 1).</span>
<span class="sd">    c : float, optional</span>
<span class="sd">        Cost parameter for effective parameters in GCV for MARS (default: 3).</span>

<span class="sd">    Methods</span>
<span class="sd">    -------</span>
<span class="sd">    fit_predict(x, y, x_test, y_test=None)</span>
<span class="sd">        Fits a MARS model, makes predictions, and calculates error if y_test is provided.</span>

<span class="sd">    compute_model(X_train, y_train, X_test, y_test)</span>
<span class="sd">        Applies the MARS model across a dataset using parallel computation with Dask.</span>

<span class="sd">    compute_prob(Predictant, clim_year_start, clim_year_end, Predictor, hindcast_det)</span>
<span class="sd">        Computes tercile probabilities for hindcast predictions over specified years.</span>

<span class="sd">    forecast(Predictant, clim_year_start, clim_year_end, Predictor, hindcast_det, Predictor_for_year)</span>
<span class="sd">        Generates a single-year forecast and computes tercile probabilities.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="WAS_MARS_Model.__init__">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_MARS_Model.__init__">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nb_cores</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dist_method</span><span class="o">=</span><span class="s2">&quot;nonparam&quot;</span><span class="p">,</span> <span class="n">max_terms</span><span class="o">=</span><span class="mi">21</span><span class="p">,</span> <span class="n">max_degree</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initializes the WAS_MARS_Model with specified parameters.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        nb_cores : int, optional</span>
<span class="sd">            Number of CPU cores to use for parallel computation, by default 1.</span>
<span class="sd">        dist_method : str, optional</span>
<span class="sd">            Distribution method to compute tercile probabilities, by default &quot;gamma&quot;.</span>
<span class="sd">        max_terms : int, optional</span>
<span class="sd">            Maximum number of basis functions for MARS, by default 21.</span>
<span class="sd">        max_degree : int, optional</span>
<span class="sd">            Maximum degree of interaction for MARS, by default 1.</span>
<span class="sd">        c : float, optional</span>
<span class="sd">            Cost parameter for GCV in MARS, by default 3.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span> <span class="o">=</span> <span class="n">nb_cores</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dist_method</span> <span class="o">=</span> <span class="n">dist_method</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_terms</span> <span class="o">=</span> <span class="n">max_terms</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_degree</span> <span class="o">=</span> <span class="n">max_degree</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">c</span> <span class="o">=</span> <span class="n">c</span></div>

    
<div class="viewcode-block" id="WAS_MARS_Model.fit_predict">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_MARS_Model.fit_predict">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">fit_predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fits a MARS model to the provided training data, makes predictions </span>
<span class="sd">        on the test data, and calculates the prediction error (if y_test is provided).</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        x : array-like, shape (n_samples, n_features)</span>
<span class="sd">            Training data (predictors).</span>
<span class="sd">        y : array-like, shape (n_samples,)</span>
<span class="sd">            Training targets.</span>
<span class="sd">        x_test : array-like, shape (n_features,) or (1, n_features)</span>
<span class="sd">            Test data (predictors).</span>
<span class="sd">        y_test : float or None</span>
<span class="sd">            Test target value. If None, no error is computed.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        np.ndarray</span>
<span class="sd">            If y_test is not None, returns [error, prediction].</span>
<span class="sd">            If y_test is None, returns [prediction].</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">MARS</span><span class="p">(</span><span class="n">max_terms</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_terms</span><span class="p">,</span> <span class="n">max_degree</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_degree</span><span class="p">,</span> <span class="n">penalty</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">c</span><span class="p">)</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">&amp;</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">mask</span><span class="p">):</span>
            <span class="n">y_clean</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>
            <span class="n">x_clean</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">mask</span><span class="p">,</span> <span class="p">:]</span>
            <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_clean</span><span class="p">,</span> <span class="n">y_clean</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">x_test</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">x_test</span> <span class="o">=</span> <span class="n">x_test</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

            <span class="n">preds</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
            <span class="n">preds</span><span class="p">[</span><span class="n">preds</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>  

            <span class="k">if</span> <span class="n">y_test</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">error_</span> <span class="o">=</span> <span class="n">y_test</span> <span class="o">-</span> <span class="n">preds</span>
                <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">error_</span><span class="p">,</span> <span class="n">preds</span><span class="p">])</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Only return prediction if y_test is None</span>
                <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">preds</span><span class="p">])</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># If no valid data, return NaNs</span>
            <span class="k">if</span> <span class="n">y_test</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">])</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">])</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span></div>


<div class="viewcode-block" id="WAS_MARS_Model.compute_model">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_MARS_Model.compute_model">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">compute_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Applies MARS regression across a spatiotemporal dataset in parallel.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X_train : xarray.DataArray</span>
<span class="sd">            Training predictors with dims (&#39;T&#39;,&#39;features&#39;).</span>
<span class="sd">        y_train : xarray.DataArray</span>
<span class="sd">            Training targets with dims (&#39;T&#39;,&#39;Y&#39;,&#39;X&#39;).</span>
<span class="sd">        X_test : xarray.DataArray</span>
<span class="sd">            Test predictors, shape (&#39;features&#39;,) or (T, features).</span>
<span class="sd">        y_test : xarray.DataArray</span>
<span class="sd">            Test targets with dims (&#39;Y&#39;,&#39;X&#39;), or broadcastable.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        xarray.DataArray</span>
<span class="sd">            dims (&#39;output&#39;,&#39;Y&#39;,&#39;X&#39;), where &#39;output&#39;=[error, prediction].</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">chunksize_x</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="o">.</span><span class="n">get_index</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">))</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span><span class="p">))</span>
        <span class="n">chunksize_y</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="o">.</span><span class="n">get_index</span><span class="p">(</span><span class="s2">&quot;Y&quot;</span><span class="p">))</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span><span class="p">))</span>
        
        <span class="c1"># Align times</span>
        <span class="n">X_train</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span>
        <span class="n">y_train</span> <span class="o">=</span> <span class="n">y_train</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="s1">&#39;T&#39;</span><span class="p">,</span> <span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">)</span>
        <span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
        <span class="n">y_test</span> <span class="o">=</span> <span class="n">y_test</span><span class="o">.</span><span class="n">drop_vars</span><span class="p">(</span><span class="s1">&#39;T&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">)</span>

        <span class="n">client</span> <span class="o">=</span> <span class="n">Client</span><span class="p">(</span><span class="n">n_workers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span><span class="p">,</span> <span class="n">threads_per_worker</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">result_da</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">,</span>
            <span class="n">X_train</span><span class="p">,</span>
            <span class="n">y_train</span><span class="o">.</span><span class="n">chunk</span><span class="p">({</span><span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">chunksize_y</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">chunksize_x</span><span class="p">}),</span>
            <span class="n">X_test</span><span class="p">,</span>
            <span class="n">y_test</span><span class="o">.</span><span class="n">chunk</span><span class="p">({</span><span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">chunksize_y</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">chunksize_x</span><span class="p">}),</span>
            <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s1">&#39;T&#39;</span><span class="p">,</span><span class="s1">&#39;features&#39;</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;T&#39;</span><span class="p">,),</span> <span class="p">(</span><span class="s1">&#39;features&#39;</span><span class="p">,),</span> <span class="p">()],</span>
            <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">dask</span><span class="o">=</span><span class="s1">&#39;parallelized&#39;</span><span class="p">,</span>
            <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s1">&#39;output&#39;</span><span class="p">,)],</span>
            <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;float&#39;</span><span class="p">],</span>
            <span class="n">dask_gufunc_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;output_sizes&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;output&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">}},</span>
        <span class="p">)</span>
        <span class="n">result_</span> <span class="o">=</span> <span class="n">result_da</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
        <span class="n">client</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">result_</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">output</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></div>

    
    <span class="c1"># ------------------ Probability Calculation Methods ------------------</span>

<div class="viewcode-block" id="WAS_MARS_Model._ppf_terciles_from_code">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_MARS_Model._ppf_terciles_from_code">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_ppf_terciles_from_code</span><span class="p">(</span><span class="n">dist_code</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return tercile thresholds (T1, T2) from best-fit distribution parameters.</span>
<span class="sd">    </span>
<span class="sd">        dist_code:</span>
<span class="sd">            1: norm</span>
<span class="sd">            2: lognorm</span>
<span class="sd">            3: expon</span>
<span class="sd">            4: gamma</span>
<span class="sd">            5: weibull_min</span>
<span class="sd">            6: t</span>
<span class="sd">            7: poisson</span>
<span class="sd">            8: nbinom</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">dist_code</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
    
        <span class="n">code</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">dist_code</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                    <span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">lognorm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                    <span class="n">lognorm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">expon</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                    <span class="n">expon</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">gamma</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                    <span class="n">gamma</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">5</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">weibull_min</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                    <span class="n">weibull_min</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">6</span><span class="p">:</span>
                <span class="c1"># Note: Renamed &#39;t_dist&#39; to &#39;t&#39; for standard scipy.stats</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">t</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                    <span class="n">t</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">7</span><span class="p">:</span>
                <span class="c1"># Poisson: poisson.ppf(q, mu, loc=0)</span>
                <span class="c1"># ASSUMPTION: &#39;mu&#39; (mean) is passed as &#39;shape&#39;</span>
                <span class="c1">#             &#39;loc&#39; is passed as &#39;loc&#39;</span>
                <span class="c1">#             &#39;scale&#39; is unused</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">poisson</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">),</span>
                    <span class="n">poisson</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">8</span><span class="p">:</span>
                <span class="c1"># Negative Binomial: nbinom.ppf(q, n, p, loc=0)</span>
                <span class="c1"># ASSUMPTION: &#39;n&#39; (successes) is passed as &#39;shape&#39;</span>
                <span class="c1">#             &#39;p&#39; (probability) is passed as &#39;scale&#39;</span>
                <span class="c1">#             &#39;loc&#39; is passed as &#39;loc&#39;</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">nbinom</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.32</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">scale</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">),</span>
                    <span class="n">nbinom</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">scale</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">),</span>
                <span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
    
        <span class="c1"># Fallback if code is not 1-8</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span></div>

        
<div class="viewcode-block" id="WAS_MARS_Model.weibull_shape_solver">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_MARS_Model.weibull_shape_solver">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">weibull_shape_solver</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">V</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Function to find the root of the Weibull shape parameter &#39;k&#39;.</span>
<span class="sd">        We find &#39;k&#39; such that the theoretical variance/mean^2 ratio</span>
<span class="sd">        matches the observed V/M^2 ratio.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Guard against invalid &#39;k&#39; values during solving</span>
        <span class="k">if</span> <span class="n">k</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">g1</span> <span class="o">=</span> <span class="n">gamma_function</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="mi">1</span><span class="o">/</span><span class="n">k</span><span class="p">)</span>
            <span class="n">g2</span> <span class="o">=</span> <span class="n">gamma_function</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="mi">2</span><span class="o">/</span><span class="n">k</span><span class="p">)</span>
            
            <span class="c1"># This is the V/M^2 ratio *implied by k*</span>
            <span class="n">implied_v_over_m_sq</span> <span class="o">=</span> <span class="p">(</span><span class="n">g2</span> <span class="o">/</span> <span class="p">(</span><span class="n">g1</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span> <span class="o">-</span> <span class="mi">1</span>
            
            <span class="c1"># This is the *observed* ratio</span>
            <span class="n">observed_v_over_m_sq</span> <span class="o">=</span> <span class="n">V</span> <span class="o">/</span> <span class="p">(</span><span class="n">M</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
            
            <span class="c1"># Return the difference (we want this to be 0)</span>
            <span class="k">return</span> <span class="n">observed_v_over_m_sq</span> <span class="o">-</span> <span class="n">implied_v_over_m_sq</span>
        <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
            <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span> <span class="c1"># Handle math errors</span></div>


<div class="viewcode-block" id="WAS_MARS_Model.calculate_tercile_probabilities_bestfit">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_MARS_Model.calculate_tercile_probabilities_bestfit">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">calculate_tercile_probabilities_bestfit</span><span class="p">(</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">error_variance</span><span class="p">,</span> <span class="n">T1</span><span class="p">,</span> <span class="n">T2</span><span class="p">,</span> <span class="n">dist_code</span><span class="p">,</span> <span class="n">dof</span> 
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generic tercile probabilities using best-fit family per grid cell.</span>

<span class="sd">        Inputs (per grid cell):</span>
<span class="sd">        - best_guess : 1D array over T (hindcast_det or forecast_det)</span>
<span class="sd">        - T1, T2     : scalar terciles from climatological best-fit distribution</span>
<span class="sd">        - dist_code  : int, as in _ppf_terciles_from_code</span>
<span class="sd">        - shape, loc, scale : scalars from climatology fit</span>

<span class="sd">        Strategy:</span>
<span class="sd">        - For each time step, build a predictive distribution of the same family:</span>
<span class="sd">            * Use best_guess[t] to adjust mean / location;</span>
<span class="sd">            * Keep shape parameters from climatology.</span>
<span class="sd">        - Then compute probabilities:</span>
<span class="sd">            P(B) = F(T1), P(N) = F(T2) - F(T1), P(A) = 1 - F(T2).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        
        <span class="n">best_guess</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">best_guess</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span>
        <span class="n">error_variance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">error_variance</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
        <span class="c1"># T1 = np.asarray(T1, dtype=float)</span>
        <span class="c1"># T2 = np.asarray(T2, dtype=float)</span>
        <span class="n">n_time</span> <span class="o">=</span> <span class="n">best_guess</span><span class="o">.</span><span class="n">size</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="n">n_time</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">best_guess</span><span class="p">))</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">dist_code</span><span class="p">)</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">T1</span><span class="p">)</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">T2</span><span class="p">)</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">error_variance</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">out</span>

        <span class="n">code</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">dist_code</span><span class="p">)</span>

        <span class="c1"># Normal: loc = forecast; scale from clim</span>
        <span class="k">if</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">error_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">error_variance</span><span class="p">)</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">error_std</span><span class="p">)</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">error_std</span><span class="p">)</span> <span class="o">-</span> <span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">error_std</span><span class="p">)</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">error_std</span><span class="p">)</span>

        <span class="c1"># Lognormal: shape = sigma from clim; enforce mean = best_guess</span>
        <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">sigma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">error_variance</span> <span class="o">/</span> <span class="p">(</span><span class="n">best_guess</span><span class="o">**</span><span class="mi">2</span><span class="p">)))</span>
            <span class="n">mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">best_guess</span><span class="p">)</span> <span class="o">-</span> <span class="n">sigma</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="mi">2</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">lognorm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">mu</span><span class="p">))</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">lognorm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">mu</span><span class="p">))</span> <span class="o">-</span> <span class="n">lognorm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">mu</span><span class="p">))</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">lognorm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">mu</span><span class="p">))</span>      


        <span class="c1"># Exponential: keep scale from clim; shift loc so mean = best_guess</span>
        <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
            <span class="n">c1</span> <span class="o">=</span> <span class="n">expon</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">error_variance</span><span class="p">))</span>
            <span class="n">c2</span> <span class="o">=</span> <span class="n">expon</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc_t</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">error_variance</span><span class="p">))</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c2</span> <span class="o">-</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">c2</span>

        <span class="c1"># Gamma: use shape from clim; set scale so mean = best_guess</span>
        <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
            <span class="n">alpha</span> <span class="o">=</span> <span class="p">(</span><span class="n">best_guess</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="n">error_variance</span>
            <span class="n">theta</span> <span class="o">=</span> <span class="n">error_variance</span> <span class="o">/</span> <span class="n">best_guess</span>
            <span class="n">c1</span> <span class="o">=</span> <span class="n">gamma</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">theta</span><span class="p">)</span>
            <span class="n">c2</span> <span class="o">=</span> <span class="n">gamma</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">theta</span><span class="p">)</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c2</span> <span class="o">-</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">c2</span>

        <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">5</span><span class="p">:</span> <span class="c1"># Assuming 5 is for Weibull   </span>
        
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_time</span><span class="p">):</span>
                <span class="c1"># Get the scalar values for this specific element (e.g., grid cell)</span>
                <span class="n">M</span> <span class="o">=</span> <span class="n">best_guess</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">M</span><span class="p">)</span>
                <span class="n">V</span> <span class="o">=</span> <span class="n">error_variance</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">V</span><span class="p">)</span>
                
                <span class="c1"># Handle cases with no variance to avoid division by zero</span>
                <span class="k">if</span> <span class="n">V</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">M</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                    <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                    <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                    <span class="k">continue</span> <span class="c1"># Skip to the next element</span>
        
                <span class="c1"># --- 1. Numerically solve for shape &#39;k&#39; ---</span>
                <span class="c1"># We need a reasonable starting guess. 2.0 is common (Rayleigh dist.)</span>
                <span class="n">initial_guess</span> <span class="o">=</span> <span class="mf">2.0</span>
                
                <span class="c1"># fsolve finds the root of our helper function</span>
                <span class="n">k</span> <span class="o">=</span> <span class="n">fsolve</span><span class="p">(</span><span class="n">weibull_shape_solver</span><span class="p">,</span> <span class="n">initial_guess</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">V</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>
        
                <span class="c1"># --- 2. Check for bad solution and calculate scale &#39;lambda&#39; ---</span>
                <span class="k">if</span> <span class="n">k</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="c1"># Solver failed</span>
                    <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                    <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                    <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                    <span class="k">continue</span>
                
                <span class="c1"># With &#39;k&#39; found, we can now algebraically find scale &#39;lambda&#39;</span>
                <span class="c1"># In scipy.stats, scale is &#39;scale&#39;</span>
                <span class="n">lambda_scale</span> <span class="o">=</span> <span class="n">M</span> <span class="o">/</span> <span class="n">gamma_function</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="mi">1</span><span class="o">/</span><span class="n">k</span><span class="p">)</span>
        
                <span class="c1"># --- 3. Calculate Probabilities ---</span>
                <span class="c1"># In scipy.stats, shape &#39;k&#39; is &#39;c&#39;</span>
                <span class="c1"># Use the T1 and T2 values for this specific element</span>
                
                <span class="n">c1</span> <span class="o">=</span> <span class="n">weibull_min</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">lambda_scale</span><span class="p">)</span>
                <span class="n">c2</span> <span class="o">=</span> <span class="n">weibull_min</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">lambda_scale</span><span class="p">)</span>
        
                <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">c1</span>
                <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">c2</span> <span class="o">-</span> <span class="n">c1</span>
                <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">c2</span>

        <span class="c1"># Student-t: df from clim; scale from clim; loc = best_guess</span>
        <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">6</span><span class="p">:</span>       
            <span class="c1"># Check if df is valid for variance calculation</span>
            <span class="k">if</span> <span class="n">dof</span> <span class="o">&lt;=</span> <span class="mi">2</span><span class="p">:</span>
                <span class="c1"># Cannot calculate scale, fill with NaNs</span>
                <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># 1. Calculate t-distribution parameters</span>
                <span class="c1"># &#39;loc&#39; (mean) is just the best_guess</span>
                <span class="n">loc</span> <span class="o">=</span> <span class="n">best_guess</span>
                <span class="c1"># &#39;scale&#39; is calculated from the variance and df</span>
                <span class="c1"># Variance = scale**2 * (df / (df - 2))</span>
                <span class="n">scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">error_variance</span> <span class="o">*</span> <span class="p">(</span><span class="n">dof</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="n">dof</span><span class="p">)</span>
                
                <span class="c1"># 2. Calculate probabilities</span>
                <span class="n">c1</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">dof</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">)</span>
                <span class="n">c2</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">dof</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">)</span>

                <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c1</span>
                <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c2</span> <span class="o">-</span> <span class="n">c1</span>
                <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">c2</span>

        <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">7</span><span class="p">:</span> <span class="c1"># Assuming 7 is for Poisson</span>
            
            <span class="c1"># --- 1. Set the Poisson parameter &#39;mu&#39; ---</span>
            <span class="c1"># The &#39;mu&#39; parameter is the mean.</span>
            
            <span class="c1"># A warning is strongly recommended if error_variance is different from best_guess</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">error_variance</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Warning: &#39;error_variance&#39; is not equal to &#39;best_guess&#39;.&quot;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Poisson model assumes mean=variance and is likely inappropriate.&quot;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Consider using Negative Binomial.&quot;</span><span class="p">)</span>
            
            <span class="n">mu</span> <span class="o">=</span> <span class="n">best_guess</span>
        
            <span class="c1"># --- 2. Calculate Probabilities ---</span>
            <span class="c1"># poisson.cdf(k, mu) calculates P(X &lt;= k)</span>
            
            <span class="n">c1</span> <span class="o">=</span> <span class="n">poisson</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">mu</span><span class="p">)</span>
            <span class="n">c2</span> <span class="o">=</span> <span class="n">poisson</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">mu</span><span class="p">)</span>
            
            <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c2</span> <span class="o">-</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">c2</span>

        <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="mi">8</span><span class="p">:</span> <span class="c1"># Assuming 8 is for Negative Binomial</span>
            
            <span class="c1"># --- 1. Calculate Negative Binomial Parameters ---</span>
            <span class="c1"># This model is ONLY valid for overdispersion (Variance &gt; Mean).</span>
            <span class="c1"># We will use np.where to set parameters to NaN if V &lt;= M.</span>
            
            <span class="c1"># p = Mean / Variance</span>
            <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">error_variance</span> <span class="o">&gt;</span> <span class="n">best_guess</span><span class="p">,</span> 
                         <span class="n">best_guess</span> <span class="o">/</span> <span class="n">error_variance</span><span class="p">,</span> 
                         <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
            
            <span class="c1"># n = Mean^2 / (Variance - Mean)</span>
            <span class="n">n</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">error_variance</span> <span class="o">&gt;</span> <span class="n">best_guess</span><span class="p">,</span> 
                         <span class="p">(</span><span class="n">best_guess</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">error_variance</span> <span class="o">-</span> <span class="n">best_guess</span><span class="p">),</span> 
                         <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
            
            <span class="c1"># --- 2. Calculate Probabilities ---</span>
            <span class="c1"># The nbinom.cdf function will propagate NaNs, correctly</span>
            <span class="c1"># handling the cases where the model was invalid.</span>
            
            <span class="n">c1</span> <span class="o">=</span> <span class="n">nbinom</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">)</span>
            <span class="n">c2</span> <span class="o">=</span> <span class="n">nbinom</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">)</span>
            
            <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c2</span> <span class="o">-</span> <span class="n">c1</span>
            <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">c2</span>
            
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid distribution&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">out</span></div>


<div class="viewcode-block" id="WAS_MARS_Model.calculate_tercile_probabilities_nonparametric">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_MARS_Model.calculate_tercile_probabilities_nonparametric">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">calculate_tercile_probabilities_nonparametric</span><span class="p">(</span><span class="n">best_guess</span><span class="p">,</span> <span class="n">error_samples</span><span class="p">,</span> <span class="n">first_tercile</span><span class="p">,</span> <span class="n">second_tercile</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Non-parametric method using historical error samples.&quot;&quot;&quot;</span>
        <span class="n">n_time</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">best_guess</span><span class="p">)</span>
        <span class="n">pred_prob</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="n">n_time</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_time</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">best_guess</span><span class="p">[</span><span class="n">t</span><span class="p">]):</span>
                <span class="k">continue</span>
            <span class="n">dist</span> <span class="o">=</span> <span class="n">best_guess</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">+</span> <span class="n">error_samples</span>
            <span class="n">dist</span> <span class="o">=</span> <span class="n">dist</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">dist</span><span class="p">)]</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">dist</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="n">p_below</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dist</span> <span class="o">&lt;</span> <span class="n">first_tercile</span><span class="p">)</span>
            <span class="n">p_between</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">dist</span> <span class="o">&gt;=</span> <span class="n">first_tercile</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">dist</span> <span class="o">&lt;</span> <span class="n">second_tercile</span><span class="p">))</span>
            <span class="n">p_above</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="p">(</span><span class="n">p_below</span> <span class="o">+</span> <span class="n">p_between</span><span class="p">)</span>
            <span class="n">pred_prob</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">p_below</span>
            <span class="n">pred_prob</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">p_between</span>
            <span class="n">pred_prob</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">p_above</span>
        <span class="k">return</span> <span class="n">pred_prob</span></div>




<div class="viewcode-block" id="WAS_MARS_Model.compute_prob">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_MARS_Model.compute_prob">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">compute_prob</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">Predictant</span><span class="p">:</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span><span class="p">,</span>
        <span class="n">clim_year_start</span><span class="p">,</span>
        <span class="n">clim_year_end</span><span class="p">,</span>
        <span class="n">hindcast_det</span><span class="p">:</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span><span class="p">,</span>
        <span class="n">best_code_da</span><span class="p">:</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">best_shape_da</span><span class="p">:</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">best_loc_da</span><span class="p">:</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">best_scale_da</span><span class="p">:</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute tercile probabilities for deterministic hindcasts.</span>

<span class="sd">        If dist_method == &#39;bestfit&#39;:</span>
<span class="sd">            - Use cluster-based best-fit distributions to:</span>
<span class="sd">                * derive terciles analytically from (best_code_da, best_shape_da, best_loc_da, best_scale_da),</span>
<span class="sd">                * compute predictive probabilities using the same family.</span>

<span class="sd">        Otherwise:</span>
<span class="sd">            - Use empirical terciles from Predictant climatology and the selected</span>
<span class="sd">              parametric / nonparametric method.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Predictant : xarray.DataArray</span>
<span class="sd">            Observed data (T, Y, X) or (T, Y, X, M).</span>
<span class="sd">        clim_year_start, clim_year_end : int or str</span>
<span class="sd">            Climatology period (inclusive) for thresholds.</span>
<span class="sd">        hindcast_det : xarray.DataArray</span>
<span class="sd">            Deterministic hindcast (T, Y, X).</span>
<span class="sd">        best_code_da, best_shape_da, best_loc_da, best_scale_da : xarray.DataArray, optional</span>
<span class="sd">            Output from WAS_TransformData.fit_best_distribution_grid, required for &#39;bestfit&#39;.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        hindcast_prob : xarray.DataArray</span>
<span class="sd">            Probabilities with dims (probability=[&#39;PB&#39;,&#39;PN&#39;,&#39;PA&#39;], T, Y, X).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Handle member dimension if present</span>
        <span class="k">if</span> <span class="s2">&quot;M&quot;</span> <span class="ow">in</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">dims</span><span class="p">:</span>
            <span class="n">Predictant</span> <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">M</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">drop_vars</span><span class="p">(</span><span class="s2">&quot;M&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>

        <span class="c1"># Ensure dimension order</span>
        <span class="n">Predictant</span> <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="s2">&quot;Y&quot;</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">)</span>

        <span class="c1"># Spatial mask</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="o">~</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">Predictant</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="mi">0</span><span class="p">)),</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>

        <span class="c1"># Climatology subset</span>
        <span class="n">clim</span> <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">sel</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="nb">slice</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">clim_year_start</span><span class="p">),</span> <span class="nb">str</span><span class="p">(</span><span class="n">clim_year_end</span><span class="p">)))</span>
        <span class="k">if</span> <span class="n">clim</span><span class="o">.</span><span class="n">sizes</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">3</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Not enough years in climatology period for terciles.&quot;</span><span class="p">)</span>

        <span class="c1"># Error variance for predictive distributions</span>
        <span class="n">error_variance</span> <span class="o">=</span> <span class="p">(</span><span class="n">Predictant</span> <span class="o">-</span> <span class="n">hindcast_det</span><span class="p">)</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="s2">&quot;T&quot;</span><span class="p">)</span>
        <span class="n">dof</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">clim</span><span class="o">.</span><span class="n">sizes</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">])</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

        <span class="c1"># Empirical terciles (used by non-bestfit methods)</span>
        <span class="n">terciles_emp</span> <span class="o">=</span> <span class="n">clim</span><span class="o">.</span><span class="n">quantile</span><span class="p">([</span><span class="mf">0.32</span><span class="p">,</span> <span class="mf">0.67</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="s2">&quot;T&quot;</span><span class="p">)</span>
        <span class="n">T1_emp</span> <span class="o">=</span> <span class="n">terciles_emp</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">quantile</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">drop_vars</span><span class="p">(</span><span class="s2">&quot;quantile&quot;</span><span class="p">)</span>
        <span class="n">T2_emp</span> <span class="o">=</span> <span class="n">terciles_emp</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">quantile</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">drop_vars</span><span class="p">(</span><span class="s2">&quot;quantile&quot;</span><span class="p">)</span>
        

        <span class="n">dm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dist_method</span>

        <span class="c1"># ---------- BESTFIT: zone-wise optimal distributions ----------</span>
        <span class="k">if</span> <span class="n">dm</span> <span class="o">==</span> <span class="s2">&quot;bestfit&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">v</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="p">(</span><span class="n">best_code_da</span><span class="p">,</span> <span class="n">best_shape_da</span><span class="p">,</span> <span class="n">best_loc_da</span><span class="p">,</span> <span class="n">best_scale_da</span><span class="p">)):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;dist_method=&#39;bestfit&#39; requires best_code_da, best_shape_da_da, best_loc_da, best_scale_da.&quot;</span>
                <span class="p">)</span>

            <span class="c1"># T1, T2 from best-fit distributions (per grid)</span>
            <span class="n">T1</span><span class="p">,</span> <span class="n">T2</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_ppf_terciles_from_code</span><span class="p">,</span>
                <span class="n">best_code_da</span><span class="p">,</span>
                <span class="n">best_shape_da</span><span class="p">,</span>
                <span class="n">best_loc_da</span><span class="p">,</span>
                <span class="n">best_scale_da</span><span class="p">,</span>
                <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[(),</span> <span class="p">(),</span> <span class="p">(),</span> <span class="p">()],</span>
                <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(),</span> <span class="p">()],</span>
                <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">dask</span><span class="o">=</span><span class="s2">&quot;parallelized&quot;</span><span class="p">,</span>
                <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span>
            <span class="p">)</span>

            <span class="c1"># Predictive probabilities using same family</span>
            <span class="n">hindcast_prob</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">calculate_tercile_probabilities_bestfit</span><span class="p">,</span>
                <span class="n">hindcast_det</span><span class="p">,</span>
                <span class="n">error_variance</span><span class="p">,</span>
                <span class="n">T1</span><span class="p">,</span>
                <span class="n">T2</span><span class="p">,</span>
                <span class="n">best_code_da</span><span class="p">,</span>
                <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;T&quot;</span><span class="p">,),</span> <span class="p">(),</span> <span class="p">(),</span> <span class="p">(),</span> <span class="p">()],</span>
                <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;probability&quot;</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">)],</span>
                <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;dof&#39;</span><span class="p">:</span> <span class="n">dof</span><span class="p">},</span>
                <span class="n">dask</span><span class="o">=</span><span class="s2">&quot;parallelized&quot;</span><span class="p">,</span>
                <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>
                <span class="n">dask_gufunc_kwargs</span><span class="o">=</span><span class="p">{</span>
                    <span class="s2">&quot;output_sizes&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;probability&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">},</span>
                    <span class="s2">&quot;allow_rechunk&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                <span class="p">},</span>
            <span class="p">)</span>

        <span class="c1"># ---------- Nonparametric ----------</span>
        <span class="k">elif</span> <span class="n">dm</span> <span class="o">==</span> <span class="s2">&quot;nonparam&quot;</span><span class="p">:</span>
            <span class="n">error_samples</span> <span class="o">=</span> <span class="n">Predictant</span> <span class="o">-</span> <span class="n">hindcast_det</span>
            <span class="n">hindcast_prob</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">calculate_tercile_probabilities_nonparametric</span><span class="p">,</span>
                <span class="n">hindcast_det</span><span class="p">,</span>
                <span class="n">error_samples</span><span class="p">,</span>
                <span class="n">T1_emp</span><span class="p">,</span>
                <span class="n">T2_emp</span><span class="p">,</span>
                <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;T&quot;</span><span class="p">,),</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,),</span> <span class="p">(),</span> <span class="p">()],</span>
                <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;probability&quot;</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">)],</span>
                <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">dask</span><span class="o">=</span><span class="s2">&quot;parallelized&quot;</span><span class="p">,</span>
                <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>
                <span class="n">dask_gufunc_kwargs</span><span class="o">=</span><span class="p">{</span>
                    <span class="s2">&quot;output_sizes&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;probability&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">},</span>
                    <span class="s2">&quot;allow_rechunk&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                <span class="p">},</span>
            <span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid dist_method: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">dist_method</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">hindcast_prob</span> <span class="o">=</span> <span class="n">hindcast_prob</span><span class="o">.</span><span class="n">assign_coords</span><span class="p">(</span>
            <span class="n">probability</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;probability&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;PB&quot;</span><span class="p">,</span> <span class="s2">&quot;PN&quot;</span><span class="p">,</span> <span class="s2">&quot;PA&quot;</span><span class="p">])</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">hindcast_prob</span> <span class="o">*</span> <span class="n">mask</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="s2">&quot;probability&quot;</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="s2">&quot;Y&quot;</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">)</span></div>



    <span class="c1"># --------------------------------------------------------------------------</span>
    <span class="c1">#  FORECAST METHOD</span>
    <span class="c1"># --------------------------------------------------------------------------</span>
<div class="viewcode-block" id="WAS_MARS_Model.forecast">
<a class="viewcode-back" href="../../api.html#wass2s.was_machine_learning.WAS_MARS_Model.forecast">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">forecast</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Predictant</span><span class="p">,</span> <span class="n">clim_year_start</span><span class="p">,</span> <span class="n">clim_year_end</span><span class="p">,</span> <span class="n">Predictor</span><span class="p">,</span> <span class="n">hindcast_det</span><span class="p">,</span> <span class="n">Predictor_for_year</span><span class="p">,</span> <span class="n">best_code_da</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">best_shape_da</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">best_loc_da</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">best_scale_da</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generates a single-year forecast using MARS, then computes </span>
<span class="sd">        tercile probabilities using self.dist_method.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Predictant : xarray.DataArray</span>
<span class="sd">            Observed data with dims (T, Y, X).</span>
<span class="sd">        clim_year_start : int</span>
<span class="sd">            Start year for climatology</span>
<span class="sd">        clim_year_end : int</span>
<span class="sd">            End year for climatology</span>
<span class="sd">        Predictor : xarray.DataArray</span>
<span class="sd">            Historical predictor data with dims (T, features).</span>
<span class="sd">        hindcast_det : xarray.DataArray</span>
<span class="sd">            Historical deterministic forecast with dims (output=[error,prediction], T, Y, X).</span>
<span class="sd">        Predictor_for_year : xarray.DataArray</span>
<span class="sd">            Single-year predictor with shape (features,) or (1, features).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        result_ : xarray.DataArray</span>
<span class="sd">            dims (output=2, Y, X) =&gt; [error, prediction]. </span>
<span class="sd">            For a true forecast, error is typically NaN.</span>
<span class="sd">        hindcast_prob : xarray.DataArray</span>
<span class="sd">            dims (probability=3, Y, X) =&gt; [PB, PN, PA].</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Provide a dummy y_test with the same shape as the spatial domain =&gt; [NaNs]</span>
        <span class="n">y_test_dummy</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">Predictant</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>

        <span class="c1"># Chunk sizes</span>
        <span class="n">chunksize_x</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">Predictant</span><span class="o">.</span><span class="n">get_index</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">))</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span><span class="p">))</span>
        <span class="n">chunksize_y</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">Predictant</span><span class="o">.</span><span class="n">get_index</span><span class="p">(</span><span class="s2">&quot;Y&quot;</span><span class="p">))</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span><span class="p">))</span>

        <span class="c1"># Align time dimension</span>
        <span class="n">Predictor</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">Predictant</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span>
        <span class="n">Predictant_st</span> <span class="o">=</span> <span class="n">standardize_timeseries</span><span class="p">(</span><span class="n">Predictant</span><span class="p">,</span> <span class="n">clim_year_start</span><span class="p">,</span> <span class="n">clim_year_end</span><span class="p">)</span>
        <span class="n">Predictant_st</span> <span class="o">=</span> <span class="n">Predictant_st</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="s1">&#39;T&#39;</span><span class="p">,</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span><span class="s1">&#39;X&#39;</span><span class="p">)</span>
        <span class="n">Predictor_for_year_</span> <span class="o">=</span> <span class="n">Predictor_for_year</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>

        <span class="c1"># 1) Fit+predict in parallel =&gt; shape (output=2, Y, X)</span>
        <span class="n">client</span> <span class="o">=</span> <span class="n">Client</span><span class="p">(</span><span class="n">n_workers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">nb_cores</span><span class="p">,</span> <span class="n">threads_per_worker</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">result_da</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">,</span>
            <span class="n">Predictor</span><span class="p">,</span>
            <span class="n">Predictant_st</span><span class="o">.</span><span class="n">chunk</span><span class="p">({</span><span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">chunksize_y</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">chunksize_x</span><span class="p">}),</span>
            <span class="n">Predictor_for_year_</span><span class="p">,</span>
            <span class="n">y_test_dummy</span><span class="o">.</span><span class="n">chunk</span><span class="p">({</span><span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">chunksize_y</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">chunksize_x</span><span class="p">}),</span>  <span class="c1"># dummy y_test</span>
            <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[</span>
                <span class="p">(</span><span class="s1">&#39;T&#39;</span><span class="p">,</span><span class="s1">&#39;features&#39;</span><span class="p">),</span>  <span class="c1"># x</span>
                <span class="p">(</span><span class="s1">&#39;T&#39;</span><span class="p">,),</span>           <span class="c1"># y</span>
                <span class="p">(</span><span class="s1">&#39;features&#39;</span><span class="p">,),</span>    <span class="c1"># x_test</span>
                <span class="p">()</span>
            <span class="p">],</span>
            <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">dask</span><span class="o">=</span><span class="s1">&#39;parallelized&#39;</span><span class="p">,</span>
            <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s1">&#39;output&#39;</span><span class="p">,)],</span>  <span class="c1"># output=2 =&gt; [error, prediction]</span>
            <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;float&#39;</span><span class="p">],</span>
            <span class="n">dask_gufunc_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;output_sizes&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;output&#39;</span><span class="p">:</span><span class="mi">2</span><span class="p">}},</span>
        <span class="p">)</span>
        <span class="n">result_</span> <span class="o">=</span> <span class="n">result_da</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
        <span class="n">client</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
        <span class="n">result_</span> <span class="o">=</span> <span class="n">result_</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">output</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">result_</span> <span class="o">=</span> <span class="n">reverse_standardize</span><span class="p">(</span><span class="n">result_</span><span class="p">,</span> <span class="n">Predictant</span><span class="p">,</span> <span class="n">clim_year_start</span><span class="p">,</span> <span class="n">clim_year_end</span><span class="p">)</span>

        <span class="c1"># 2) Compute thresholds T1, T2 from climatology</span>
        <span class="n">index_start</span> <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">get_index</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">get_loc</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">clim_year_start</span><span class="p">))</span><span class="o">.</span><span class="n">start</span>
        <span class="n">index_end</span>   <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">get_index</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">get_loc</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">clim_year_end</span><span class="p">))</span><span class="o">.</span><span class="n">stop</span>
        <span class="n">rainfall_for_tercile</span> <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="nb">slice</span><span class="p">(</span><span class="n">index_start</span><span class="p">,</span> <span class="n">index_end</span><span class="p">))</span>
        <span class="n">terciles</span> <span class="o">=</span> <span class="n">rainfall_for_tercile</span><span class="o">.</span><span class="n">quantile</span><span class="p">([</span><span class="mf">0.32</span><span class="p">,</span> <span class="mf">0.67</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="s1">&#39;T&#39;</span><span class="p">)</span>
        <span class="n">T1_emp</span> <span class="o">=</span> <span class="n">terciles</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">quantile</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">drop_vars</span><span class="p">(</span><span class="s1">&#39;quantile&#39;</span><span class="p">)</span>
        <span class="n">T2_emp</span> <span class="o">=</span> <span class="n">terciles</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">quantile</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">drop_vars</span><span class="p">(</span><span class="s1">&#39;quantile&#39;</span><span class="p">)</span>
        <span class="n">error_variance</span> <span class="o">=</span> <span class="p">(</span><span class="n">Predictant</span> <span class="o">-</span> <span class="n">hindcast_det</span><span class="p">)</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="s1">&#39;T&#39;</span><span class="p">)</span>
        
        <span class="c1"># Expand single prediction to T=1 so probability methods can handle it</span>
        <span class="n">forecast_expanded</span> <span class="o">=</span> <span class="n">result_</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span>
            <span class="n">T</span><span class="o">=</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">Timestamp</span><span class="p">(</span><span class="n">Predictor_for_year</span><span class="o">.</span><span class="n">coords</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">to_pydatetime</span><span class="p">()]</span>
        <span class="p">)</span>
        <span class="n">year</span> <span class="o">=</span> <span class="n">Predictor_for_year</span><span class="o">.</span><span class="n">coords</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;datetime64[Y]&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1970</span>
        <span class="n">T_value_1</span> <span class="o">=</span> <span class="n">Predictant</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">coords</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>  <span class="c1"># Get the datetime64 value from da1</span>
        <span class="n">month_1</span> <span class="o">=</span> <span class="n">T_value_1</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;datetime64[M]&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span> <span class="o">%</span> <span class="mi">12</span> <span class="o">+</span> <span class="mi">1</span>  <span class="c1"># Extract month</span>
        <span class="n">new_T_value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">datetime64</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">year</span><span class="si">}</span><span class="s2">-</span><span class="si">{</span><span class="n">month_1</span><span class="si">:</span><span class="s2">02d</span><span class="si">}</span><span class="s2">-01&quot;</span><span class="p">)</span>
        
        <span class="n">forecast_expanded</span> <span class="o">=</span> <span class="n">forecast_expanded</span><span class="o">.</span><span class="n">assign_coords</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span><span class="p">([</span><span class="n">new_T_value</span><span class="p">],</span> <span class="n">dims</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">]))</span>
        <span class="n">forecast_expanded</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">forecast_expanded</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;datetime64[ns]&#39;</span><span class="p">)</span>

        <span class="n">dof</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">rainfall_for_tercile</span><span class="o">.</span><span class="n">sizes</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">])</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

        <span class="n">dm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dist_method</span>

        <span class="c1"># ---------- BESTFIT ----------</span>
        <span class="k">if</span> <span class="n">dm</span> <span class="o">==</span> <span class="s2">&quot;bestfit&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">v</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="p">(</span><span class="n">best_code_da</span><span class="p">,</span> <span class="n">best_shape_da</span><span class="p">,</span> <span class="n">best_loc_da</span><span class="p">,</span> <span class="n">best_scale_da</span><span class="p">)):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;dist_method=&#39;bestfit&#39; requires best_code_da, best_shape_da, best_loc_da, best_scale_da.&quot;</span>
                <span class="p">)</span>
            
            <span class="n">T1</span><span class="p">,</span> <span class="n">T2</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_ppf_terciles_from_code</span><span class="p">,</span>
                <span class="n">best_code_da</span><span class="p">,</span>
                <span class="n">best_shape_da</span><span class="p">,</span>
                <span class="n">best_loc_da</span><span class="p">,</span>
                <span class="n">best_scale_da</span><span class="p">,</span>
                <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[(),</span> <span class="p">(),</span> <span class="p">(),</span> <span class="p">()],</span>
                <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(),</span> <span class="p">()],</span>
                <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">dask</span><span class="o">=</span><span class="s2">&quot;parallelized&quot;</span><span class="p">,</span>
                <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span>
            <span class="p">)</span>

            <span class="n">forecast_prob</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">calculate_tercile_probabilities_bestfit</span><span class="p">,</span>
                <span class="n">forecast_expanded</span><span class="p">,</span>
                <span class="n">error_variance</span><span class="p">,</span>
                <span class="n">T1</span><span class="p">,</span>
                <span class="n">T2</span><span class="p">,</span>
                <span class="n">best_code_da</span><span class="p">,</span>
                <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;T&quot;</span><span class="p">,),</span> <span class="p">(),</span> <span class="p">(),</span> <span class="p">(),</span> <span class="p">()],</span>
                <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;probability&quot;</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">)],</span>
                <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">dask</span><span class="o">=</span><span class="s2">&quot;parallelized&quot;</span><span class="p">,</span>
                <span class="n">kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;dof&quot;</span><span class="p">:</span> <span class="n">dof</span><span class="p">},</span>
                <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>
                <span class="n">dask_gufunc_kwargs</span><span class="o">=</span><span class="p">{</span>
                    <span class="s2">&quot;output_sizes&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;probability&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">},</span>
                    <span class="s2">&quot;allow_rechunk&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                <span class="p">},</span>
            <span class="p">)</span>

        <span class="c1"># ---------- Nonparametric ----------</span>
        <span class="k">elif</span> <span class="n">dm</span> <span class="o">==</span> <span class="s2">&quot;nonparam&quot;</span><span class="p">:</span>
            <span class="n">error_samples</span> <span class="o">=</span> <span class="n">Predictant</span> <span class="o">-</span> <span class="n">hindcast_det</span>
            <span class="n">forecast_prob</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">apply_ufunc</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">calculate_tercile_probabilities_nonparametric</span><span class="p">,</span>
                <span class="n">forecast_expanded</span><span class="p">,</span>
                <span class="n">error_samples</span><span class="p">,</span>
                <span class="n">T1_emp</span><span class="p">,</span>
                <span class="n">T2_emp</span><span class="p">,</span>
                <span class="n">input_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;T&quot;</span><span class="p">,),</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,),</span> <span class="p">(),</span> <span class="p">()],</span>
                <span class="n">output_core_dims</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;probability&quot;</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">)],</span>
                <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">dask</span><span class="o">=</span><span class="s2">&quot;parallelized&quot;</span><span class="p">,</span>
                <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>
                <span class="n">dask_gufunc_kwargs</span><span class="o">=</span><span class="p">{</span>
                    <span class="s2">&quot;output_sizes&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;probability&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">},</span>
                    <span class="s2">&quot;allow_rechunk&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                <span class="p">},</span>
            <span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid dist_method: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">dist_method</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">forecast_prob</span> <span class="o">=</span> <span class="n">forecast_prob</span><span class="o">.</span><span class="n">assign_coords</span><span class="p">(</span><span class="n">probability</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;probability&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;PB&#39;</span><span class="p">,</span> <span class="s1">&#39;PN&#39;</span><span class="p">,</span> <span class="s1">&#39;PA&#39;</span><span class="p">]))</span>
        <span class="k">return</span> <span class="n">forecast_expanded</span><span class="p">,</span> <span class="n">forecast_prob</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="s1">&#39;probability&#39;</span><span class="p">,</span> <span class="s1">&#39;T&#39;</span><span class="p">,</span> <span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">)</span></div>
</div>

</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Mandela C. M. HOUNGNIBO.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>