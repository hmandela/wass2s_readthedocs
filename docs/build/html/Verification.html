

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Verification Module &mdash; wass2s: A python-based tool for seasonal climate forecast in West Africa and the Sahel. 0.1.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=e59714d7" />

  
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js?v=a58bc63e"></script>
      <script src="_static/doctools.js?v=9bcbadda"></script>
      <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Multi-Model Ensemble (MME) Techniques" href="mme.html" />
    <link rel="prev" title="Preprocessing Modules" href="Preprocessing.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            wass2s: A python-based tool for seasonal climate forecast in West Africa and the Sahel.
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="Installation.html">Installation</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="Usage.html">Usage</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="Download.html">Download module</a></li>
<li class="toctree-l2"><a class="reference internal" href="Preprocessing.html">Preprocessing Modules</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Verification Module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#deterministic-metrics">Deterministic Metrics</a></li>
<li class="toctree-l3"><a class="reference internal" href="#probabilistic-metrics">Probabilistic Metrics</a></li>
<li class="toctree-l3"><a class="reference internal" href="#ensemble-metrics">Ensemble Metrics</a></li>
<li class="toctree-l3"><a class="reference internal" href="#annual-year-validation">Annual Year Validation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="mme.html">Multi-Model Ensemble (MME) Techniques</a></li>
<li class="toctree-l2"><a class="reference internal" href="ImplementWASNextGen.html">Quantifying uncertainty via cross-validation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="api.html">wass2s submodules</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">wass2s: A python-based tool for seasonal climate forecast in West Africa and the Sahel.</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="Usage.html">Usage</a></li>
      <li class="breadcrumb-item active">Verification Module</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/Verification.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="verification-module">
<h1>Verification Module<a class="headerlink" href="#verification-module" title="Link to this heading"></a></h1>
<p><strong>This section is under construction.</strong></p>
<p>The Verification module provides tools for evaluating the performance of climate forecasts using a variety of deterministic, probabilistic, and ensemble-based metrics. It is implemented in the <cite>was_verification.py</cite> module and leverages the <cite>WAS_Verification</cite> class to compute metrics such as Kling-Gupta Efficiency (KGE), Pearson Correlation, Ranked Probability Skill Score (RPSS), and Continuous Ranked Probability Score (CRPS). The module also includes visualization utilities for plotting scores, reliability diagrams, and ROC curves.</p>
<p>This module is designed to work with gridded climate data, typically stored in <cite>xarray</cite> DataArrays, and supports parallel computation using <cite>dask</cite> for efficiency with large datasets.</p>
<p>The <cite>WAS_Verification</cite> class is the core of the Verification module, providing methods to compute and visualize various performance metrics for climate forecasts.</p>
<p><strong>Initialization</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">wass2s.was_verification</span> <span class="kn">import</span> <span class="n">WAS_Verification</span>

<span class="c1"># Initialize with a distribution method for probabilistic forecasts</span>
<span class="n">verifier</span> <span class="o">=</span> <span class="n">WAS_Verification</span><span class="p">()</span>
</pre></div>
</div>
<p><strong>Available Metrics</strong></p>
<p>The class defines a dictionary of scoring metrics with metadata, including:</p>
<ul class="simple">
<li><p><strong>Deterministic Metrics</strong>:
- <cite>KGE</cite>: Kling-Gupta Efficiency (-1 to 1).
- <cite>Pearson</cite>: Pearson Correlation Coefficient (-1 to 1).
- <cite>IOA</cite>: Index of Agreement (0 to 1).
- <cite>MAE</cite>: Mean Absolute Error (0 to 100).
- <cite>RMSE</cite>: Root Mean Square Error (0 to 100).
- <cite>NSE</cite>: Nash-Sutcliffe Efficiency (None to 1).
- <cite>TAYLOR_DIAGRAM</cite>: Taylor Diagram (visualization).</p></li>
<li><p><strong>Probabilistic Metrics</strong>:
- <cite>GROC</cite>: Generalized Receiver Operating Characteristic (0 to 1).
- <cite>RPSS</cite>: Ranked Probability Skill Score (-1 to 1).
- <cite>IGS</cite>: Ignorance Score (0 to None).
- <cite>RES</cite>: Resolution Score (0 to None).
- <cite>REL</cite>: Reliability Score (None to None).
- <cite>RELIABILITY_DIAGRAM</cite>: Reliability Diagram (visualization).
- <cite>ROC_CURVE</cite>: Receiver Operating Characteristic Curve (visualization).</p></li>
<li><p><strong>Ensemble Metrics</strong>:
- <cite>CRPS</cite>: Continuous Ranked Probability Score (0 to 100).</p></li>
</ul>
<p><strong>Metadata Access</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">metadata</span> <span class="o">=</span> <span class="n">verifier</span><span class="o">.</span><span class="n">get_scores_metadata</span><span class="p">()</span>
</pre></div>
</div>
<p>This returns a dictionary containing the name, range, type, colormap, and computation function for each metric.</p>
<section id="deterministic-metrics">
<h2>Deterministic Metrics<a class="headerlink" href="#deterministic-metrics" title="Link to this heading"></a></h2>
<p>Deterministic metrics evaluate the performance of point forecasts against observations. They are computed using the <cite>compute_deterministic_score</cite> method, which applies a scoring function over <cite>xarray</cite> DataArrays.</p>
<p><strong>Example Usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Compute Pearson Correlation</span>
<span class="n">pearson_score</span> <span class="o">=</span> <span class="n">verifier</span><span class="o">.</span><span class="n">compute_deterministic_score</span><span class="p">(</span>
    <span class="n">verifier</span><span class="o">.</span><span class="n">pearson_corr</span><span class="p">,</span> <span class="n">obs_data</span><span class="p">,</span> <span class="n">model_data</span>
<span class="p">)</span>

<span class="c1"># Plot the score</span>
<span class="n">verifier</span><span class="o">.</span><span class="n">plot_model_score</span><span class="p">(</span><span class="n">pearson_score</span><span class="p">,</span> <span class="s2">&quot;Pearson&quot;</span><span class="p">,</span> <span class="n">dir_save_score</span><span class="o">=</span><span class="s2">&quot;./scores&quot;</span><span class="p">,</span> <span class="n">figure_name</span><span class="o">=</span><span class="s2">&quot;Pearson_Score&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Key Methods</strong></p>
<ul class="simple">
<li><p><cite>kling_gupta_efficiency</cite>: Computes KGE, balancing correlation, bias, and variability.</p></li>
<li><p><cite>pearson_corr</cite>: Computes Pearson Correlation Coefficient.</p></li>
<li><p><cite>index_of_agreement</cite>: Computes IOA, measuring agreement between predictions and observations.</p></li>
<li><p><cite>mean_absolute_error</cite>: Computes MAE, the average absolute difference.</p></li>
<li><p><cite>root_mean_square_error</cite>: Computes RMSE, the square root of mean squared differences.</p></li>
<li><p><cite>nash_sutcliffe_efficiency</cite>: Computes NSE, comparing prediction errors to the mean of observations.</p></li>
<li><p><cite>taylor_diagram</cite>: Placeholder for Taylor Diagram visualization (to be implemented).</p></li>
</ul>
<p><strong>Plotting</strong></p>
<p>The <cite>plot_model_score</cite> method visualizes deterministic scores on a map using <cite>cartopy</cite>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">verifier</span><span class="o">.</span><span class="n">plot_model_score</span><span class="p">(</span><span class="n">score_result</span><span class="p">,</span> <span class="s2">&quot;KGE&quot;</span><span class="p">,</span> <span class="n">dir_save_score</span><span class="o">=</span><span class="s2">&quot;./scores&quot;</span><span class="p">,</span> <span class="n">figure_name</span><span class="o">=</span><span class="s2">&quot;KGE_Model&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>The <cite>plot_models_score</cite> method plots multiple model scores in a grid.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model_metrics</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;model1&quot;</span><span class="p">:</span> <span class="n">score_result1</span><span class="p">,</span>
    <span class="s2">&quot;model2&quot;</span><span class="p">:</span> <span class="n">score_result2</span>
<span class="p">}</span>
<span class="n">verifier</span><span class="o">.</span><span class="n">plot_models_score</span><span class="p">(</span><span class="n">model_metrics</span><span class="p">,</span> <span class="s2">&quot;Pearson&quot;</span><span class="p">,</span> <span class="n">dir_save_score</span><span class="o">=</span><span class="s2">&quot;./scores&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="probabilistic-metrics">
<h2>Probabilistic Metrics<a class="headerlink" href="#probabilistic-metrics" title="Link to this heading"></a></h2>
<p>Probabilistic metrics evaluate the performance of forecasts that provide probabilities for tercile categories (below-normal, near-normal, above-normal). These are computed using the <cite>compute_probabilistic_score</cite> method.</p>
<p><strong>Example Usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Compute tercile probabilities</span>
<span class="n">proba_forecast</span> <span class="o">=</span> <span class="n">verifier</span><span class="o">.</span><span class="n">gcm_compute_prob</span><span class="p">(</span><span class="n">obs_data</span><span class="p">,</span> <span class="n">clim_year_start</span><span class="o">=</span><span class="mi">1981</span><span class="p">,</span> <span class="n">clim_year_end</span><span class="o">=</span><span class="mi">2010</span><span class="p">,</span> <span class="n">hindcast_det</span><span class="o">=</span><span class="n">model_data</span><span class="p">)</span>

<span class="c1"># Compute RPSS</span>
<span class="n">rpss_score</span> <span class="o">=</span> <span class="n">verifier</span><span class="o">.</span><span class="n">compute_probabilistic_score</span><span class="p">(</span>
    <span class="n">verifier</span><span class="o">.</span><span class="n">calculate_rpss</span><span class="p">,</span> <span class="n">obs_data</span><span class="p">,</span> <span class="n">proba_forecast</span><span class="p">,</span> <span class="n">clim_year_start</span><span class="o">=</span><span class="mi">1981</span><span class="p">,</span> <span class="n">clim_year_end</span><span class="o">=</span><span class="mi">2010</span>
<span class="p">)</span>
</pre></div>
</div>
<p><strong>Key Methods</strong></p>
<ul class="simple">
<li><p><cite>classify</cite>: Classifies data into terciles based on climatology.</p></li>
<li><p><cite>compute_class</cite>: Computes tercile class labels for observations.</p></li>
<li><p><cite>calculate_groc</cite>: Computes GROC, averaging AUC across tercile categories.</p></li>
<li><p><cite>calculate_rpss</cite>: Computes RPSS, comparing forecast probabilities to climatology.</p></li>
<li><p><cite>ignorance_score</cite>: Computes Ignorance Score per Weijs (2010).</p></li>
<li><p><cite>resolution_score_grid</cite>: Computes Resolution Score, measuring how forecasts differ from climatology.</p></li>
<li><p><cite>reliability_score_grid</cite>: Computes Reliability Score, assessing forecast calibration.</p></li>
<li><p><cite>reliability_diagram</cite>: Plots Reliability Diagrams for each tercile category.</p></li>
<li><p><cite>plot_roc_curves</cite>: Plots ROC Curves with confidence intervals for each tercile.</p></li>
</ul>
<p><strong>Visualization</strong></p>
<p>Reliability Diagrams and ROC Curves are generated for probabilistic forecasts.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot Reliability Diagram</span>
<span class="n">verifier</span><span class="o">.</span><span class="n">reliability_diagram</span><span class="p">(</span>
    <span class="n">modelname</span><span class="o">=</span><span class="s2">&quot;Model1&quot;</span><span class="p">,</span> <span class="n">dir_to_save_score</span><span class="o">=</span><span class="s2">&quot;./scores&quot;</span><span class="p">,</span> <span class="n">y_true</span><span class="o">=</span><span class="n">obs_data</span><span class="p">,</span> <span class="n">y_probs</span><span class="o">=</span><span class="n">proba_forecast</span><span class="p">,</span>
    <span class="n">clim_year_start</span><span class="o">=</span><span class="mi">1981</span><span class="p">,</span> <span class="n">clim_year_end</span><span class="o">=</span><span class="mi">2010</span>
<span class="p">)</span>

<span class="c1"># Plot ROC Curves with 95% confidence intervals</span>
<span class="n">verifier</span><span class="o">.</span><span class="n">plot_roc_curves</span><span class="p">(</span>
    <span class="n">modelname</span><span class="o">=</span><span class="s2">&quot;Model1&quot;</span><span class="p">,</span> <span class="n">dir_to_save_score</span><span class="o">=</span><span class="s2">&quot;./scores&quot;</span><span class="p">,</span> <span class="n">y_true</span><span class="o">=</span><span class="n">obs_data</span><span class="p">,</span> <span class="n">y_probs</span><span class="o">=</span><span class="n">proba_forecast</span><span class="p">,</span>
    <span class="n">clim_year_start</span><span class="o">=</span><span class="mi">1981</span><span class="p">,</span> <span class="n">clim_year_end</span><span class="o">=</span><span class="mi">2010</span><span class="p">,</span> <span class="n">n_bootstraps</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">ci</span><span class="o">=</span><span class="mf">0.95</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="ensemble-metrics">
<h2>Ensemble Metrics<a class="headerlink" href="#ensemble-metrics" title="Link to this heading"></a></h2>
<p>Ensemble metrics evaluate forecasts with multiple members, such as those from GCMs. The primary metric is CRPS, computed using <cite>xskillscore</cite>.</p>
<p><strong>Example Usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Compute CRPS for ensemble forecast</span>
<span class="n">crps_score</span> <span class="o">=</span> <span class="n">verifier</span><span class="o">.</span><span class="n">compute_crps</span><span class="p">(</span><span class="n">obs_data</span><span class="p">,</span> <span class="n">model_data</span><span class="p">,</span> <span class="n">member_dim</span><span class="o">=</span><span class="s1">&#39;number&#39;</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="s2">&quot;T&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Key Methods</strong></p>
<ul class="simple">
<li><p><cite>compute_crps</cite>: Computes CRPS for ensemble forecasts, measuring the difference between predicted and observed distributions.</p></li>
</ul>
</section>
<section id="annual-year-validation">
<h2>Annual Year Validation<a class="headerlink" href="#annual-year-validation" title="Link to this heading"></a></h2>
<p>The module provides utilities to validate forecasts for a specific year, including ratio-to-average classification and RPSS computation.</p>
<p><strong>Key Methods</strong></p>
<ul class="simple">
<li><p><cite>ratio_to_average</cite>: Classifies forecast data relative to the climatological mean into categories (e.g., Well Above Average, Near Average).</p></li>
<li><p><cite>compute_one_year_rpss</cite>: Computes RPSS for a specific year and visualizes it on a map.</p></li>
</ul>
<p><strong>Example Usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Classify ratio to average for a specific year</span>
<span class="n">verifier</span><span class="o">.</span><span class="n">ratio_to_average</span><span class="p">(</span><span class="n">predictant</span><span class="o">=</span><span class="n">obs_data</span><span class="p">,</span> <span class="n">clim_year_start</span><span class="o">=</span><span class="mi">1981</span><span class="p">,</span> <span class="n">clim_year_end</span><span class="o">=</span><span class="mi">2010</span><span class="p">,</span> <span class="n">year</span><span class="o">=</span><span class="mi">2020</span><span class="p">)</span>

<span class="c1"># Compute RPSS for a specific year</span>
<span class="n">verifier</span><span class="o">.</span><span class="n">compute_one_year_rpss</span><span class="p">(</span>
    <span class="n">obs</span><span class="o">=</span><span class="n">obs_data</span><span class="p">,</span> <span class="n">prob_pred</span><span class="o">=</span><span class="n">proba_forecast</span><span class="p">,</span> <span class="n">clim_year_start</span><span class="o">=</span><span class="mi">1981</span><span class="p">,</span> <span class="n">clim_year_end</span><span class="o">=</span><span class="mi">2010</span><span class="p">,</span> <span class="n">year</span><span class="o">=</span><span class="mi">2020</span>
<span class="p">)</span>
</pre></div>
</div>
<p>This documentation provides an overview of the Verification module’s capabilities, along with example usage for key methods.
For detailed information on each method, refer to the source code and docstrings in API.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="Preprocessing.html" class="btn btn-neutral float-left" title="Preprocessing Modules" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="mme.html" class="btn btn-neutral float-right" title="Multi-Model Ensemble (MME) Techniques" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Mandela C. M. HOUNGNIBO.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>